[["index.html", "Readings for MTH207 Preface", " Readings for MTH207 Derek H. Ogle 18 Jan 2021 Preface This book contains a translation and re-development of past lectures from MTH207. Thus, it contains all, but only, information that I expect you to know from this course. I have made every attempt to make it easy to read, provide visuals and explanations for all concepts, and grammatically correct. However, there are likely still errors or descriptions that dont make sense. Please feel free to ask questions or post errors on the appropriate channel of the course MS Team. The book highlights definitions and tips in special boxes. Definition: This is a definition. This is a tip. R Code and results are also shown in special boxes. Code in the R box can be copied verbatim from the box with the icon that appears when you hover over the upper right corner of the code box. dat &lt;- c(3,4,5,2,8) mean(dat) #R&gt; [1] 4.4 The material presented in this book can be challenging to master. Please dont hesitate to ask me questions as you have them! "],["ModelTypes.html", "Module 1 Model Types &amp; Methods 1.1 Distinguishing Methods 1.2 Method Purposes", " Module 1 Model Types &amp; Methods During this course we will examine a variety of models called either general linear or generalIZED linear models. General linear models have a quantitative response variable and generally assume that the errors around the model follow a normal distribution. General linear models that we will discuss are One-Way ANOVA1, Two-WAY ANOVA, Simple Linear Regression, and Indicator Variable Regression. GeneralIZED linear models do not require a quantitative response variable nor errors that are normally distributed. Thus, generalIZED linear models are more flexible than general linear models. The only generalIZED linear model that we will encounter in this course is Logistic Regression, but the chi-square test from your introductory statistics course can also be cast as a generalIZED linear model. Response Variable: The variable thought to depend upon, be explained by, or be predicted by other variables. All models covered in this course will have only one response variable Both general and generalIZED linear models can have a single explanatory variable that can be either quantitative or categorical, or multiple explanatory variables that can be all quantitative, all categorical, or a mixture of both quantitative and categorical. Ultimately, there can be several explanatory variables in a model, but we will only consider one or two explanatory variables in this course. Explanatory Variable: A variable thought to explain or be able to predict the response variable. 1.1 Distinguishing Methods The five methods covered in this course can be distinguished by considering only the type of response variable and the types and number of explanatory variables (Table 1.1). Thus, you should review variable types and definitions and distinctions of response and explanatory variables from your introductory statistics course. Table 1.1: Response and explanatory variable types (and number) for the models considered in this course. Response Explanatory Linear Model Quantitative Categorical (only one) One-Way ANOVA Quantitative Categorical (two) Two-Way ANOVA Quantitative Quantitative (only one) Simple Linear Regression Quantitative Quantitative (one) &amp; Categorical (one) Indicator Variable Regression Binomial Quantitative (or Both) (Binary) Logistic Regression 1.2 Method Purposes As seen above, each method uses different types of data. Not surprisingly then, each method tests different hypotheses or has a different analytical purpose. These purposes will be discussed in detail in subsequent modules. However, the major objective of each method is explained briefly below (in the order that we will cover them). Each example uses a data set that contains data about mirex concentrations (mirex) for two species of salmon (species) captured in six years between 1977 and 1999 (year) in Lake Ontario. The weight of each fish (weight) and whether or not the mirex concentration exceeded the EPA limit of 0.1 mg/kg (exceeds_limit) were also recorded. A one-way ANOVA is used to determine if the means of the quantitative response variable (mirex) differ among two or more groups defined by a single categorical variable (e.g., year). Figure 1.1: Mean mirex concentration by sample year. This is an example of a One-Way ANOVA. A two-way ANOVA is used to determine if the means of the quantitative response variable (mirex) differ among groups of one categorical variable (e.g., year), among groups of another categorical variable (e.g., species), or by the interaction between the two categorical variables. Figure 1.2: Mean mirex concentration by sample year and salmon species. This is an example of a Two-Way ANOVA. A simple linear regression is used to determine if there is a relationship between the quantitative response variable (e.g., mirex) and a single quantitative explanatory variable (e.g., weight). Figure 1.3: Mirex concentration by fish weight. This is an example of a Simple Linear Regression. An indicator variable regression is used to determine if the relationship between a quantitative response (e.g., mirex) and a quantitative explanatory variable (e.g., weight) differs between two or more groups defined by a categorical explanatory variable (e.g., species). This will look like two (or more) simple linear regressions are being compared. Figure 1.4: Mirex concentration by fish weight seprated by salmon species. This is an example of an Indicator Variable Regression. A logistic regression is used to determine if there is a relationship between the probability of success for a binary2 categorical response variable (e.g., exceeds_limit) and the quantitative explanatory variable (e.g., weight). Figure 1.5: The probability that the mirex concentration exceeded the 0.1 mg/kg threshold by fish weight. This is an example of a Logistic Regression. From these examples it should be apparent that ANOVAs compare means among groups and will look like means (usually with confidence intervals) plotted as points for each group. In contrast regressions explore relationships and will look like a line or a curve when plotted. ANOVAs compare means; regressions examine relationships. ANOVA is short for ANalysis Of VAriance Binary means there are only two categories  generically success and failure. "],["T2Review.html", "Module 2 2-Sample t Review 2.1 Review 2.2 Analysis in R 2.3 Signal-to-Noise", " Module 2 2-Sample t Review A two-sample t-test is a statistical method for comparing the means of a quantitative variable between two populations represented by two independent samples. The specific details of a two-sample t-test were covered in your introductory statistics course and will only be cursorily reviewed here. 2.1 Review The null hypothesis for a 2-sample t-test is H0: \\(\\mu_{1}=\\mu_{2}\\), where \\(\\mu\\) is the population mean and the subscripts represent the two populations. The alternative hypothesis of a 2-sample t-test may be less than, greater than, or not equals. We will use HA: \\(\\mu_{1}\\ne\\mu_{2}\\) for most examples in this course. The 2-sample t-test assumes that (i) individuals in the populations are independent; (ii) the sample size (\\(n_{1}+n_{2}\\)) is great than 40, greater than 15 and the histograms are not strongly skewed, or the histograms are normally distributed; and (iii) the population variances are equal. The assumption of equal variances for the 2-sample t-test is tested with Levenes test, which uses H0: \\(\\sigma_{1}^{2}=\\sigma_{2}^{2}\\) and HA: \\(\\sigma_{1}^{2}\\ne\\sigma_{2}^{2}\\), where \\(\\sigma^{2}\\) is the population variance. If H0 is rejected for Levenes test then the variances for both populations are assumed to be equal, such that only one combined sample variance needs to be estimated. That combined sample variance is called the the pooled sample variance and is computed as a weighted mean of the two sample variances, \\[ s_{p}^{2}=\\frac{(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2} \\] If the three assumptions are met then the statistic for the 2-sample t-test is \\(\\bar{x}_{1}-\\bar{x}_{2}\\) which is standardized to a t test statistic with \\[ t=\\frac{\\bar{x}_{1}-\\bar{x}_{2}}{\\sqrt{s_{p}^{2}\\left(\\frac{1}{n_{1}}+\\frac{1}{n_{2}} \\right)}} \\] The t test statistic is converted to a p-value using a t-distribution with \\(n_{1}+n_{2}-2\\) df. Of course, a p-value &lt;  means that H0 is rejected and the two population means appear to be different. A confidence interval would then be used to fully describe which population mean was greater (or smaller) and by how much. 2.2 Analysis in R 2.2.1 Data Format Data for a 2-sample t-test must be in stacked format, where measurements are in one column and a label for the populations is in another column. Each row corresponds to the measurement and population of a single individual. The data in BOD.csv (data, meta) are the biological oxygen demands (BOD) at the inlet and outlet to an aquaculture facility. These data illustrate stacked data because each row is one water sample with two variables recorded  BOD and where the sample came from. aqua &lt;- read.csv(&quot;BOD.csv&quot;) # Loads the data headtail(aqua) # First and last three rows of the data #R&gt; BOD src #R&gt; 1 6.782 inlet #R&gt; 2 5.809 inlet #R&gt; 3 6.849 inlet #R&gt; 18 8.545 outlet #R&gt; 19 8.063 outlet #R&gt; 20 8.001 outlet Stacked Data: Data where the quantitative measurements of two or more groups are stacked on top of each other and a second variable is used to record to which group (or population) the measurement belongs. Stacked data are required for the methods used in this course. Specific details for performing a 2-sample t-test in R were provided in your introductory statistics course, but will be cursorily reviewed below. 2.2.2 Assumption Checking The meta)data suggests that measurements at the intake and outtake were taken at different times. Thus, there is no reasonable reason to think that BOD measurements are dependent across the two locations. Thus, the independence assumption is met. The sample size is less than 40 but greater than 15. The histograms shown below are not particularly informative because of the small sample size. The histogram for the inlet samples appears to be not strongly skewed, but that for the outlet appears to be strongly right-skewed. I am going to continue with this analysis, but I will be cautious with my final interpretations. ggplot(data=aqua,mapping=aes(x=BOD)) + geom_histogram(binwidth=0.5,boundary=0,color=&quot;black&quot;,fill=&quot;lightgray&quot;) + labs(y=&quot;Frequency of Water Samples&quot;,x=&quot;Biological Oxygen Demand&quot;) + scale_y_continuous(expand=expansion(mult=c(0,0.05))) + theme_NCStats() + facet_wrap(vars(src)) The ggplot2 package is required to make plots with ggplot(). Levenes test is computed with levenesTest() using a formula of response~groups as the first argument, where response represents the name of the quantitative response variable and groups represents the name of the categorical variable that identifies the two populations. The data.frame with the variables must be in data=. From the results below, it is concluded that the population variances appear to be equal because the Levenes test p-value (0.5913) is greater than =0.05. levenesTest(BOD~src,data=aqua) #R&gt; Levene&#39;s Test for Homogeneity of Variance (center = median) #R&gt; Df F value Pr(&gt;F) #R&gt; group 1 0.2989 0.5913 #R&gt; 18 Levenes test requires the NCStats package to be loaded. 2.2.3 Analysis A 2-sample t-test is constructed in R with t.test() using the exact same response~groups formula and data= used in levenesTest(). Additionally, var.equal=TRUE is used when the two population variances should be considered equal. By default t.test() uses a not equals HA and a 95% confidence interval. In the results below the two sample means are 6.6538 for the inlet group and 8.6873 for the outlet group such that the statistic is 6.6538-8.6873=-2.0335; the t test statistic is -8.994 with 18 df; and the p-value is &lt;0.00005 (or, more specifically, 4.449e-08).3 Because the p-value&lt; the H0 is rejected and we conclude that the mean BOD at the inlet is lower than the mean BOD at the outlet. More specifically, the mean BOD at the inlet is between 1.558 and 2.509 units lower than the mean BOD at the outlet. Thus, it appears that the mean BOD in the water is increased from when it enters to when it leaves the aquaculture facility. t.test(BOD~src,data=aqua,var.equal=TRUE) #R&gt; Two Sample t-test with BOD by src #R&gt; t = -8.994, df = 18, p-value = 4.449e-08 #R&gt; alternative hypothesis: true difference in means is not equal to 0 #R&gt; 95 percent confidence interval: #R&gt; -2.508511 -1.558489 #R&gt; sample estimates: #R&gt; mean in group inlet mean in group outlet #R&gt; 6.6538 8.6873 A graphic that illustrates the mean BOD with 95% confidence intervals for each sampling location is constructed below. In the code below you only need to change data= to the name of your data and x= and y= to the names of the explanatory and response variables in the first line and provide appropriate labels for the x- and y-axes in labs(). ggplot(data=aqua,mapping=aes(x=src,y=BOD)) + geom_jitter(alpha=0.5,width=0.05) + stat_summary(fun.data=mean_cl_normal,geom=&quot;errorbar&quot;,size=2,width=0) + stat_summary(fun=mean,geom=&quot;point&quot;,pch=21,fill=&quot;white&quot;,size=2) + labs(x=&quot;Water Sample Location&quot;,y=&quot;Biological Oxygen Demand&quot;) + theme_NCStats() 2.3 Signal-to-Noise The ratio of signal to noise can be a useful metaphor for understanding hypothesis testing, as we have done here, and model comparisons, as we will do in future modules. In this metaphor, think of signal as how different two things are and noise as anything that gets in the way of you receiving the signal. For example, the lights on a care are a signal, but fog on the road is noise (Figure 2.1). As another example, it may be easy to see an orange kayak (the signal) on Lake Superior on a calm day but harder to see it on a wavy day (i.e., more noise; Figure 2.1). Figure 2.1: Signal-to-noise metahpors - seeing car lights through fog (Left) and seeing a kayak in the waves (Right). In a 2-sample t-test, the signal is the difference in the two group means (Figure 2.2), which is measured by \\(\\bar{x}_{1}-\\bar{x}_{2}\\), the numerator of the t-test statistic. The bigger the difference in sample means the stronger the signal that the population means are different. Figure 2.2: Response variable by group for each individual (points) with group means shown as horizontal segments. The difference in sample means is highlighted as the signal in these data. The signal is the difference in sample means Noise is sampling variability, the fact that statistics (e.g., \\(\\bar{x}_{1}\\) and \\(\\bar{x}_{2}\\)) vary from sample to sample. Sampling variability in a 2-sample t-test is measured by \\(SE_{\\bar{x}_{1}-\\bar{x}_{2}}\\), which is the denominator of the t test statistic, or \\(\\sqrt{s_{p}^{2}\\left(\\frac{1}{n_{1}}+\\frac{1}{n_{2}}\\right)}\\). This SE increases with increasing \\(s_{p}^{2}\\) and decreases with increasing n1 and n2. So the noise increases as the (natural) variability of individuals increases (i.e., \\(s_{p}^{2}\\); Figure 2.3), but decreases as the sample size increases. Figure 2.3: Response variable by group for each individual (points) with group means shown as horizontal segments. The variability of individuals around the group means is highlighted as a part of the noise in these data. The noise is sampling variability The ratio of signal to noise is related to whether we will be able to detect the difference between two things or not. If the signal is large relative to the noise then the signal will be detected. In other words, we will be able to see the car lights if the road is not foggy or we will more likely see the kayak if the lake is calm. For example, each panel in Figure 2.4 has the same signal (difference in means) but the noise (i.e., SE) increases from left to right. In the left-most panel it is very clear that the sample means are different (high signal-to-noise ratio), but in the right-most panel it is less clear that the sample means are different (low signal-to-noise ratio). Figure 2.4: Response variable by group for each indiviual (points) with group means shown as horizontal segments for three different standard errors (SE; i.e., noise). Note that the group means are the same in all three panels. The t test statistic is a measure of signal (i.e., difference in sample means) to noise (i.e., sampling variability as measured by the SE) \\[ t=\\frac{\\bar{x}_{1}-\\bar{x}_{2}}{\\sqrt{s_{p}^{2}\\left(\\frac{1}{n_{1}}+\\frac{1}{n_{2}} \\right)}} = \\frac{\\text{Signal}}{\\text{Noise}} \\] Thus, larger values of the t test statistic indicate a larger signal-to-noise ratio. Larger t test statistics are further into the tail of the t distribution and result in smaller p-values. Therefore, small p-values represent larger signal-to-noise ratios and are more likely to lead to concluding that the population means differ. In other words, you were able to detect the signal through the noise. More signal-to-noise means smaller p-values We will return to the signal-to-noise metaphor throughout this course. I usually round my p-values to four decimal places. In this case that would mean 0.0000 which is awkward. Thus, I will say p&lt;0.00005 as the fifth position must have been less than 5 to round to 0.0000. "],["ModelConcepts.html", "Module 3 Model Concepts 3.1 What is a Model 3.2 Assessing Fit (SS) 3.3 Residual Degrees-of-Freedom 3.4 Mean-Squares", " Module 3 Model Concepts 3.1 What is a Model A model is a representation of something or some phenomena. It is usually a simplification or an abstraction that helps our understanding of the more complex reality. A mathematical or statistical model is an equation or system of equations that is meant to characterize the general characteristics of observations. Statistical models do not represent every observation perfectly, rather they attempt to best represent the central tendency of the observations. Weather forecasts are based on mathematical and statistical models. You have observed at least two statistical models in your introductory statistics course  the mean and the regression line (Figure 3.1). Figure 3.1: Two examples of models seen in your introductory statistics course  two means (Left) and regression line (Right). Models can predict an observation but generally not perfectly. For example, weather forecasters predict the temperature for tomorrow but will most likely be off by (hopefully only) a small amount. An observed value of the response variable can be thought of as being equal to a value predicted from a model plus some deviation, or error, from that prediction; i.e., \\[ \\text{Observed Response} = \\text{Model Predicted Response} + \\text{error} \\] For example, tomorrows temperature may be 74oF, which is the predicted 76oF from the forecasters model plus -2oF error. In statistics, one model for predicting the response variable for an individual in a group is to use the mean for the group. My best guess at the height of an unknown student is to guess that they are average for their group. Obviously, most individuals are not truly average, so the specific individual will deviate from the mean. In Figure 3.2 an observation is shown as a red point, the predicted value for that individual is shown as a horizontal line at the mean for the individuals group, and the error from this prediction is shown as the vertical red line. Figure 3.2: Biological oxygen demand versus sample location (points) with group means shown by horizontal segments. The residual from a model that uses a separate mean for both groups is shown. We always predict the response variable with a model. In the context of a simple linear regression, the predicted value is obtained by plugging the observed value of the explanatory variable into the regression equation. Thus, the error is the vertical distance between an observed point and the corresponding point on the line (Figure 3.3). Figure 3.3: Mirex concentration versus fish weight with a simple linear regression line show. The residual from the regression line model is shown. Many hypothesis tests, including the two-sample t-test, can be cast in a framework of competing statistical models. Using this framework requires assessing the relative fit (to data) and complexity of a model. The remainder of this module is about measuring fit and complexity of models. We will discuss fit and formally compare two models to see which is best in the next module. 3.2 Assessing Fit (SS) 3.2.1 A Residual A residual is an estimate of the error discussed in the previous section. If you rearrange the formula shown above and replace error with residual you see that \\[ \\text{residual} = \\text{Observed Response} - \\text{Model Predicted Response} \\] Visually a residual is the vertical distance between a point and the model, as shown by the vertical dashed lines above (or further below). Residuals are vertical distances because they are the difference between two values of the response variable, which is always plotted on the y-axis. Residuals are vertical distances between an observation and the model. Residuals are negative if the point is below the model prediction and positive if the point is above the model prediction. More importantly, the absolute value of the residual is a measure of how close the model prediction is to the point or how well the model fits the individual point. Large residuals (in an absolute value sense) mean that the point is far from the model prediction and, thus, the model does not represent that point very well. Points with small residuals, in contrast, are near the model prediction and are thus well-represented by the model. Figure 3.4 shows points with relatively large residuals in red and relatively small residuals in blue. Figure 3.4: Same plots as previously but with a large residual shown in red and a small residual shown in blue. 3.2.2 Residual Sum-of-Squares If a residual measures how closely a model comes to a point then it stands to reason that the sum of all of the residuals measures how closely a model comes to all of the points. Unfortunately, because residuals are negative and positive they always sum to 0.4 Thus, the sum of all residuals is not a useful measure of the overall fit of a model. Instead of summing residuals, statisticians sum squared residuals into a quantity called a residual sum-of-squares (RSS).5 Using the formula for a residual from above, an RSS for a given set of observed data and a model is computed with \\[ \\text{RSS} = \\sum_{data}\\left(\\text{Observed Response}-\\text{Model Predicted Response}\\right)^2 \\] The RSS measures how closely the model comes to all of the observations. The RSS is on an unfamiliar scale (squared residuals?) but it maintains the same conceptual idea that summing residuals would have. Mainly, the smaller the RSS the more closely the points are to the model. The full set of residuals required to compute an RSS are shown in Figure 3.5. Figure 3.5: Same plots as previously but with all residuals shown. As a value, the RSS is a measure of how poorly the model fits the data  i.e., small values are a good fit, large values are a poor fit. Thus, the RSS is often called a measure of lack-of-fit of the model to the observations. An RSS is a measure of the lack-of-fit of a model to the data. Unfortunately, the magnitude of the RSS is only useful in comparison to other RSS computed for different models from the same data. We will discuss this further in the next module. 3.3 Residual Degrees-of-Freedom You used degrees-of-freedom (df) with t-tests and chi-square tests in your introductory statistics course. However, you likely did not discuss what degrees-of-freedom mean and where they come from. I will discuss this briefly here, but we will use df more in the next module. Residual degrees-of-freedom (Rdf) are the number of observations that are free to vary if the sample size (\\(n\\)) and number of parameters estimated is known. As a simple example, suppose that we know that \\(\\bar{x}\\)=13 from \\(n\\)=4 observations. With just this information can I tell you the values for the four observations that went into \\(\\bar{x}\\)? Clearly I cannot. If you give me one observation can I tell you the remaining three? No! If you tell me two? No! If you tell me three observations can I tell you the last observation? Yes, because the total of the four numbers must be 52 (=\\(n\\bar{x}\\)=4Ã—13); so the last number must be 52 minus the total of the three numbers you told me. In this case, three numbers were free to be any value before the last number was set. Thus, this case has three residual degrees-of-freedom. Residual degrees-of-freedom are more complicated to explain in other situations, but generally \\[ \\text{Rdf}=\\text{Number of Observations}-\\text{Number of Model Parameters} \\] In the example above, there were four observations (n) and one model parameter  \\(\\bar{x}\\)  so df=4-1=3. In Figure 3.1-Left there are 20 observations and two parameters (i.e., two group means) so Rdf=20-2=18. In Figure 3.1-Right there are 122 observations and two parameters (i.e., the slope and intercept of the regression line) so Rdf=122-2=120. As a general rule, parameter estimates are more precisely estimated with more residual degrees-of-freedom. Thus, models that preserve residual degrees-of-freedom (i.e., have fewer parameters) are preferred, all else being equal. 3.4 Mean-Squares Sums-of-squares are useful measures of model fit, but they are largely uninterpretible on their own. However, if a sum-of-squares is divided by its corresponding degrees-of-freedom it is called a Mean-Square (MS). Mean-squares are the variance (i.e., squared standard deviation) of individuals around a given model. Mean-squares have useful mathematical properties as you will see in future modules. However, visually the square root of a mean square loosely describes how far each point is from the model (i.e., the errors), on average. The mean-squares are thus a measure of the noise around each model. MS are variances; thus, the square root of MS are standard deviations Under certain reasonable assumptions. Some statisticans call this an error sum-of-squares or a sum of squared errors (SSE) "],["ModelComparison.html", "Module 4 Model Comparison 4.1 Competing Models 4.2 Measuring Increase in Fit 4.3 Measuring Increase in Complexity 4.4 Noise Variances 4.5 Signal Variance (Benefit-to-Cost) 4.6 Ratio of Variances (Signal-to-Noise) 4.7 ANOVA Table 4.8 Two-Sample t-Test Revisited: Using Linear Models 4.9 One More Look at MS and F-test", " Module 4 Model Comparison 4.1 Competing Models 4.1.1 General Many hypothesis tests can be cast in a framework of competing models. In this module we will cast the familiar 2-sample t-test in this framework which will then serve as a conceptual foundation for all other linear models in this course. The two competing models are generically called the simple and full models (Table 4.1). The simple model is simpler than the full model in the sense that it has fewer parameters. However, the simple model fits the data worse than a full model. Thus, determining which model to use becomes a question of balancing fit (full model fits better than the simple model) with complexity (simple model is less complex than the full model). Because the simple model corresponds to H0 and the full model corresponds to HA, deciding which model to use is the same as deciding which hypothesis is supported by the data. Table 4.1: Differences between the two generic model types. Model Parameters Residual df Relative Fit Residual SS Hypothesis Simple Fewer More Worse Larger Null Full More Less Better Smaller Alternative 4.1.2 2-Sample t-Test Recall that H0 in a two-sample t-test is that the two population means do not differ (i.e., they are equal). In this hypothesis, if the two means do not differ than a single mean would adequately represent both groups. The general model from Section 3.16 could be specified for this situation as \\[ Y_{ij} = \\mu + \\epsilon_{ij} \\] where \\(Y_{ij}\\) is the \\(j\\)th observation of the response variable in the \\(i\\)th group, \\(\\mu\\) is the population grand mean, and \\(\\epsilon_{ij}\\) is the error for the \\(j\\)th observation in the \\(i\\)th group. This model means that  is the predicted response value for each observation and the model looks like the red line in Figure 4.1. Figure 4.1: Biological oxygen demand versus sample location with group means shown as blue horizontal segments and the grand mean shown as a red horizontal segment. In contrast, HA in the 2-sample t-test is that the two population means differ (i.e., they are not equal). This hypothesis suggests that two separate means are needed to predict observations in the separate groups. The model for this situation is \\[ Y_{ij} = \\mu_{i} + \\epsilon_{ij} \\] where \\(\\mu_{i}\\) is the population mean for the \\(i\\)th group. This model means that \\(\\mu_{1}\\) is the predicted response value for observations in the first group and \\(\\mu_{2}\\) is the predicted response value for observations in the second group. This model looks like the two blue lines in the figure above. Thus, for a 2-sample t-test, the simple model corresponds to H0: \\(\\mu_{1}=\\mu_{2}\\) (=\\(\\mu\\)), has fewer parameters (i.e., requires only one mean; the red line in the plots above), and fits worse.7 In contrast, the full model corresponds to HA: \\(\\mu_{1}\\ne\\mu_{2}\\), has more parameters (i.e., requires two means; the blue lines in the plots above), and fits better. In the ensuing sections we will develop a method to determine if the increase in fit is worth the increase in complexity. 4.2 Measuring Increase in Fit 4.2.1 SSTotal and SSWithin In Section 3.2.2 the idea of using the residual sum-of-squares (RSS) to measure the lack-of-fit of a model was introduced. Here we apply that concept to measure the lack-of-fit of the simple and full models, which we will then use to see how much better the full model fits than the simple model. Remember that the full model will always fit better than the simple model, even if by just a small amount. The RSS for the simple model using just the grand mean is called SSTotal and is computed with \\[ \\text{SS}_{\\text{Total}} = \\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}\\left(Y_{ij}-\\bar{Y}_{\\cdot\\cdot}\\right)^{2} \\] where \\(I\\) is the number of groups (=2 in a 2-sample t-test), \\(n_{i}\\) is the sample size in the \\(i\\)th group, and \\(\\bar{Y}_{\\cdot\\cdot}\\) is the sample grand mean as computed with \\[ \\bar{Y}_{\\cdot\\cdot}= \\frac{\\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}Y_{ij}}{n} \\] where \\(n\\) is the sample size across all groups. The \\(\\bar{Y}_{\\cdot\\cdot}\\) is used here because it is an estimate of the population grand mean, \\(\\mu\\), which is used to make predictions in this simple model. The formula for SSTotal may look daunting but it is just the sum of the squared residuals computed from each observation relative to the grand mean (Figure 4.2). Figure 4.2: Biological oxygen demand versus sample location with the grand mean shown as a red horizontal segment. Residuals from the grand mean are shown by red vertical dashed lines. The sum of these residuals is SSTotal. The RSS for the full model using separate group means is called SSWithin and is computed with \\[ \\text{SS}_{\\text{Within}} = \\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}\\left(Y_{ij}-\\bar{Y}_{i\\cdot}\\right)^{2} \\] where \\(\\bar{Y}_{i\\cdot}\\) are the sample group means as computed with \\[ \\bar{Y}_{\\cdot\\cdot} = \\frac{\\sum_{j=1}^{n_{i}}Y_{ij}}{n_{i}} \\] The \\(\\bar{Y}_{i\\cdot}\\) are used here because they are an estimate of the population group means, \\(\\mu_{i}\\), which are used to make predictions in this full model. Again, the formula for SSWithin may look imposing but it is just the sum of the squared residuals computed from each observation to the observations group mean (Figure 4.3). Figure 4.3: Biological oxygen demand versus sample location with the group means shown as blue horizontal segments. Residuals from the group means are shown by blue vertical dashed lines. The sum of these residuals is SSWithin. Thus, SSTotal measures the lack-of-fit of the grand mean to the data or the lack-of-fit of the simple model. SSWithin, in contrast, measures the lack-of-fit of the group means to the data or the lack-of-fit of the full model. In this example, SSTotal=25.28 and SSWithin=4.60. Because SSWithin is less than SSTotal that means that the full model that uses i fits the data better than the simple model that uses just \\(\\mu\\). However, we knew that this was going to happen as the full model always fits better. What we need now is a measure of how much better the full model fits or, equivalently, a measure of how much the lack-of-fit was reduced by using the full model rather than the simple model. 4.2.2 SSAmong An useful property of SSTotal is that it partitions into two parts according to the following simple formula \\[ \\text{SS}_{\\text{Total}} = \\text{SS}_{\\text{Within}} + \\text{SS}_{\\text{Among}} \\] This introduces a new quantity, SSAmong. A quick re-arrangement of the partitioning of SSTotal shows that \\[ \\text{SS}_{\\text{Among}} = \\text{SS}_{\\text{Total}} - \\text{SS}_{\\text{Within}} \\] Thus, SSAmong records how much the lack-of-fit was reduced by using the full model rather than the simple model. In other words, SSAmong records how much better the full model fits the data than the simple model. In our example, SSAmong=25.28-4.60=20.68. Thus, the residual SS from the simple model was reduced by 20.68 when the full model was used. SSAmong is the benefit (i.e., reduction in lack-of-fit) of using the full rather than simple model SSAmong can also be thought of in a different way. It can be algebraically shown that \\[ \\text{SS}_{\\text{Among}} = \\sum_{i=1}^{I}n_{i}\\left(\\bar{Y}_{i\\cdot}-\\bar{Y}_{\\cdot\\cdot}\\right)^{2} \\] Again, this looks complicated, but the main part to focus on is \\(\\bar{Y}_{i\\cdot}-\\bar{Y}_{\\cdot\\cdot}\\), which shows that SSAmong is primarily concerned with measuring the distance between the group means (i.e., \\(\\bar{Y}_{i\\cdot}\\)) and the grand mean (i.e., \\(\\bar{Y}_{\\cdot\\cdot}\\); Figure 4.4). Figure 4.4: Mean biological oxygen demand versus sample location with the grand mean shown as a red horizontal segment and the group means shown as blue horizontal segments. Residuals between the group means and the grand mean are shown by black vertical dashed lines. The sum of these residuals scaled by the group sample sizes is SSAmong. From the figure above, it is seen that SSAmong will increase as the group means become more different. In other words, SSAmong measures the signal in the data. SSAmong is the signal (i.e., relative difference in group means) in the data This can be seen in the interactive graphic below. You can adjust the amount of signal in the data by increasing or decreasing the difference between the group means and the grand mean. As you do this note how SSAmong (and SSTotal) change. So, SSAmong is immensely useful  it is a measure of benefit that will be used in a benefit-to-cost ratio and it is the signal that will be used in a signal-to-noise ratio. These ratios are discussed further below. Next we discuss how to measure the cost of using the more complex full model. 4.3 Measuring Increase in Complexity In this example, dfTotal=20-1 because there is one parameter (the grand mean) in the simple model, and dfWithin=20-2 because there are two parameters (the group means) in the full model. The full model uses more parameters and, thus, the residual degrees-of-freedom is reduced  there is a cost to using the full model over the simple model. We need a measure of this cost.8 Interestingly dfTotal partitions in the same way as SSTotal; i.e., \\[ \\text{df}_{\\text{Total}} = \\text{df}_{\\text{Within}} + \\text{df}_{\\text{Among}} \\] This introduces another new quantity, dfAmong. A quick re-arrangement of the partitioning of dfTotal shows that \\[ \\text{df}_{\\text{Among}} = \\text{df}_{\\text{Total}} - \\text{df}_{\\text{Within}} \\] In this case, dfAmong=19-18=1. Thus, dfAmong is the degrees-of-freedom that were lost or used when the more complicated full model was used compared to the simpler simple model. The dfAmong is also the difference in number of parameters between the full and simple models. In other words, dfAmong is how much more complex (in terms of number of parameters) the full model is compared to the simple model. Thus, dfAmong measures the cost of using the full model rather than the simple model. dfAmong is the extra cost (i.e., loss of df) from using the full rather than simple model 4.4 Noise Variances MSTotal and MSWithin are measures of the variance9 of individuals around the grand mean and group means, respectively. Thus, MSTotal measures the variance or noise around the full model, whereas MSWithin measures the variance or noise around the simple model. MSTotal and MSWithin measure noise  i.e., variability of observations around a model Before moving on to discuss MSAmong, it is worth noting that MSTotal is \\[ \\text{MS}_{\\text{Total}} = \\frac{\\text{SS}_{\\text{Total}}}{\\text{df}_{\\text{Total}}} = \\frac{\\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}\\left(Y_{ij}-\\bar{Y}_{\\cdot\\cdot}\\right)^{2}}{n-1} \\] Realizing that the double summation simply means to sum across all individuals it is seen that this is the variance (\\(s^{2}\\)) from your introductory statistics course. In other words it is just the variability of the individuals around a mean that ignores that there are groups. MSTotal=\\(s^{2}\\) Similarly, MSWithin is \\[ \\text{MS}_{\\text{Within}} = \\frac{\\text{SS}_{\\text{Within}}}{\\text{df}_{\\text{Within}}} = \\frac{\\sum_{i=1}^{I}\\sum_{j=1}^{n_{i}}\\left(Y_{ij}-\\bar{Y}_{i\\cdot}\\right)^{2}}{\\sum_{i=1}^{I}n_{i}-I} \\] It is not hard to show algebraically (and for just two groups) that the numerator is \\(n_{1}s_{1}^{2}+n_{2}s_{2}^{2}\\) and that the denominator is \\(n_{1}+n_{2}-2\\). This numerator and denominator are then simply the pooled sample variance (\\(s_{p}^{2}\\)) from the 2-sample t-test. Thus, MSWithin with two groups is the same as \\(s_{p}^{2}\\) from the 2-sample t-test. MSWithin=\\(s_{p}^{2}\\) 4.5 Signal Variance (Benefit-to-Cost) Of course SSAmong divided by dfAmong will be MSAmong. However, while MSAmong is still a variance, it has a very different interpretation. MSAmong is NOT a variance of individuals, rather it is a variance of sample means. Sample means can vary (i.e., not be equal) for two reasons  purely due to random sampling variability (i.e., the population means are not different) or the population means really do differ such that the sample means differ. In other words, MSAmong  the variance among means  is a combination of noise and signal. Our goal (next) is to disentangle these two reasons for why the sample means differ to determine if there is a real signal or not. Additionally, MSAmong is a ratio of the benefit (i.e., SSAmong) to the cost (i.e., dfAmong) of using the full model over the simple model. So MSAmong scales the benefit to the cost of using the full model. 4.6 Ratio of Variances (Signal-to-Noise) From the above discussion we have a measure of potential signal in MSAmong and actual noise around the full model (the model representing the signal) in MSWithin. The ratio of this signal to noise is called an F test statistic; i.e., \\[ \\text{F}=\\frac{\\text{MS}_{\\text{Among}}}{\\text{MS}_{\\text{Within}}} = \\frac{\\text{Signal}}{\\text{Noise}} = \\frac{\\text{Variance Explained by Full Model}}{\\text{Variance Unexplained by Full Model}} \\] If the F-ratio is large, then a great deal more variability was explained (i.e., more signal) than was unexplained by the full model (i.e., less noise) and one would conclude that the full model fits the data significantly better than the simple model, even considering the increased complexity of the full model. The question now becomes when is the F-ratio considered large enough to reject the simple model and conclude that the full model is significantly better? This question can by comparing the F-ratio test statistic to an F-distribution. An F-distribution10 is right-skewed, with the exact shape of the distribution dictated by two separate degrees-of-freedom  called the numerator and denominator degrees-of-freedom, respectively. The numerator df is equal to the df used in MSAmong, whereas the denominator df is equal to the df used in MSWithin. The p-value is always computed as the area under the F-distribution curve to the right of the observed F-ratio test statistic.11 The p-value is always computed to the right on an F-distribution. From this it can be seen that a small p-value comes from a large F-ratio, which comes from a large MSAmong relative to MSWithin, which means both that the full model explains more variability than is left unexplained and the signal is much greater than the noise, which means that the full model does fit significantly better than the simple model (even given the increased complexity), and, thus, the means are indeed different, which is what we would conclude from a small p-value. This cascade of measures can be explored with the dynamic graphic below. 4.7 ANOVA Table The degrees-of-freedom (df), sum-of-squares (SS), mean-squares (MS), F-ratio test statistic (F), and corresponding p-value are summarized in what is called an analysis of variance (ANOVA) table.12 The ANOVA table contains rows that correspond to the different measures discussed above: among,13 within,14 and total. The df and SS are shown for each source, but the MS is shown only for the within and among sources because MSAmong+MSWithinMSTotal. SS and df partition, but MS do not! Do not add MSAmong and MSWithin to get MSTotal, instead divide SSTotal by dfTotal. An ANOVA table for the BOD measurements at the inlet and outlet sources to the aquaculture facility is in Table 4.2. Note that R does not show the total row that most softwares do. Table 4.2: An ANOVA table for biological oxygen demand measurements at two locations of the aquaculture facility. Note that the Total row is not shown. Df Sum Sq Mean Sq F value Pr(&gt;F) src 1 20.6756 20.6756 80.8912 0 Residuals 18 4.6008 0.2556 These results indicate that H0 should be rejected (i.e., F-test p-value &lt;0.00005). Thus, the full model fits the data significantly better than the simple model even given the difference in complexity between the two models and sampling variability. Therefore, there is a significant difference in mean BOD between the two locations. In addition to the primary objective of comparing the full and simple models, several items of interest can be identified from an ANOVA table. Using the table above as an example, note the following items: The variance within groups is equal to MSWithin (e.g., MSResiduals=0.2556 in this case). This is \\(s_{p}^{2}\\) from the two-sample t-test (because there are only two groups here). The common variance about the mean (\\(s^{2}\\)) is given by MSTotal (e.g., \\(=\\frac{20.6756+4.6008}{1+18}\\)=1.3303). 4.8 Two-Sample t-Test Revisited: Using Linear Models The models for a two-sample t-test can be fit and assessed with lm(). This function requires the same type of formula for its first argument  response~factor  and a data.frame in the data= argument as described for t.test() in Section 2.2. The results of lm() should be assigned to an object so that specific results can be selectively extracted from it. For example, the ANOVA table results are extracted from the lm() object with anova(). In addition, coefficient results15 can be extracted with coef(), confint(), and summary(). Note that I like to column-bind the coefficients and confidence intervals together for a more succinct representation. aqua.lm &lt;- lm(BOD~src,data=aqua) anova(aqua.lm) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: BOD #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; src 1 20.6756 20.6756 80.891 4.449e-08 #R&gt; Residuals 18 4.6008 0.2556 cbind(ests=coef(aqua.lm),confint(aqua.lm)) #R&gt; ests 2.5 % 97.5 % #R&gt; (Intercept) 6.6538 6.317917 6.989683 #R&gt; srcoutlet 2.0335 1.558489 2.508511 From these results, note: The p-value in the ANOVA table is the same as that computed from t.test(). The coefficient for srcoutlet is the same as the difference in the group means computed with t.test(). The F test statistics in the ANOVA table equals the square of the t test statistic from t.test(). This is because an F with 1 numerator and v denominator df exactly equals the square of a t with v df. Thus, the exact same results for a two-sample t-test are obtained whether the analysis is completed in the traditional manner (i.e., with t.test()) or with competing models (i.e., using lm()). This concept will be extended in subsequent modules. 4.9 One More Look at MS and F-test Recall from your introductory statistics course that a sampling distribution is the distribution of a statistic from all possible samples. For example, the Central Limit Theorem states that the distribution of sample means is approximately normal, centered on , with a standard error of \\(\\frac{\\sigma}{\\sqrt{n}}\\) as long as assumptions about the sample size are met. Further recall that the sampling distribution of the sample means is centered on  because the sample mean is an unbiased estimator of . Similarly, it is also known that the center of the sampling distribution of \\(s^{2}\\) is equal to \\(\\sigma^{2}\\) because \\(s^{2}\\) is an unbiased estimate of \\(\\sigma^{2}\\). MSWithin and MSAmong are statistics just as \\(\\bar{x}\\) and \\(s^{2}\\) are statistics. Thus, MSWithin and MSAmong are subject to sampling variability and have sampling distributions. It can be shown16 that the center of the sampling distribution of MSWithin is \\(\\sigma^{2}\\) and the center of the sampling distribution of MSAmong is \\[ \\sigma^{2} + \\frac{1}{I-1}\\sum_{i=1}^{I}n_{i}\\left(\\mu_{i}-\\mu\\right)^{2} \\] Thus, MSAmong consists of two sources of variability. The first source (\\(\\sigma^{2}\\)) is the natural variability that exists among individuals. The second source \\(\\left(\\frac{1}{I-1}\\sum_{i=1}^{I}n_{i}\\left(\\mu_{i}-\\mu\\right)^{2}\\right)\\) is related to differences among the group means. Therefore, if the group means are all equal  i.e., \\(\\mu_{1}\\)=\\(\\mu_{2}\\)= \\(\\cdots\\) = \\(\\mu_{I}\\) = \\(\\mu\\)  then the second source of variability is equal to zero and MSAmong will equal MSWithin. As soon as the groups begin to differ, the second source of variability will be greater than 0 and MSAmong will be greater than MSWithin. From this, it follows that if the null hypothesis of equal population means is true (i.e., one mean fits all groups), then the center of the sampling distribution of both MSWithin and MSAmong is \\(\\sigma^{2}\\). Therefore, if the null hypothesis is true, then the F test-statistic is expected to be equal to 1, on average, which will always result in a large p-value and a DNR H0 conclusion. However, if the null hypothesis is false (i.e., separate means are needed for all groups), then the center of the sampling distribution of MSWithin is \\(\\sigma^{2}\\) but the center of the sampling distribution of MSAmong is \\(\\sigma^{2}\\) + something, where the something is greater than 0 and gets larger as the means become more different. Thus, if the null hypothesis is false then the F test-statistic is expected to be greater than 1 and will get larger as the null hypothesis gets more false. This analysis of sampling distribution theory illustrates once again that (1) MSAmong consists of multiple sources of variability and (2) large values of the F test-statistic indicate that the null hypothesis is incorrect. Generally, Observation = Model Prediction + Error We will be more objective in the following sections, but an examination of the plot above clearly shows that the red line does not represent the observations well. The cost is obviously 1 in this simple case. As discussed in Section 3.4, SS are not true variances until they are divided by their df and become mean-squares (MS). An F-distribution occurs whenever the ratio of two variances is calculated. If the F-ratio is computed by hand, then distrib() with distrib=\"f\", df1=, df2=, and lower.tail=FALSE may be used to calculate the corresponding p-value. An ANOVA table does not necessarily mean that an analysis of variance method was used. It turns out that all general linear models are summarized with an ANOVA table, regardless of whether a one- or two-way ANOVA method was used. Labeled as the factor variable in most statistical software packages including R  that variable was called src in this example. Labeled as residuals in R and error in other statistical software packages. The coefficient results will be discussed in more detail in Module 5. This derivation is beyond the scope of this course. "],["ANOVA1Foundations.html", "Module 5 One-Way Foundations 5.1 Analytical Foundation 5.2 One-Way ANOVA in R", " Module 5 One-Way Foundations Many studies, including the following examples, result in the comparison of means from more than two independent populations. Determine if the mean volume of white blood cells of Virginia opossums (Didelphis virginiana) differed by season in the same year (Woods and Hellgren 2003). Determine if the mean frequency of occurrence of badgers (Meles meles) in plots differs between plots at different locations (Virgos and Casanovas 1999). Test for differences in the mean total richness of macroinvertebrates between the three zones of a river (Grubbs and Taylor 2004). Test if the mean mass of porcupines (Erithizon dorsatum) differs among months of summer (Sweitzer and Berger 1992). Test if the mean clutch size of spiders differs among three types of parental care categories (Simpson 1995). Determine if the mean age of harvested deer (Odocoelius virginianus) differs among Ashland, Bayfield, Douglas, and Iron counties. In each of these situations, the mean of a quantitative variable (e.g., age, frequency of occurrence, total richness, or body mass) is compared among two or more populations of a single factor variable (e.g., county, locations, zones, or season). A 2-sample t-test cannot be used in these situations because more than two groups are compared. A one-way analysis of variance (or one-way ANOVA) is simply an extension of a 2-sample t-test and can be used for each of these situations.17 A one-way analysis of variance (ANOVA) is used to determine if a significant difference exists among the means of more than two populations. In this module, we examine the immunoglobulin18 measurements of opossums (imm) during three months of the same year (season). The data are loaded into R and a subset of rows is shown below. opp &lt;- read.csv(&quot;Opossums.csv&quot;) head(opp) #R&gt; imm season #R&gt; 1 0.640 feb #R&gt; 2 0.680 feb #R&gt; 3 0.731 feb #R&gt; 4 0.587 feb #R&gt; 5 0.668 feb #R&gt; 6 0.613 feb Data must be stacked!! 5.1 Analytical Foundation The generic null hypothesis for a one-way ANOVA is \\[ \\text{H}_{\\text{0}}: \\mu_{1} = \\mu_{2} = \\ldots = \\mu_{I} \\] where \\(I\\) is the total number of groups or populations.19 The alternative hypothesis is complicated because not all pairs of means need differ for the null hypothesis to be rejected. Thus, the alternative hypothesis for a one-way ANOVA is wordy and is often written as \\[ \\text{H}_{\\text{A}}:\\text{At least one pair of means is different} \\] A rejection of H0 in favor of HA is a statement that some difference in group means exists. It does not clearly indicate which group means differ. Methods to identify which group means differ are in Module 6. Rejecting H0 just means that some group means differ. The simple (\\(Y_{ij} = \\mu + \\epsilon_{ij}\\)) and full (\\(Y_{ij} = \\mu_{i} + \\epsilon_{ij}\\)) models for the one-way ANOVA are the same as those for the 2-sample t-test, except that there are \\(I\\)&gt;2 means in the full model. Thus, SStotal, SSwithin, and SSamong are computed using the same formulae shown in Module 4, except to again note that \\(I\\)&gt;2. The degrees-of-freedom are also computed similarly  i.e., dfWithin=\\(n\\)-\\(I\\) and dfAmong=\\(I\\)-1. The MS, F, and p-value are also computed in the same way.20 A 2-Sample t-Test is simply a special case of a One-Way ANOVA. Figure ?? is a visual for simple and full models and residuals from each. Note the similarity with figures from the Module 4, except that there are three group means here. Figure 5.1: Immunoglobulin concentrations versus season (or month) of capture for New Zealand opposums. The grand mean is shown by a red horizontal segment, group means are shown by blue horizontal segments, residuals from the grand mean are red vertical dashed lines, residuals from the groups means are blue vertical dashed lines, and differnces between the group means and the grand mean are black vertical dashed lines. Figure 5.2: Immunoglobulin concentrations versus season (or month) of capture for New Zealand opposums. The grand mean is shown by a red horizontal segment, group means are shown by blue horizontal segments, residuals from the grand mean are red vertical dashed lines, residuals from the groups means are blue vertical dashed lines, and differnces between the group means and the grand mean are black vertical dashed lines. Figure 5.3: Immunoglobulin concentrations versus season (or month) of capture for New Zealand opposums. The grand mean is shown by a red horizontal segment, group means are shown by blue horizontal segments, residuals from the grand mean are red vertical dashed lines, residuals from the groups means are blue vertical dashed lines, and differnces between the group means and the grand mean are black vertical dashed lines. An ANOVA table (Table 5.1) is used to display the results from a one-way ANOVA, because the one-way ANOVA is simply a comparison of two models. Table 5.1: An ANOVA table for immunoglobuling concentration by season (or month) for New Zealand opossums. Note that the Total row is not shown. Df Sum Sq Mean Sq F value Pr(&gt;F) season 2 0.2340 0.1170 14.4486 1e-04 Residuals 24 0.1944 0.0081 In addition to the usual meanings attached to MSAmong, MSAmong, and MSTotal,21 the following can be discerned from this ANOVA table. dfAmong=2 and because dfAmong=\\(I\\)-1, then \\(I\\)=3. This confirms that there are three groups in this analysis. dfTotal=dfAmong+dfWithin=2+24=26. Because dfTotal=\\(n\\)-1, then \\(n\\)=27. This shows that there are 27 individuals in this analysis. There is a significant difference in the mean immunoglobulin values among the three months because the p-value=0.0001&lt;. 5.2 One-Way ANOVA in R The models for a one-way ANOVA are fit and assessed with lm() exactly as described for a 2-sample t-test in Section 4.8. As a reminder, a formula of response~factor is the first argument and a data.frame is given in data= in lm(), the results of lm() should be assigned to an object, and the ANOVA table is extracted with anova(). The lm() code is the same for a 2-Sample t-Test and a One-Way ANOVA. lm1 &lt;- lm(imm~season,data=opp) anova(lm1) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: imm #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; season 2 0.23401 0.117005 14.449 7.609e-05 #R&gt; Residuals 24 0.19435 0.008098 A graphic that illustrates the mean immunoglobulin value with 95% confidence intervals for each month is constructed below (as shown in Section 2.2). ggplot(data=opp,mapping=aes(x=season,y=imm)) + geom_jitter(alpha=0.5,width=0.05) + stat_summary(fun.data=mean_cl_normal,geom=&quot;errorbar&quot;,size=2,width=0) + stat_summary(fun=mean,geom=&quot;point&quot;,pch=21,fill=&quot;white&quot;,size=2) + labs(y=&quot;Immunoglobulin Concentration&quot;,x=&quot;Season/Month&quot;) + theme_NCStats() This and the next several modules depends heavily on the foundational material in Modules 1-4, especially the concepts of simple and full models; signal and noise; variances explained and unexplained; and SS, MS, F, and p-values. Any of a class of proteins present in the serum and cells of the immune system, which function as antibodies. From this, it is evident that the one-way ANOVA is a direct extension of the 2-sample t-test. The MS, F, and p-value are computed the same in nearly every ANOVA table encountered in this class. Note that MSTotal must be computed from SSTotal and dfTotal and not by summing MSAmong an MSWithin. "],["ANOVA1MultipleComparisons.html", "Module 6 One-Way Multiple Comparisons 6.1 Multiple Comparison Problem 6.2 Correction Methods 6.3 Multiple Comparisons in R", " Module 6 One-Way Multiple Comparisons A significant result (i.e., reject H0) in a one-way ANOVA indicates that the means of at least one pair of groups differ. It is not yet known whether all means differ, all but two means differ, only one pair of means differ, or any other possible combination of differences. Thus, specific follow-up analyses to a significant one-way ANOVA are needed to identify which pairs of means are significantly different. A significant one-way ANOVA only indicates that at least one pair of means differ. Follow-up analyses are required to determine which pairs differ. 6.1 Multiple Comparison Problem The most obvious solution to identify which pairs of means differ is to perform a 2-sample t-test for each pair of groups. Unfortunately, this seemingly simple answer has at least two major problems. First, the number of 2-sample t-tests needed increases dramatically with increasing numbers of groups. Second, the probability of incorrectly concluding that at least one pair of means differs when no pairs actually differ increases dramatically with increasing numbers of groups. Of these two issues, the second is much more problematic and needs to be better understood. In any one comparison of two means the probability of incorrectly concluding that the means are different when they are actually not different is . This incorrect conclusion is called a pairwise Type I error because it relates to only one comparison of a pair of means. In a situation with three (\\(I\\)=3) groups (say A, B, C) then there are three pairwise comparisons (\\(k\\)=3) to be made (A to B, A to C, and B to C). A pairwise error could be made on any of these three tests. Making a Type I error on at least one of these multiple pairwise tests is called an experiment-wise Type I error because it involves all pairwise comparisons in the experiment at hand. It is important that you notice at least in the definition of the experiment-wise error rate. For example, in three comparisons, the incorrect conclusion could be for the first pair, the second pair, the third pair, the first and second pair, the first and third pair, the second and third pair, or all three pairs!! A Type I error is rejecting H0 when H0 is actually true. In a two-sample t-test, a Type I error is concluding that two means are significantly different when they are not different. Pairwise error rate: The probability of a Type I error in a single comparison of two means. Sometimes called an comparison-, individual-, or test-wise error. Experiment-wise error rate: The probability of at least one Type I error in a set of comparisons of two means. Sometimes called the family-wise error. Figure 6.1 demonstrates the two issues related to multiple comparisons. First, the x-axis labels show how the number of pairwise comparisons (\\(k\\)) increases quickly with increasing number of groups (\\(I\\)) in the study. For example, six groups (\\(I\\)=6) is not a complicated study, but it results in fifteen pairwise comparisons (\\(k\\)=15). More importantly the line and point labels in the figure show how the experiment-wise error rate increases quickly and dramatically with increasing number of groups. For example, the experiment-wise error rate for six (\\(I\\)=6) groups is over 0.50.22 Thus, it is nearly a coin flip that at least one error will be made in all paired comparisons among six groups. Making an error more than 50% of the time in such a simple study is not acceptable and must be corrected. Figure 6.1: Relationship between the number of groups (I) in an analysis, the number of pairs of means that would need to be tested (k), and the probability of making one or more Type I errors in all comparisons. Note that alpha=0.05. The experiment-wise error rate increases dramatically with increasing numbers of treatment groups. 6.2 Correction Methods There are many procedures designed to attempt to control experiment-wise error rate at a desired level (usually ). You will here a variety of names like Tukeys HSD, Bonferronis adjustment, Sidaks method, and Scheffes method.23 For simplicity, only the Tukey-Kramer honestly significantly different (i.e., Tukeys HSD or Tukeys) method will be used here. As simplistically as possible, Tukeys test computes the t test statistic for each pair of means as if conducting a 2-sample t-test. However, this test statistic is compared to a Studentized range rather than a t distribution to compute the p-value. These adjusted p-values are then simply compared to  to make a decision about the means of each pair. The net result of this modification however is that the experiment-wise error rate across all comparisions is controlled at the desired level when the group sample sizes are equal and is slightly conservative when the group sample sizes are different. 6.3 Multiple Comparisons in R Tukeys procedure should only be implemented if multiple comparisons are needed!! In other words, only use this method following a significant One-Way ANOVA result; i.e., H0 was rejected such that it appears that there is some difference among group means. Therefore, a One-Way ANOVA must be performed first as described in Section 5.2. The ANOVA table from the analysis of immunoglobulin levels in opossums across seasons that was begun in the Module 5 is shown below. lm1 &lt;- lm(imm~season,data=opp) anova(lm1) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: imm #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; season 2 0.23401 0.117005 14.449 7.609e-05 #R&gt; Residuals 24 0.19435 0.008098 Once again, there appears to be some significant difference in the mean immunoglobulin values among the three months (0.0001&lt;). Thus, a multiple comparisons procedure is warranted here to identify exaclty which pairs of means differ. There are a number of functions and packages in R for computing Tukeys multiple comparisons. I prefer to use functions in the emmeans package because those functions will generalize to other methods, some of which we will use in other modules and some of which you may use in more advanced statistics courses. The emmeans package must be attached with library() before its functions can be used. The emmeans package must be attached with library to perform Tukeys procedure. library(emmeans) Tukeys procedure is computed with a two-step process. First, use emmeans() with the lm() object as the first argument and a specs= argument with pairwise~ followed by the name of the variable that identifies the groups. The results from this function should be saved to an object. mc &lt;- emmeans(lm1,specs=pairwise~season) That saved object is then the first argument to summary(), which also uses infer=TRUE. This again should be saved to an object. ( mcsum &lt;- summary(mc,infer=TRUE) ) #R&gt; $emmeans #R&gt; season emmean SE df lower.CL upper.CL t.ratio p.value #R&gt; feb 0.668 0.0260 24 0.614 0.721 25.702 &lt;.0001 #R&gt; may 0.724 0.0340 24 0.654 0.795 21.299 &lt;.0001 #R&gt; nov 0.491 0.0318 24 0.425 0.557 15.433 &lt;.0001 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; #R&gt; $contrasts #R&gt; contrast estimate SE df lower.CL upper.CL t.ratio p.value #R&gt; feb - may -0.0568 0.0428 24 -0.1636 0.0501 -1.326 0.3948 #R&gt; feb - nov 0.1767 0.0411 24 0.0741 0.2792 4.301 0.0007 #R&gt; may - nov 0.2334 0.0466 24 0.1171 0.3497 5.012 0.0001 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 3 estimates #R&gt; P value adjustment: tukey method for comparing a family of 3 estimates The results are in two sections labeled as $emmeans and $contrasts. The $contrasts section contains the actual Tukeys test for each pair of means. In these results the difference in group sample means is under estimate, a 95% confidence interval for the difference in means is under lower.CL and upper.CL, and a p-value for testing that the difference in group population means is 0 is under p.value. For example, the difference in group sample mean immunoglobulin between February and May is -0.0568, but the p-value suggests that the population mean immunoglobulin does not differ between February and May (p=0.3948). In contrast, it appears that the population mean immunoglobulin for opossums in November differed from both those in Feb (p=0.0007) and those in May (p=0.0001). The difference of group means with 95% confidence intervals and p-values are shown in the $contrasts section of the results. The $emmeans section contains the group sample means under emmean with 95% confidence intervals under lower.CL and upper.CL. For example, the sample mean immunoglobulin level for opossums in February was 0.668, with a 95% confidence interval from 0.614 to 0.721. The t.ratio and p.value in this section tests if the group population mean is different than 0. These tests are not often of interest and can largely be ignored. The group means with 95% confidence intervals are shown in the $emmeans section of the results. A plot of group means with 95% confidence intervals using the results in $emmeans is slightly different than shown in Sections 4.8 and 5.2 because the raw data and the means with their confidence intervals are in separate data frames. While this method is slightly more complicated, it will generalize to a wider variety of situationst throughout the course. The data= and mapping=aes() arguments are not included in the initial ggplot() because we will be drawing variables from two data frames. Thus, geom_jitter() below adds the raw data to the plot, jittered to decrease overlap; geom_errorbar() creates the error bars from the $emmeans object, and geom_point() simply overlays the mean from the $emmeans object. Note that in the code below you would only need to modify the two data= arguments, the three x= arguments (to the grouping variables), and the one y= argument in geom_jitter() (to the response variable). ggplot() + geom_jitter(data=opp,mapping=aes(x=season,y=imm), alpha=0.25,width=0.05) + geom_errorbar(data=mcsum$emmeans, mapping=aes(x=season,ymin=lower.CL,ymax=upper.CL), size=2,width=0) + geom_point(data=mcsum$emmeans,mapping=aes(x=season,y=emmean), size=2,pch=21,fill=&quot;white&quot;) + labs(y=&quot;Immunoglobulin Concentration&quot;,x=&quot;Season/Month&quot;) + theme_NCStats() Using =0.05 See here for a short list of methods. "],["ANOVA1Assumptions.html", "Module 7 One-Way Assumptions 7.1 Independence 7.2 Equal Variances 7.3 Normality 7.4 No Outliers 7.5 Testing Assumptions in R", " Module 7 One-Way Assumptions As with most statistical methods, the One-Way ANOVA requires that four assumptions be met so that the calculations made in Modules 5 and 6 mean what we said they would mean. The four assumptions for a One-Way ANOVA are:24 independence of individuals within and among groups, equal variances among groups, normality of residuals within each group, and no outliers Each of these assumptions in more detail below. 7.1 Independence In a One-Way ANOVA the individuals must be independent both within and among groups. In other words, there must be no connection between individuals within a group or between individuals in one group and individuals in other groups. Independence of individuals is a critical assumption of one-way ANOVAs. Violations of this assumption cannot be corrected. A lack of independence may include applying multiple treatments to the same individual, having related individuals either within the same group or specifically spread across the groups, or having individuals that are not separated in space or time. Below are examples where there was a lack of independence. Researchers measured the self-esteem at three time points  beginning, middle, and end  for 10 people following a specific diet. They wanted to determine if self-esteem increased over the time that individuals were on the diet. This example illustrates a lack of among-group independence because the same 10 people were in each of the groups (i.e., beginning, middle, and end time period). Zoo keepers were interested in whether the activity rate of lions differed by time of day. For this study, they recorded the activity rate of all five lions at the same random times in the morning, afternoon, evening, and night across several days. This example illustrates a lack of among-group independence because the same lions were recorded in each period. This also illustrates a lack of within-group independence because the activity rates were recorded at the same times for each lion. Thus, the lions may be affecting each others activity rates. For example, if one lion gets up to roam around then the other lions may be more likely to get up to roam around as well. Researchers with the LoonWatch program wanted to determine if mean density of loons differs among Bayfield, Ashland, and Iron counties. For this they asked local volunteers to record the number of loons they observed on several lakes during the same weekend in June. This example illustrates a lack of within-group independence as different observers were used in each county. It is possible that the observers in one county are more adept at observing loons on their lakes (for whatever reason  they know their lakes better, their lakes are smaller, they are more motivated, they spend more time). There are methods to detect violations of the independence assumption if the assumption is related to time (e.g., the first situation above), but for most other situations a violation is only detected by careful consideration of the design of the data collection. Violations that are discovered after the data are collected cannot be corrected and the data have to be analyzed with techniques specific to dependent data.25 In other words, designing data collections with independence among individuals is critical and needs to be ascertained before the data are collected. Independence is generally assessed by considering how the individuals were obtained. In this course, the data will have already been collected for you and, at times, the description of that data collection may be sparse. To address independence you will be asked to explain why you think dependencies do not exist in the data collection. This may take several sentences. Examples will be provided below and in future analyses. 7.2 Equal Variances The variances among groups must be equal because the estimate of MSWithin is based on pooling estimates across the groups. In other words, if the variances among each group are equal, then the variance (or MS) for each group is an estimate of the overall MSWithin. If the variances are equal across groups then combining the variances from each group provides a robust estimate of the overall variance within groups. Equal variances among groups is a critical assumption of a one-way ANOVA. Violations of this assumption should be corrected. The assumption of equal variances can be tested with Levenes homogeneity of variances test.26 The hypotheses tested by Levenes test are \\[ \\begin{split} \\text{H}_{\\text{0}} &amp;: \\sigma_{1}^{2}=\\sigma_{2}^{2}=\\cdots=\\sigma_{I}^{2} \\\\ \\text{H}_{\\text{A}} &amp;: \\text{At least one pair of variances differ} \\end{split} \\] Thus, a p-value less than  means that the variances are not equal and the assumption of the one-way ANOVA has not been met.27 The equality of variances may be visually examined with a boxplot of full model residuals28 by group. If the boxes on this boxplot are not roughly the same, then the equal variances assumption may be violated. I will usually examine the boxplots rather than use a Levenes Test when the sample size is very large because Levenes test can be hyper-sensitive with large samples sizes (i.e., reject H0 of equal variances when the variances are not practically different). 7.3 Normality The normality of residuals WITHIN each group is difficult to test because there may be many groups being considered or relatively few individuals in each group. Thus the normality of all residuals taken as a whole is often tested. As most linear models are resilient to slight departures from normality, it is thought that if all of the residuals as a whole appear approximately normal then the residuals within each group are likely normal enough. A one-way ANOVA is resilient to slight violations of the normality assumption. Severe violations of this assumption should be corrected. Normality is often tested by simply viewing a histogram of residuals or a so-called Q-Q plot. For an adequate sample size, a histogram that is not strongly skewed is probably adequate for a One-Way ANOVA. The normality of residuals may also be tested with the Anderson-Darling Normality Test.29 The hypotheses for this test are \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: \\text{Residuals are normally distributed} \\\\ \\text{H}_{\\text{A}}&amp;: \\text{Residuals are not normally distributed} \\\\ \\end{split} \\] An Anderson-Darling p-value greater than  indicates that the residuals appear to be normally distributed and the normality assumption is met. An Anderson-Darling p-value less than  suggests that the normality assumption has been violated. The results of an Anderson-Darling test should be interpreted cautiously for both small and very large sample sizes. At small sample sizes, the distribution would need to be wildly non-normal for the Anderson-Darling Test to suggest that it is not normal. At very large sample sizes, very small and insubstantial differences from normality may result in the test indicating that the distribution is not normal. Thus, it is important to always examine the histogram of residuals to decide whether this assumption is adequately met or not. 7.4 No Outliers The one-way ANOVA is very sensitive to outliers. Outliers should be corrected if possible (usually if there is a data transcription or entry problem) or deleted if it is determined that the outlier is clearly in error or is not part of the population of interest. If the outlier is not corrected or deleted, then the relative effect of the outlier on the analysis should be determined by completing the analysis with and without the outlier present. Any differences in results or interpretations due to the presence of the outlier should be clearly explained to the reader. A one-way ANOVA is very sensitive to outliers. Outliers may be detected by visual examination of a histogram of residuals. Potential outliers can be more objectively detected with externally Studentized residuals,30 which essentially measure how many standard deviations an individual is from its group mean. Studentized residuals follow a t-distribution with dfWithin-1 degrees-of-freedom.31 A p-value for testing whether an individual residual is an outlier or not is calculated by converting the Studentized residual to a two-tailed p-value using a t-distribution. As these p-values are computed for each residual, this process suffers from the multiple comparison problem (see Section ??). Thus, the p-values use a Bonferroni method32 to correct for multiple comparisons so that the likelihood of mistakingly identifying an outlier is controlled at a desirable level. If the Bonferroni adjusted p-value for the most extreme residual is less than , then that individual is considered to be a significant outlier and should be flagged for further inspection as described above. 7.5 Testing Assumptions in R All plots and tests of assumptions can be completed by submitting the saved lm object from when the One-Way ANOVA was computed to assumptionCheck(). For example, the code below fits the One-Way ANOVA for testing if the mean immunoglobulin levels of New Zealand opossums differs among seasons (the opp data frame was created in Module 6) and then performs the calculations needed to check the assumptions. lm1 &lt;- lm(imm~season,data=opp) assumptionCheck(lm1) For a One-Way ANOVA, assumptionCheck() produces a histogram of residuals with the Anderson-Darling and outlier test p-values on the left and a boxplot of residuals for each group with the Levenes Test p-value on the right. In this case the boxes on the boxplot are similarly sized and the Levenes test p-value (=0.3708) is greater than  suggesting that the group variances are equal. The histogram of residuals is difficult to assess because the sample size is so small, but it does not appear strongly skewed and the Anderson-Darling p-value (=0.0609) is (barely) greater than , which weakly suggests that the residuals are normally distributed. The histogram does not show any odd individuals and the outlier test p-value (=0.0402) is greater than  which suggests that there are not any significant outliers in these data. Thus, the three assumptions that can be tested with the data all appear to be met. The independence assumption cannot be assessed from the data and must be reasoned through. While there is not much information about this study, I will assume between group independence as there is no suggestion that the same opossums were sampled in each of the three seasons (i.e., no indication that they were tagged or otherwise individually identified). This is particularly clear because the sample size differs across seasons (see table below). I will also assume that there is within-group independence because there is no evidence that the opossums within any given season were somehow related or connected. xtabs(~season,data=opp) #R&gt; season #R&gt; feb may nov #R&gt; 12 7 8 Note that the first three are the same three assumptions you learned for a 2-Sample t-test. Such methods may include repeated measures ANOVA, mixed-models, and hierarchical models. There are a wide variety of statistical tests for examining equality of variances. We will use the Levenes test in this class because it is common in the literature and simple to implement in most statistical software packages. Methods for working around this assumption violation are discussed in Module 8. Recall that these are the vertical differences between observations and their group mean. There are also a wide variety of normality tests. Some authors even argue against the use of hypothesis tests for testing normality and suggest the use of graphical methods instead. For simplicity, the Anderson-Darling normality test will be used throughout this course. A residual divided by the standard deviation of the residual, where the standard deviation is computed with that individual removed. The extra one is subtracted because the individual residual is not included in the calculation of the standard deviation of residuals. An adjusted p-value is computed by multiplying the original p-value by the number of comparisons made (in this case n). "],["ANOVA1Transformations.html", "Module 8 One-Way Transformations 8.1 Power Transformations 8.2 Transformations from Theory 8.3 Interpretations After Transformations 8.4 Back-Transformations in R", " Module 8 One-Way Transformations As discussed in Module 7 a One-Way ANOVA depends on four assumptions being met. If those assumptions are not met, then the results of the one-way ANOVA are invalid. Fortunately, violations of the equality of variances and normality assumptions can often be addressed by transforming the quantitative response variable to a scale where the assumptions are met. For example it is common use the natural log of the response variable rather than the response variable on its original scale. If the assumptions of a one-way ANOVA are not met, then the data may be transformed to a scale where the assumptions are met. Besides the obvious reason related to assumption violations, Fox (1997) gave four arguments for why data that is skewed or has unequal variances should be transformed: Highly skewed distributions are difficult to examine because most of the observations are confined to a small part of the range of the data. Apparently outlying individuals in the direction of the skew are brought in towards the main body of the data when the distribution is made more symmetric. In contrast, unusual values in the direction opposite to the skew can be hidden prior to transforming the data. Linear models summarize distributions based on means. The mean of a skewed distribution is not, however, a good summary of its center. When a variable has very different degrees of variation in different groups, it becomes difficult to examine the data and to compare differences in levels across the groups. Identification of an appropriate transformation and understanding the resultant output is the focus of this module. 8.1 Power Transformations With power transformations, the response variable is transformed by raising it to a particular power, \\(\\lambda\\), i.e., \\(Y^{\\lambda}\\) (Table 8.1). Table 8.1: Common power transformations in ANOVAs. Power Name Formula R Code \\(\\lambda\\)=1  \\(Y^{1}=Y\\)  \\(\\lambda\\)=0.5 Square Root \\(Y^{0.5}=\\sqrt{Y}\\) df$newvar &lt;- sqrt(df$oldvar) \\(\\lambda\\)=0.33 Cube Root \\(Y^{0.33}=\\sqrt[3]{Y}\\) df$newvar &lt;- df$oldvar^(1/3) \\(\\lambda\\)=0.25 Fourth Root \\(Y^{0.25}=\\sqrt[4]{Y}\\) df$newvar &lt;- df$oldvar^(1/4) \\(\\lambda\\)=0 Natural log \\(log(Y)\\) df$newvar &lt;- log(df$oldvar) \\(\\lambda\\)=-1 Inverse \\(Y^{-1}=\\frac{1}{Y}\\) df$newvar &lt;- 1/df$oldvar Each transformation in Table 8.1 spreads out small values and draws in large values in a distribution. For example, in Figure 8.1 the log function is shown as the black curved line, the original histogram of strongly right-skewed data is shown upside-down below the x-axis, and the histogram following the log-transformation is shown sideways left of the y-axis. Two small values are shown in red on the x-axis. The log-transformation of these two points is shown by following the two vertical lines from these points to the black log function and then moving horizontally to the y-axis. From this it is seen that these two values that were relatively close together are more spread out after the transformation. Conversely two large values are shown in blue on the x-axis. Following the same process it is seen that these two points are closer together following the log transformation. Figure 8.1: Demonstration of the result (upper-left) from applying the natural log transformation function (black curve in upper-right) to strongly right-skewed original values (lower-right). As seen in Figure 8.1, applying the log transformation to all values in the original strongly right-skewed distribution resulted in a distribution that was approximately normal. All transformations may not achieve normality. For example, the same process shown in Figure 8.1 is repeated in Figure 8.2 for a square-root transformation. A comparison of the two figures shows that the square-root transformation function is less curved, it spreads out relatively small values less and draws in relative larger values less, and it does not transform the original strongly right-skewed distribution to an approximately normal distribution. Thus, the square-root transformation is not a strong enough transformation to normalize this strongly right-skewed original distribution. Figure 8.2: Demonstration of the result (upper-left) from applying the square root transformation function (black curve in upper-right) to strongly right-skewed original values (lower-right). The original values here are the same as those in the previous Figure. The square root transformation is more likely to be useful when the original distribution is less strongly skewed (Figure 8.3). Figure 8.3: Demonstration of the result (upper-left) from applying the square root transformation function (black curve in upper-right) to slightly right-skewed original values (lower-right). The original values here are not the same as those in the previous two figures. As demonstrated above, the common transformations listed in Table 8.1 vary in their ability to normalize skewed distributions. Generally the common transformations in Table 8.1 are ordered from least to most powerful. In other words, the transformations are ordered from those that normalize mildly skewed data to those that normalize strongly skewed data.33 It is possible to combine one of the common powers with the inverse transformation to create a larger array of transformations. For example, \\(\\lambda\\)=-0.5 is an inverse square-root transformation. These types of transformations are common but less common than those listed in Table 8.1. Table 8.2: Common inverse power transformations in ANOVAs. These transformations are much less common than those in Table 8.1. Power Name Formula R Code \\(\\lambda\\)=-0.25 Inverse Fourth Root \\(Y^{-0.25}=\\frac{1}{\\sqrt[4]{Y}}\\) df$ifourrt.y &lt;- df$Y^(-1/4) \\(\\lambda\\)=-0.33 Inverse Cube Root \\(Y^{-0.33}=\\frac{1}{\\sqrt[3]{Y}}\\) df$icubert.y &lt;- df$Y^(-1/3) \\(\\lambda\\)=-0.5 Inverse Square Root \\(Y^{-0.5}=\\frac{1}{\\sqrt{Y}}\\) df$isqrt.y &lt;- 1/sqrt(df$Y) Power transformations require non-negative and non-zero data. Violations of this restriction can be rectified by adding an amount to all values of the response variable such that all values become positive. This is called shifting the data and does not effect the shape of the distribution. In addition, power transformations are not effective if the range of values of the response variable is narrow.34 There are several methods to identify the power transformation that is most likely to meet the assumptions of a one-way ANOVA.35 One simple method is trial-and-error  i.e., trying various powers until one is found where the assumptions of the model are most closely met. The trial-and-error method is made easier with software. For example, the assumptionCheck() function introduced in Section 7.5 can be used to quickly compute the graphs and hypothesis tests for assumption checking after the data have been transformed by the power given in the lambday= argument. For example, the code and results below show what the assumption checking would look like if the immunoglobulin measurements for the New Zealand opossums had been log transformed. lm1 &lt;- lm(imm~season,data=opp) assumptionCheck(lm1,lambday=0) #lambda=0 corresponds to log-transformation Of course, it was shown in Section 7.5 that the assumptions for a One-Way ANOVA with these data had been met; thus, there is no need to explore a transformation here. However, this shows how easily one quickly test various transformations for a given set of data. Note that assumptionCheck() only transform the data behind-the-scenes. If you want to continue with transformed data then you need to use R code like that shown in the last columns of Tables 8.1 and 8.2. 8.2 Transformations from Theory Certain special transformations are common in particular fields of study and are generally well-known to scientists in those fields. An example that crosses many fields is the transformation of proportions or percentages data by using the arcsine square-root function (i.e., \\(\\text{sin}^{-1}(\\sqrt{Y})\\)). Also, a possible power transformation may be chosen from theory related to the response variable. For example, it is common to square-root transform response variables that are areas and cube-root transform response variables that are volumes. In addition, discrete counts are often transformed with the square root. 8.3 Interpretations After Transformations Care must be taken with interpretations following transformations. A few simple rules help in this regard. First, tell the reader what transformation you used and how you arrived at it. In other words, clearly demonstrate that the assumptions were not met on the original scale and demonstrate that they were met on the transformed scale. Second, when making a conclusion from the One-Way ANOVA p-value, refer to the transformed response variable in your conclusions. In other words, say the mean square root of the response variable differed among groups rather than the mean of the response variable differed among groups. It will be implied that the means differed on the original scale, but you strictly tested on the transformed scale so you should be explicit about that here. Third, back-transform estimates (and confidence intervals) for points. In One-Way ANOVA this means that you should back-transform estimates of means. For example, if the response variable was log-transformed such that the mean log of Y was 1.356 then this should be back-transformed to the original scale with e1.356=3.881. Similarly if the response variable was square-root transformed such that the mean square-root of Y was 1.356 then this should be back-transformed to the original scale with 1.3562=1.839. Fourth, do NOT back-transform differences unless those differences are from a log-transformation. In a One-Way ANOVA this translates into whether or not you can back-transform differences in means, as would result from multiple comparisons. For example if the result is a difference in the mean square-root of the response variable between groups then do not back-transform this value as it can not be back-transformed to anything meaningful. However, if the result is a difference in mean log of the response variable between groups then this difference can (and should) be back-transformed to something meaningful. We know from algebra class that the difference in the log of two values is the log of the ratio of the two values  i.e., \\(log(a)-log(b) = log(\\frac{a}{b})\\). Thus, back-transforming the difference in log values results in a ratio of values on the original scale  i.e., \\(e^{log(a)-log(b)} = e^{log(\\frac{a}{b})} = \\frac{a}{b}\\). Thus, in a One-Way ANOVA, the back-transformed difference in group means on the log scale is the ratio of group means on the original scale. For example, suppose that the difference in log means for two groups is 0.5. Back-transforming this value gives \\(e\\)0.5=1.649. Thus, on the original scale, the mean for the first group is 1.649 times larger than the mean for the second group. Alternatively, suppose that the difference in log means for two groups is -0.5. Back-transforming this value gives \\(e\\)-0.5=0.607. Thus, on the original scale, the mean for the first group is 0.607 as large as the mean for the second group. Or, the mean for the second group is \\(\\frac{1}{0.607}\\)=1.649 times larger than the mean for the first group. Log-transformations are very special, as they allow both means and differences in means to be back-transformed to the original scale with a meaningful result. Because of this, the first transformation that you should try in all situations is the log-transformation. Many times we prefer the log-transformation over other transformations, even if the assumptions are not perfectly met with the log-transformation. Always try the log-transformation first as it allows for meaningful back-transformations of means and differences. If the log transformation does not work to meet the assumptions of the One-Way ANOVA then you should start with the least strong transformation (i.e., the square root) and successively move through more strong transformations until the assumptions are adequately met. 8.4 Back-Transformations in R Transformations and back-transformations will be illustrated more in this modules assignment and in Module 9. However, the emmeans() function introduced in Section 6.3 makes back-transformations very easy. While a transformation was not needed for the New Zealand opossums example, lets suppose for illustrative purposes that a square root transformation was used. First, a square root variable is created and a new ANOVA model with this variable is used. opp$sqrtimm &lt;- sqrt(opp$imm) lm2 &lt;- lm(sqrtimm~season,data=opp) anova(lm2) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: sqrtimm #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; season 2 0.099654 0.049827 14.675 6.868e-05 #R&gt; Residuals 24 0.081487 0.003395 Multiple comparisons can be created as before, but there is an advantage to telling emmeans() that you used a square root transformation with tran= as shown below. Here we can see (see the two notes under the $emmeans and $contrasts portions of the output) that summary() reminds you that the results are on the square root scale. This should help you remember to interpret these results on the square root scale. mct &lt;- emmeans(lm2,specs=pairwise~season,tran=&quot;sqrt&quot;) ( mcsumt &lt;- summary(mct,infer=TRUE) ) #R&gt; $emmeans #R&gt; season emmean SE df lower.CL upper.CL t.ratio p.value #R&gt; feb 0.816 0.0168 24 0.781 0.851 48.513 &lt;.0001 #R&gt; may 0.849 0.0220 24 0.803 0.894 38.528 &lt;.0001 #R&gt; nov 0.698 0.0206 24 0.656 0.741 33.886 &lt;.0001 #R&gt; #R&gt; Results are given on the sqrt (not the response) scale. #R&gt; Confidence level used: 0.95 #R&gt; #R&gt; $contrasts #R&gt; contrast estimate SE df lower.CL upper.CL t.ratio p.value #R&gt; feb - may -0.0325 0.0277 24 -0.1017 0.0367 -1.172 0.4806 #R&gt; feb - nov 0.1179 0.0266 24 0.0515 0.1843 4.434 0.0005 #R&gt; may - nov 0.1504 0.0302 24 0.0751 0.2257 4.988 0.0001 #R&gt; #R&gt; Note: contrasts are still on the sqrt scale #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 3 estimates #R&gt; P value adjustment: tukey method for comparing a family of 3 estimates More importantly if you declare your transformation with tran= then you can use summary() to appropriately back-transform the results by including type=\"response\". Here, the $emmeans results are back-transformed as the Intervals are back-transformed from the sqrt scale note indicates, but you are reminded that the p-values were computed on the transformed scale with the Tests are performed on the sqrt scale. The $contrasts results are left on the square root scales as noted with Note: contrasts are still on the sqrt scale because emmeans() is smart enough to know that you should not back-transform differences when using a square root transformation. ( mcsumbt &lt;- summary(mct,infer=TRUE,type=&quot;response&quot;) ) #R&gt; $emmeans #R&gt; season response SE df lower.CL upper.CL t.ratio p.value #R&gt; feb 0.666 0.0275 24 0.610 0.724 48.513 &lt;.0001 #R&gt; may 0.720 0.0374 24 0.645 0.799 38.528 &lt;.0001 #R&gt; nov 0.487 0.0288 24 0.430 0.549 33.886 &lt;.0001 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; Intervals are back-transformed from the sqrt scale #R&gt; Tests are performed on the sqrt scale #R&gt; #R&gt; $contrasts #R&gt; contrast estimate SE df lower.CL upper.CL t.ratio p.value #R&gt; feb - may -0.0325 0.0277 24 -0.1017 0.0367 -1.172 0.4806 #R&gt; feb - nov 0.1179 0.0266 24 0.0515 0.1843 4.434 0.0005 #R&gt; may - nov 0.1504 0.0302 24 0.0751 0.2257 4.988 0.0001 #R&gt; #R&gt; Note: contrasts are still on the sqrt scale #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 3 estimates #R&gt; P value adjustment: tukey method for comparing a family of 3 estimates The back-transformed means in $emmeans can be used to construct a plot of means as before, but you must realize that the means are now labeled as response (look at the last output above) rather than emmean (thus you must change y= in geom_errobar() and geom_point()). ggplot() + geom_jitter(data=opp,mapping=aes(x=season,y=imm),alpha=0.25,width=0.05) + geom_errorbar(data=mcsumbt$emmeans, mapping=aes(x=season,y=response,ymin=lower.CL,ymax=upper.CL), size=2,width=0) + geom_point(data=mcsumbt$emmeans,mapping=aes(x=season,y=response), size=2,pch=21,fill=&quot;white&quot;) + labs(y=&quot;Immunoglobulin Concentration&quot;,x=&quot;Season/Month&quot;) + theme_NCStats() Now, look at the same results for a log transformation. Once again the results when not using type=\"response\" show a note reminding you that the results are on the log scale. opp$logimm &lt;- log(opp$imm) lm3 &lt;- lm(logimm~season,data=opp) mct &lt;- emmeans(lm2,specs=pairwise~season,tran=&quot;log&quot;) ( mcsumt &lt;- summary(mct,infer=TRUE) ) #R&gt; $emmeans #R&gt; season emmean SE df lower.CL upper.CL t.ratio p.value #R&gt; feb 0.816 0.0168 24 0.781 0.851 48.513 &lt;.0001 #R&gt; may 0.849 0.0220 24 0.803 0.894 38.528 &lt;.0001 #R&gt; nov 0.698 0.0206 24 0.656 0.741 33.886 &lt;.0001 #R&gt; #R&gt; Results are given on the log (not the response) scale. #R&gt; Confidence level used: 0.95 #R&gt; #R&gt; $contrasts #R&gt; contrast estimate SE df lower.CL upper.CL t.ratio p.value #R&gt; feb - may -0.0325 0.0277 24 -0.1017 0.0367 -1.172 0.4806 #R&gt; feb - nov 0.1179 0.0266 24 0.0515 0.1843 4.434 0.0005 #R&gt; may - nov 0.1504 0.0302 24 0.0751 0.2257 4.988 0.0001 #R&gt; #R&gt; Results are given on the log (not the response) scale. #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 3 estimates #R&gt; P value adjustment: tukey method for comparing a family of 3 estimates However, when type=\"response\" is used, the $emmeans portion of the results are back-transformed with a note again saying so. However, the $contrasts portion is now also back-transformed because emmeans() is smart enough to know that it is possible (and useful) to back-transform differences from the log scale. In fact the rows in the $contrasts portion are appropriately labeled as ratios to aid your interpretation. ( mcsumbt &lt;- summary(mct,infer=TRUE,type=&quot;response&quot;) ) #R&gt; $emmeans #R&gt; season response SE df lower.CL upper.CL t.ratio p.value #R&gt; feb 2.26 0.0380 24 2.18 2.34 48.513 &lt;.0001 #R&gt; may 2.34 0.0515 24 2.23 2.44 38.528 &lt;.0001 #R&gt; nov 2.01 0.0414 24 1.93 2.10 33.886 &lt;.0001 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; Intervals are back-transformed from the log scale #R&gt; Tests are performed on the log scale #R&gt; #R&gt; $contrasts #R&gt; contrast ratio SE df lower.CL upper.CL t.ratio p.value #R&gt; feb / may 0.968 0.0268 24 0.903 1.04 -1.172 0.4806 #R&gt; feb / nov 1.125 0.0299 24 1.053 1.20 4.434 0.0005 #R&gt; may / nov 1.162 0.0351 24 1.078 1.25 4.988 0.0001 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 3 estimates #R&gt; Intervals are back-transformed from the log scale #R&gt; P value adjustment: tukey method for comparing a family of 3 estimates #R&gt; Tests are performed on the log scale Alternatively, the transformations are listed in order from the transformations that spread out the small values the least to those that spread out the small values the most. In effect, the power transformation is basically linear over short ranges and, thus, is not effective. Box and Cox (1964) provided a statistical and graphical method for identifying the appropriate power transformation for the response variable. The details of this method are beyond the scope of this class but, in general, the method searches for a \\(\\lambda\\) that minimizes SSwithin). A slightly modified Box and Cox approach is implemented in R by sending a lm object to boxcox() from the MASS package. "],["ANOVA1Summary.html", "Module 9 One-Way Summary 9.1 Suggested Workflow 9.2 Nematodes (No Transformation) 9.3 Ant Foraging (Transformation) 9.4 Peak Discharge (Transformation)", " Module 9 One-Way Summary Specific parts of a full One-Way ANOVA analysis have been described in Modules 5-8. In this module, a workflow for a full analysis is offered and that workflow is demonstrated with several examples. 9.1 Suggested Workflow The process of fitting and interpreting linear models is as much an art as it is a science. The feel for fitting these models comes with experience. The following is a process to consider for fitting a one-way ANOVA model. Consider this process as you learn to fit one-way ANOVA models, but dont consider this to be a concrete process for all models. Perform a thorough EDA of the quantitative response variable. Pay special attention to the distributional shape, center, dispersion, and outliers within each level of the grouping variable. Show the sample size per group and comment on whether the study was balanced (i.e., same sample size per group) or not. Address the independence assumption. If this assumption is not met then other analysis methods must be used. Fit the untransformed full model (i.e., separate group means) with lm(). Check the other three assumptions for the untransformed model with assumptionCheck(). Check equality of variances with a Levenes test and residual plot. Check normality of residuals with an Anderson-Darling test and histogram of residuals. Check for outliers with an outlier test, residual plot, and histogram of residuals. If an assumption or assumptions are violated, then attempt to find a transformation where the assumptions are met. Use the trial-and-error method with assumptionCheck(), theory, or experience to identify a possible transformation. Always try the log transformation first. If only an outlier exists (i.e., there are equal variances and normal residuals) and no transformation corrects the outlier then consider removing the outlier from the data set. Fit the ultimate full model with the transformed response or reduced data set. Construct an ANOVA table for the full model with anova() and make a conclusion about the equality of means from the p-value. If differences among group means exist, then use a multiple comparison technique with emmeans() and summary() to identify specific differences. Discuss specific differences using confidence intervals. If the data were log-transformed then discuss specific ratios of means using back-transformed differences (use tran= in emmeans() and type=\"response\" in summary() to computed the back-transformations). Create a summary graphic of observations with group means on the original scale and 95% confidence intervals using ggplot() and results from emmeans(). Write a succinct conclusion of your findings. 9.2 Nematodes (No Transformation) Root-Knot Nematodes (Meloidogyne spp.) are microscopic worms found in soil that may negatively affect the growth of plants through their trophic dynamics. Tomatoes are a commercially important plant species that may be negatively affected by high densities of nematodes in culture situations. A science fair student designed an experiment to determine the effect of increased densities of nematodes on the growth of tomato seedlings. The student hypothesized that nematodes would negatively affect the growth of tomato seedlings  i.e., growth of seedlings would be lower at higher nematode densities. The statistical hypotheses to be examined were \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: \\mu_{0} = \\mu_{1000} = \\mu_{5000} = \\mu_{10000} \\\\ \\text{H}_{\\text{A}}&amp;:\\text{At least one pair of means is different} \\end{split} \\] where \\(\\mu\\) is the mean growth of the tomato seedlings and the subscripts identify densities of nematodes (see below). The student had 16 pots of a homogeneous soil type in which he stocked a known density of nematodes. The densities of nematodes used were 0, 1000, 5000, or 10000 nematodes per pot. The density of nematodes to be stocked in each pot was randomly assigned. After stocking the pots with nematodes, tomato seedlings, which had been selected to be as nearly identical in size and health as possible, were transplanted into each pot. The exact pot that a seedling was transplanted into was again randomly selected. Each pot was placed under a growing light in the same laboratory and allowed to grow for six weeks. Watering regimes and any other handling necessary during the six weeks was kept the same as much as possible among the pots. After six weeks, the plants were removed from the growing conditions and the growth of the seedling (in cm) from the beginning of the experiment was recorded. This study was balanced as the number of pots at each nematode density is the same (Table 9.1). The sample size, though, is quite small. Table 9.1: Number of pots at each nematode density treatment. density Freq 0 4 1000 4 5000 4 10000 4 Independence appears to be largely met in this experiment. Each tomato plant was planted in a randomly selected individual pot that had been randomly assigned a number of nematodes. Thus, the growth of an individual plant should not effect the growth of another individual plant. I would be concerned if the pots were not randomly placed around the laboratory. For example, if all pots of a certain treatment were placed in one corner of the laboratory then conditions in that one corner may affect growth for those pots. There is no indication that this happened, so I will assume that it did not. Note the detailed discussion of independence. Variances among treatments appear to be approximately equal (Levenes p=0.8072; Figure 9.1-Right), the residuals appear to be approximately normally distributed (Anderson-Darling p=0.9268) and the histogram of residuals does not indicate any major skewness (Figure 9.1-Left), and there does not appear to be any major outliers in the data (outlier test p=0.6712; Figure 9.1). The analysis will proceed with untransformed data because the assumptions of the one-way ANOVA were met. Note the succinct writing with respect to testing the assumptions. Figure 9.1: Histogram (Left) and boxplot (Right) of residuals from the utransformed One-Way ANOVA model for the tomato seedling growth at each nematode density. There appears to be a significant difference in mean tomato seedling growth among at least some of the four treatments (p=0.0006; Table 9.2). Note the use of ANOVA table to first identify any differences. Table 9.2: ANOVA results for tomato seedling growth at four nematode densities. Df Sum Sq Mean Sq F value Pr(&gt;F) density 3 100.65 33.55 12.08 0.00062 Residuals 12 33.33 2.78 It appears that mean growth of tomatoes does not differ at densities 0 and 1000 (p=0.9974) and 5000 and 10000 (p=0.9992), but does differ for all other pairs of nematode densities (p0.0070) (Table 9.3). Table 9.3: Tukeys multiple comparisons for differences in mean tomato seedling growth for all pairs of four nematode densities. contrast estimate lower.CL upper.CL p.value 0 - 1000 0.225 -3.274 3.724 0.9974 0 - 5000 5.050 1.551 8.549 0.0050 0 - 10000 5.200 1.701 8.699 0.0041 1000 - 5000 4.825 1.326 8.324 0.0070 1000 - 10000 4.975 1.476 8.474 0.0056 5000 - 10000 0.150 -3.349 3.649 0.9992 The students hypothesis was generally supported (Figure 9.2). However, it does not appear that tomato seedling growth is negatively affected for all increases in nematode density. For example, seedling growth declined for an increase from 1000 to 5000 nematodes per pot but not for increases from 0 to 1000 nematodes per pot or from 5000 to 10000 nematodes per pot. Specifically, it appears that the mean growth of the tomato seedlings is between 1.3 and 8.3 cm lower at a density of 5000 nematodes than at a density of 1000 nematodes (Table 9.2). Note use of a confidence interval and specific direction (i.e., lower) when describing the difference. Figure 9.2: Mean (with 95% confidence interval) of tomato growth at each nematode density. From this analysis, it appears that there is a critical density of nematodes for tomato growth somewhere between 1000 and 5000 nematodes per pot. The experimenter may want to redo this experiment for densities between 1000 and 5000 nematodes per pot in an attempt to more specifically identify a critical nematode density below which there is very little affect on growth and above which there is a significant negative affect on growth. R Code and Results TN &lt;- read.csv(&quot;http://derekogle.com/Book207/data/TomatoNematode.csv&quot;) TN$density &lt;- factor(TN$density) lm.tn &lt;- lm(growth~density,data=TN) xtabs(~density,data=TN) assumptionCheck(lm.tn) anova(lm.tn) mc.tn &lt;- emmeans(lm.tn,specs=pairwise~density) ( mcsum.tn &lt;- summary(mc.tn,infer=TRUE) ) ggplot() + geom_jitter(data=TN,mapping=aes(x=density,y=growth),alpha=0.25,width=0.1) + geom_errorbar(data=mcsum.tn$emmeans, mapping=aes(x=density,y=emmean,ymin=lower.CL,ymax=upper.CL), size=2,width=0) + geom_point(data=mcsum.tn$emmeans,mapping=aes(x=density,y=emmean), size=2,pch=21,fill=&quot;white&quot;) + labs(x=&quot;Nematode Stocking Density&quot;,y=&quot;Tomato Plant Growth (cm)&quot;) + theme_NCStats() 9.3 Ant Foraging (Transformation) Red wood ants (Formica rufa) forage for food (mainly insects and honeydew produced by aphids) both on the ground and in the canopies of trees. Rowan, Oak and Sycamore trees support very different communities of insect herbivores (including aphids) and it would be interesting to know whether the foraging efficiency of ant colonies is affected by the type of trees available to them. As part of an investigation of the foraging of Formica rufa, observations were made of the prey being carried by ants down trunks of trees. The total biomass of prey being transported was measured over a 30-minute sampling period on different tree specimens. The results were expressed as the biomass (dry weight in mg) of prey divided by the total number of ants leaving the tree to give a rate of food collection per ant per half hour. Observations were made on 28 Rowan, 26 Sycamore, and 27 Oak trees.36 The statistical hypotheses to be examined are \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: \\mu_{Oak} = \\mu_{Rowan} = \\mu_{Sycamore} \\\\ \\text{H}_{\\text{A}}&amp;:\\text{At least one pair of means is different} \\end{split} \\] where \\(\\mu\\) is the mean foraging rate of the ants and the subscripts identify the type of tree examined. This study was slightly unbalanced as the number of ants recorded on each tree is similar, but not the same (Table 9.4). Table 9.4: Number of ants recorded on each type of tree. Tree Freq Oak 27 Rowan 28 Sycamore 26 The data appear to be independent as long as the separate trees were not in close proximity to each other. It is possible that the researchers examined one species of tree entirely within one forest of those trees. This would mean that the individuals within a species were somehow related, which would violate the independence assumption. In addition, the researchers could have looked at one specimen of each species all in a certain location, such that one tree could influence another tree. This again would violate the independence assumption. There is no indication that either of the scenarios occurred so I will assume that the individuals are independent both within- and among-groups. Note careful discussion of independence here. Variances among treatments for the untransformed data appear to be non-constant (Levenes p=0.0036; Figure 9.3-Right). The residuals appear to be not normally distributed (Anderson-Darling p=0.0002) with a fairly strong skew in the histogram (Figure 9.3-Left). There also appears to be a significant outlier (outlier test p=0.0012) that has a large residual and appears to be in the Oak group (Figure 9.3). None of the assumptions are met so transforming the food rate was considered. Figure 9.3: Histogram of residuals (Left) and boxplot of residual (Right) from the one-way ANOVA on untransformed foraging rate of ants. A log transformation of foraging rate resulted in equal variances (Levenes p=0.4815; Figure 9.4-Right), normal (Anderson-Darling p=0.0603) or at least not skewed (Figure 9.4-Left) residuals, and no significant outliers (outlier test p&gt;1). Thus, the assumptions of the One-Way ANOVA model appeared to have been adequately met on the log scale. Figure 9.4: Histogram of residuals (Left) and boxplot of residual (Right) from the one-way ANOVA on log transformed foraging rate of ants. There appears to be a significant difference in mean log foraging rate of the ants among some of the tree species (p=0.0013; Table 9.5). Note the careful use of the transformation name here. Table 9.5: ANOVA results for the log transformed foraging rate of ants among tree species. Df Sum Sq Mean Sq F value Pr(&gt;F) Tree 2 7.479 3.739 7.287 0.00126 Residuals 78 40.028 0.513 Tukey multiple comparisons indicate that the mean log foraging rate was greater for ants on Oak trees than ants on Rowan trees (p=0.0008; Table 9.6). Specifically, the mean foraging rate for ants on an Oak tree was between 1.318 and 3.318 times higher than the mean foraging rate for ants on a Rowan tree (Table 9.7). However, there was no significant difference in mean log foraging rate between ants on Sycamore trees and ants on Oak (p=0.1559) or Rowan (p=0.1457; Table 9.6) trees. Note how the back-transformed difference in means forms a ratio that is interpreted as a multiplicative change. Table 9.6: Tukeys multiple comparisons for differences in mean log foraging rate of ants among tree species. contrast estimate lower.CL upper.CL p.value Oak - Rowan 0.738 0.276 1.199 0.0008 Oak - Sycamore 0.367 -0.103 0.837 0.1559 Rowan - Sycamore -0.371 -0.837 0.096 0.1457 Table 9.7: Tukeys multiple comparisons for ratios of mean foraging rate of ants among tree species. contrast ratio lower.CL upper.CL p.value Oak / Rowan 2.091 1.318 3.318 0.0008 Oak / Sycamore 1.443 0.902 2.310 0.1559 Rowan / Sycamore 0.690 0.433 1.100 0.1457 These results indicate that there is a difference in the mean foraging rate of ants, but only between those on Oak and Rowan trees, where ants on Oak trees had approximately double the mean foraging rate as ants on Rowan trees (Figure 9.5). There was no difference in mean foraging rates for ants on Sycamore trees and either Oak or Rowan trees. It is possible with a log to back-transform both means and differences in means. Figure 9.5: Back-transformed mean (with 95% confidence interval) foraging rate of ants on each tree species. The mean foraging rate differed only between Oak and Rown trees. R Code and Results AF &lt;- read.csv(&quot;http://derekogle.com/Book207/data/Ants.csv&quot;) lm.af &lt;- lm(Food~Tree,data=AF) xtabs(~Tree,data=AF) assumptionCheck(lm.af) assumptionCheck(lm.af,lambday=0) AF$logFood &lt;- log(AF$Food) lm.aft &lt;- lm(logFood~Tree,data=AF) anova(lm.aft) mc.aft &lt;- emmeans(lm.aft,specs=pairwise~Tree,tran=&quot;log&quot;) ( mcsum.aft &lt;- summary(mc.aft,infer=TRUE) ) ( mcsum.afbt &lt;- summary(mc.aft,infer=TRUE,type=&quot;response&quot;) ) ggplot() + geom_jitter(data=AF,mapping=aes(x=Tree,y=Food),alpha=0.25,width=0.05) + geom_errorbar(data=mcsum.afbt$emmeans, mapping=aes(x=Tree,y=response,ymin=lower.CL,ymax=upper.CL), size=2,width=0) + geom_point(data=mcsum.afbt$emmeans,mapping=aes(x=Tree,y=response), size=2,pch=21,fill=&quot;white&quot;) + labs(x=&quot;Tree Species&quot;,y=&quot;Foraging Rate (mg per ant per 30 mins)&quot;) + theme_NCStats() 9.4 Peak Discharge (Transformation) Mathematical models are used to predict flood flow frequency and estimates of peak discharge for the Mississippi River watershed. These models are important for forecasting potential dangers to the public. A civil engineer was interested in determining whether four different methods for estimating flood flow frequency produce equivalent estimates of peak discharge when applied to the same watershed. The statistical hypotheses to be examined are \\[\\begin{split} \\text{H}_{\\text{0}}&amp;: \\mu_{1} = \\mu_{2} = \\mu_{3} = \\mu_{4} \\\\ \\text{H}_{\\text{A}}&amp;:\\text{At least one pair of means is different} \\end{split} \\] where \\(\\mu\\) is the mean peak discharge estimate and the subscripts generically identify the four different methods for estimating peak discharge. Each estimation method was used six times on the watershed and the resulting discharge estimates (in cubic feet per second) were recorded (Table 9.8). Table 9.8: Number of estimates for each method. method Freq 1 6 2 6 3 6 4 6 At first glance, the data do not appear to be independent either within- or among-groups as the same methods were applied to the same watershed. However, the single watershed is the engineers population of interest; thus, this form of data collection is not problematic unless the engineer (or you) attempt to make strict inferences to other watersheds. In addition, measurements from the same method may seem dependent, but this is the factor that is being examined, thus this is not a within-group dependency issue. Note careful discussion of independence here. Variances among estimation methods for the untransformed data appear to be non-constant (Levenes p=0.0136; Figure 9.6-Right). The residuals appear normally distributed (Anderson-Darling p=0.4106) or at least only slightly skewed (Figure 9.6-Left) and there are no significant outliers (outlier test p=0.3572). Unequal variances violates a critical assumption so transforming the discharge estimates was considered. Figure 9.6: Histogram of residuals (Left) and boxplot of residual (Right) from the one-way ANOVA on untransformed peak discharge data. A square root transformation for the peak discharge estimates resulted in equal variances (Levenes p=0.8680; Figure 9.7-Right), normal residuals (Anderson-Darling p=0.4207) or at least only slightly skewed (Figure 9.7-Left), and no significant outliers (outlier test p&gt;1). Thus, the assumptions of the One-Way ANOVA model appear to have been adequately met on the square-root scale. Figure 9.7: Histogram of residuals (Left) and boxplot of residual (Right) from the one-way ANOVA on square root transformed peak discharge data. There appears to be a significant difference in mean square root peak discharge among the four methods (p&lt;0.00005; Table 9.9). Note the careful use of the transformation name here. Table 9.9: ANOVA results for the square root peak discharge analysis by estimationg method. Df Sum Sq Mean Sq F value Pr(&gt;F) method 3 32.684 10.895 81.049 0 Residuals 20 2.688 0.134 Tukey multiple comparisons indicate that no two mean square root peak discharges were equal (p0.0046; Table 9.10). It appears that the mean square root of estimated peak discharge increases from Method 1 to Method 2 to Method 3 to Method 4. For example, the mean square root of estimated peak discharge was between 2.471 and 3.656 units greater for Method 4 than for Method 1 (Table 9.10). Table 9.10: Tukeys multiple comparisons for differences in square root peak discharge for different estimation methods. contrast estimate lower.CL upper.CL p.value 1 - 2 -0.825 -1.417 -0.232 0.0046 1 - 3 -2.046 -2.638 -1.453 0.0000 1 - 4 -3.063 -3.656 -2.471 0.0000 2 - 3 -1.221 -1.814 -0.629 0.0001 2 - 4 -2.239 -2.831 -1.646 0.0000 3 - 4 -1.018 -1.610 -0.425 0.0006 These results indicate that the mean peak discharge estimate differed significantly, with a higher peak discharge estimated for each method from Method 1 to Method 4 (Figure 9.8). It is possible with a square root to back-transform means, but not differences in means. Figure 9.8: Back-transformed mean (with 95% confidence interval) estimates of peak discharge (cubic feet per second, cfs) by each estimation method. The transformed means were different among all estimationg methods. R Code and Results PD &lt;- read.csv(&quot;http://derekogle.com/Book207/data/PeakDischarge.csv&quot;) PD$method &lt;- factor(PD$method) lm.pd &lt;- lm(discharge~method,data=PD) xtabs(~method,data=PD) assumptionCheck(lm.pd) assumptionCheck(lm.pd,lambday=0.5) PD$sqrtdischarge &lt;- sqrt(PD$discharge) lm.pdt &lt;- lm(sqrtdischarge~method,data=PD) anova(lm.pdt) mc.pdt &lt;- emmeans(lm.pdt,specs=pairwise~method,tran=&quot;sqrt&quot;) ( mcsum.pdt &lt;- summary(mc.pdt,infer=TRUE) ) ( mcsum.pdbt &lt;- summary(mc.pdt,infer=TRUE,type=&quot;response&quot;) ) ggplot() + geom_jitter(data=PD,mapping=aes(x=method,y=discharge), alpha=0.25,width=0.05) + geom_errorbar(data=mcsum.pdbt$emmeans, mapping=aes(x=method,y=response,ymin=lower.CL,ymax=upper.CL), size=2,width=0) + geom_point(data=mcsum.pdbt$emmeans,mapping=aes(x=method,y=response), size=2,pch=21,fill=&quot;white&quot;) + labs(x=&quot;Estimation Method&quot;,y=&quot;Peak Discharge (cfs)&quot;) + theme_NCStats() This example is directly from https://dzchilds.github.io/stats-for-bio/ "],["ANOVA2Foundations1.html", "Module 10 Two-Way Conceptual Foundation 10.1 Two Factors 10.2 Interaction Effects 10.3 Main Effects 10.4 Advantages of CCFD", " Module 10 Two-Way Conceptual Foundation In contrast to a one-way ANOVA, a two-way ANOVA allows for simultaneously determining whether the mean of a quantitative response variable differs according to the levels of two grouping variables or an interaction between the two. For example, consider the following situations: Determining the effect of UV-B light intensity and tadpole density on mean growth of plains leopard frog (Rana blairi) tadpoles (Smith et al. 2000). Whether mean monoterpene levels in Douglas firs (Pseudotsuga menziesii) differ depending on exposure to ambient or elevated levels of CO2 and ambient or elevated levels of temperature (Snow et al. 2003). Whether mean microcystin-LR concentration (a common cyanotoxin) differed by time (days) and exposure type (control (no exposure), direct exposure, or indirect exposure) to duckweed (Lemna gibba) (LeBlanc et al. 2005). Determining if the mean Na-K-ATPase activity level differs among locations of the kidney and between normal and hypertensive rats (Garg et al. 1985). The theory and application of two-way ANOVAs are discussed in this module. The presentation here depends heavily on the foundational material discussed for One-Way ANOVAs. 10.1 Two Factors It is both possible and advantageous to manipulate more than one factor at a time to determine the effect of those factors on the response variable. For example, an experimenter may manipulate both the density of tadpoles and the level of exposure to UV-B light to determine the effect of both of these explanatory variables on body mass of tadpoles. The design of such an experiment and why it is beneficial to simultaneously manipulate two factors, as compared to varying each of those factors alone in two separate experiments, is examined in this section. 10.1.1 Design Suppose that we are interested in the impact of two different UV-B light intensity levels (simply called High and Low) and the density of tadpoles (1, 2, and 4 individuals per tank) on the body mass (g) of tadpoles. Further suppose that we have access to 90 tanks in which to conduct this work, where each tank will be stocked with a certain number of tadpoles and exposed to a certain UV-B light intensity. After a period of time the body mass of the tadpoles will be recorded (as a surrogate for growth). Note here that in experiments like this the explanatory variables are often called factors. Thus, we are considering two factors in this study. Observational studies usually will use explanatory variable rather than factor. One way to design this study would be to separate the 90 tanks available for the experiment into two sets. One set of tanks would be used to determine the effect of UV-B light intensity on tadpole body mass and the other set of tanks would be used to determine the effect of density on tadpole body mass. The tanks within each group would be randomly allocated to the different levels of each of the factors. This is called a one factor at a time (OFAT) design and might look like that shown in Table 10.1. Table 10.1: Schematic of two OFAT experiments with UV-B light intensity and density of tadpoles. Tank numbers correspond to the random allocation of individual tanks to each treatment. UVB Tanks High 37, 73, 63, 80, 76, 36, 67, 53, 83, 31, 29, 88, 62, 35, 21, 68, 17, 46, 89, 81, 26, 48 Low 85, 40, 30, 71, 60, 11, 47, 51, 24, 32, 54, 52, 23, 1, 38, 44, 78, 50, 3, 16, 9, 20 Density Tanks 1 Tadpole 74, 57, 58, 7, 8, 86, 56, 43, 82, 90, 39, 27, 49, 77, 12 2 Tadpoles 61, 64, 15, 65, 6, 70, 10, 22, 14, 55, 72, 33, 25, 45, 42 4 Tadpoles 66, 59, 19, 28, 34, 18, 69, 4, 2, 79, 75, 5, 84, 87, 13 In contrast, an alternative way to design this study would be to create treatments37 where each level of one factor is combined with each level of the other factor. In this example, there would be six treatments as two levels of UV-B light intensity would be crossed with three levels of tadpole density. Tanks would be randomly allocated to treatments. This type of design is called a completely crossed factorial design (CCFD) and might look like that shown in Table 10.2. Table 10.2: Schematic depicting the crossing of three levels of UV-B light intensity with two levels of tadpole density to produce six treatments. Numbers in each cell represent individual tanks exposed to that treatment. UVB Density Tanks High 1 Tadpole 37, 73, 63, 80, 76, 36, 67, 53, 83, 31, 29, 88, 62, 35, 21 High 2 Tadpoles 68, 17, 46, 89, 81, 26, 48, 85, 40, 30, 71, 60, 11, 47, 51 High 4 Tadpoles 24, 32, 54, 52, 23, 1, 38, 44, 78, 50, 3, 16, 9, 20, 41 Low 1 Tadpole 74, 57, 58, 7, 8, 86, 56, 43, 82, 90, 39, 27, 49, 77, 12 Low 2 Tadpoles 61, 64, 15, 65, 6, 70, 10, 22, 14, 55, 72, 33, 25, 45, 42 Low 4 Tadpoles 66, 59, 19, 28, 34, 18, 69, 4, 2, 79, 75, 5, 84, 87, 13 Completely crossed factorial design (CCFD): A study design where each level of one explanatory variable (or factor) is combined with each level of the other explanatory variable (or factor) to form groups (or treatments). 10.2 Interaction Effects An interaction among factors is said to exist if the effect of one explanatory variable on the mean response depends on the level of the other explanatory variable. For example, if the mean body mass of the tadpoles increased across densities in the low light intensity treatments but decreased across densities in the high light intensity treatments (Figure 10.1-Left), then an interaction between the density of tadpoles and UV-B light intensities is said to exist. However, if the pattern among tadpole densities is the same in both the low and high density light intensities (Figure 10.1-Right), then no interaction exists between the factors. Figure 10.1: Interaction plot (mean growth rate for each treatment connected within the UV-B light intensity levels) for the tadpole experiment illustrating a hypothetical interaction effect (Left) and a lack of an interaction effect (Right). Interaction effect: When the effect of one explanatory variable (or factor) on the mean response is significantly different among the levels of the other explanatory variable (or factor). The tell-tale sign of an interaction effect is if you describe the effect of a factor on the mean response differently depending on the level of the other explanatory variable. For example, in Figure 10.2-Left the effect of tadpole density on mean body mass is increasing in the high UV-B light intensity treatments, but is neither increasing or decreasing in the low UV-B light intensity treatments. The fact that density had a different effect on mean body mass in the different UV-B light treatments tells of an interaction effect. In Figure 10.2-Right mean body mass increases with increasing density but at a very different rate (at least for densities of 1 to 2 tadpoles per tank). Again, this is a different conclusion about the effect of density on mean body mass depending on level of UV-B light; thus this represents an interaction effect. Figure 10.2: Interaction plot (mean growth rate for each treatment connected within the UV-B light intensity levels) for the tadpole experiment illustrating hypothetical interaction effects. In Module 11 we will develop objective mathematical measures of whether an interaction effect exists.38 However, in addition to the concept above, an interaction effect will look like means that are connected for levels of one explanatory variable that do not track together for levels of the other explanatory variable. For example, in Figure 10.2-Left the blue line (connecting high UV-B light treatments) is steadily increasing whereas the red line (connecting low UV-B light treatments) is steadily flat  i.e., they dont track together, which indicates an interaction effect. The two lines also do not track together in Figure 10.2 - Right. An interaction effect is evident if the lines in an interaction plot do not largely track together. 10.3 Main Effects A main effect occurs when there is a difference in the mean response among levels of an explanatory variable that is consistent across the levels of the other explanatory variable. Thus, by definition, a main effect cannot exist if an interaction effect exists. Thus, do not try to identify main effects when an interaction is present. Do not identify main effects when an interact effect exists. For example, Figure 10.1-Right showed no significant interaction; thus, main effects can be assessed. In that case, the main effect of density is that mean body mass decreased when density increased from 1 to 2 tadpoles per tank and continued to decrease at a slower rate when the density increased from 2 to 4 tadpoles per tank. From the same figure, the effect of UV-B light density is that mean body mass was greater at a low than at a high UV-B intensity.39 Main effects can also be determined for both interaction plots in Figure 10.3. The main effect for density in Figure 10.3-Left is the same as that described for Figure 10.1-Right. However, in this case there is no UV-B main effect because there is no separation in means by UV-B light level at each level of density. In other words the red line for low UV-B light and the blue line for high UV-B light are (nearly) directly on top of each other, so there is no difference in means due to UV-B light and thus no main effect of UV-B light. Figure 10.3: Interaction plot (mean growth rate for each treatment connected within the UV-B light intensity levels) for the tadpole experiment illustrating hypothetical lack2 of interaction effects. In Figure 10.3-Right, there is no main effect of tadpole density as the mean body mass at each density within each UV-B light level is the same; i.e., mean body mass does not differ by density. However, there is a UV-B light main effect as mean body mass at the high UV-B light intensity is always40 greater than mean body mass at the low UV-B light intensity. As a reminder, only assess main effects if there is no interaction effect. Visually a main effect of the factor shown on the x-axis will be evident if the lines connecting the means are not horizontal (i.e., the means differ). In contrast, a main effect of the factor not shown on the x-axis (but shown as a legend) will be evident if the lines connecting the means are not right on top of each other. 10.4 Advantages of CCFD A two-factor CCFD has two major advantages over two separate OFAT experiments. First, the CCFD allocates individuals more efficiently than the two OFAT experiments. For example, in the CCFD of the tadpole experiment, all 90 individuals were used to identify differences among the light intensities AND all 90 individuals were used to identify differences among the densities of tadpoles. However, in the OFAT experiments, only 44 individuals41 were used to identify differences among the light intensities and only 45 individuals were used to identify differences among the tadpole densities. CCFD studies effectively increase the sample size for identifying effects on the response variable. Efficiency in allocation of individuals effectively leads to an increased sample size for determining the effect of any one factor. An increased sample size means more precise estimates of means42 and more statistical power. Statistical power is the probability of correctly rejecting a false null hypothesis. In lay terms, statistical power is the ability to correctly identify a difference in means when a difference in means really exists. Relatedly, the increased sample size means that smaller effect sizes can be identified. In practice this means that smaller differences in means will be found to be statistically different. In yet other words, a smaller signal can be detected. Finally, the increased efficiency means that the same power and detectable effect size can be obtained with a smaller overall sample size and, thus, lower costs. More efficient use of individuals in CCFD studies results in increased power and increased ability to detect small effect sizes, or lower costs to obtain the same power and effect size detectability. A second advantage of CCFD studies is that they allow researchers to identify if an interaction effect exists between the two explanatory variables. An interaction effect cannot be detected in OFAT studies because the two explanatory variables are not considered simultaneously. The combination of levels is often called a treatment in an experiment. In an observational study it would just be called a group. That is, we will use a p-value. The blue line was always below the red line by roughly the same amount. For each density. One individual was not used in order to have equal numbers of individuals in each treatment. That is, a reduced SE "],["ANOVA2Foundations2.html", "Module 11 Two-Way Analytical Foundation 11.1 Terminology 11.2 Total and Within SS, df, and MS 11.3 Among SS, df, and MS 11.4 ANOVA Table", " Module 11 Two-Way Analytical Foundation In this module we will examine the analytical foundation of a Two-Way ANOVA. In many ways, this foundation is very similar to that for the One-Way ANOVA. However, there are some striking differences. The similarities and differences are discussed here. 11.1 Terminology 11.1.1 Definitions Some terminology must be developed before discussing the objective criteria for determining the significance of main and interaction effects in a Two-Way ANOVA. The tadpole body mass study discussed in Module 10 was an experiment with two factors: UV-B light intensity with two levels (High and Low) and the density of tadpoles with three levels (1, 2, and 4 tadpoles). The combination of these two factors created six treatments with 15 individuals or replicates per treatment.43 11.1.2 Graphing Two-factor studies can be visualized with the response variable on the y-axis, levels of one factor on the x-axis, and levels of the other factor shown with different colors or symbols. It does not make a difference which factor is on the x-axis, though putting the factor with more levels on the x-axis makes for a less cluttered graph. In this module, two graphs will often be shown side-by-side. These are the same data but the role of the factor variables in the plot are reversed. For example, Figure 11.1-Left has tadpole density on the x-axis with different colors for the UV-B light levels and Figure 11.1-Right has UV-B light intensity on the x-axis with different colors for the tadpole densities. Figure 11.1: Tadpole body mass by density and UV-B light intensity factors. The points are jittered with respect to the x-axis so that each point can be seen. The two panels differ only in which factor variable is displayed on the x-axis. 11.1.3 Symbols In a two-factor study, one of the factors is generically labeled as Factor A and the other factor is generically labeled as Factor B. Ultimately it does not make a difference which factor is considered first. In this example, tadpole density will be the first (A) factor and UV-B light intensity will be the second (B) factor. Factor A has \\(a\\) levels and Factor B has \\(b\\) levels. In the tadpole example, \\(a\\)=3 (1, 2, and 4 tadpoles per tank) and \\(b\\)=2 (High and Low UV-B light intensity). We use \\(i\\) to index the first (A) factor and \\(j\\) to index the second (B) factor. Thus, \\(i\\) varies from 1 (first level) to \\(a\\) (last level) and \\(j\\) varies from 1 to \\(b\\). For the sake of simplicity the same number of replicates are used in each treatment.44 With this \\(m\\) is the number of replicates per treatment. In the tadpole example \\(m\\)=15. We use \\(k\\) as an index for individuals within a treatment. Thus, \\(k\\) varies from 1 to \\(m\\) for each treatment. With these definitions, the response variable recorded on the \\(k\\)th individual in the treatment defined by the \\(i\\)th level of Factor A and the \\(j\\)th level of the Factor B is denoted by \\(Y_{ijk}\\). For example, the body mass of tadpoles in the seventh tank (\\(k\\)=7) that received 1 tadpole (\\(i\\)=1) and low UV-B light (\\(j\\)=2) would be \\(Y_{127}\\) (Figure 11.2). Figure 11.2: Tadpole body mass by density and UV-B light intensity factors. The points are jittered with respect to the x-axis so that each point can be seen. The two panels differ only in which factor variable is displayed on the x-axis. The mean response for the \\(i\\)th level of Factor A and the \\(j\\)th level of Factor B is denoted by \\(\\overline{Y}_{ij\\cdot}\\). The \\(\\overline{Y}_{ij\\cdot}\\) are called treatment means in an experiment or group means in an observational study. The dot in \\(\\overline{Y}_{ij\\cdot}\\) replaces the subscript in \\(Y_{ijk}\\) that was summed across when computing the mean. Treatment means are calculated by summing across individuals in a treatment (the \\(k\\) subscript), thus the \\(k\\) subscript is replaced with a dot. As an example, the treatment mean body mass for tadpoles in the 1 tadpole density (\\(i\\)=1) and low UV-B light intensity (\\(k\\)=2) would be \\(\\overline{Y}_{12\\cdot}\\) (Figure 11.3).45 Figure 11.3: Same as previous figure except that six treatments means are shown with horizontal blue segments. The mean response for the \\(i\\)th level of Factor A is given by \\(\\overline{Y}_{i\\cdot\\cdot}\\). These level means are calculated by first summing individuals in each treatment (the \\(k\\) subscript) and then summing across UV-B light levels (the \\(j\\) subscript); thus, both the \\(k\\) and \\(j\\) subscripts are replaced with a dot. For example, the mean body mass for tadpoles in the 1 tadpole density (\\(i\\)=1) is \\(\\overline{Y}_{1\\cdot\\cdot}\\) (Figure 11.4-Left). Figure 11.4: Same as previous figure except that three density level means are shown on the left and two UV-B light level means are shown on the right with horizontal orange segments. Similarly, the mean response for the \\(j\\)th level of Factor B is given by \\(\\overline{Y}_{\\cdot j\\cdot}\\). These level means are calculated by first summing individuals in each treatment (the \\(k\\) subscript) and then summing across tadpole density levels (the \\(i\\) subscript); thus, both the \\(k\\) and \\(i\\) subscripts are replaced with a dot. For example, the mean body mass for tadpoles in the low UV-B light intensity (\\(j\\)=2) is \\(\\overline{Y}_{\\cdot2\\cdot}\\) (Figure 11.4-Right). Finally, the mean response regardless of level of any factor is given by \\(\\overline{Y}_{\\cdot\\cdot\\cdot}\\) and is called the grand mean (Figure 11.5). The grand mean is calculated by summing individuals in each treatment, then summing across UV-B light intensities, and then summing across tadpole densities; thus, all three subscripts are replaced with a dot. Figure 11.5: Same as previous figure except that the grand means is shown with a horizontal red segment in each panel. In symbols for means, dots replace lettered subscripts for subscripts summed across when calculating the mean. 11.2 Total and Within SS, df, and MS 11.2.1 Models The total and within SS and df46 are effectively the same with a Two-Way ANOVA as with a One-Way ANOVA, though their calculation may look more complicated. In a Two-Way ANOVA, the full model uses a separate mean for each treatment group and the simple model uses a single grand mean for all treatment groups. In essence, the simple model says that each treatment mean should be modeled by a common mean (Figure 11.6-Left), whereas the full model says that each treatment mean should be modeled by a separate mean (Figure 11.6-Right). It should be evident that this is the same simple and full models used in a One-Way ANOVA. Figure 11.6: Tadpole body mass by density and UV-B light levels (different colored points) with the grand mean of the simple model (Left) and the treatments means of the full model (Right) shown. 11.2.2 SSTotal, dfTotal, and MSTotal As discussed with a One-Way ANOVA, SSTotal measures the lack-of-fit of the observations around the simple model of a grand mean. Visually, this computation sums the square of the vertical distance of each point from the red line at the grand mean in Figure 11.6-Left; i.e., \\[ \\text{SS}_{\\text{Total}} = \\sum_{i=1}^{a}\\sum_{j=1}^{b}\\sum_{k=1}^{m}\\left(Y_{ijk}-\\overline{Y}_{\\cdot\\cdot\\cdot}\\right)^{2} \\] This formula may appear intimidating but focus on the part being summed  \\(\\left(Y_{ijk}-\\overline{Y}_{\\cdot\\cdot\\cdot}\\right)^{2}\\). This is simply the square of each observation (\\(Y_{ijk}\\)) from the simple model of a grand mean (\\(\\overline{Y}_{\\cdot\\cdot\\cdot}\\)). The three summations simply mean47 to sum across individuals, then across levels of Factor B, and then across levels of Factor A. In other words, sum the squared residuals across all individuals, exactly what you did for a One-Way ANOVA. The total degrees-of-freedom is still the total number of individuals (\\(n\\)) minus 1 because only one parameter (the grand mean) is being used in the simple model. Note, however, that \\(n=abm\\), or the number of treatments (\\(ab\\)) times the number of replicates (or individuals) per treatment. Thus dfTotal=\\(abm-1\\). The MSTotal is (as always) SSTotal divided by dfTotal and represents the variance of individuals around the grand mean (or simple model). 11.2.3 SSWithin, dfWithin, and MSWithin Not surprisingly, SSWithin measures the lack-of-fit of the observations around the full model of separate means for each treatment. Visually, this computation sums the square of the vertical distance of each point from the blue line at the corresponding treatment mean in Figure 11.6-Right; i.e., \\[ \\text{SS}_{\\text{Within}} = \\sum_{i=1}^{a}\\sum_{j=1}^{b}\\sum_{k=1}^{m}\\left(Y_{ijk}-\\overline{Y}_{ij\\cdot}\\right)^{2} \\] Again focus on the part of the formula being summed  \\(\\left(Y_{ijk}-\\overline{Y}_{ij\\cdot}\\right)^{2}\\). This is the square of each observation (\\(Y_{ijk}\\)) from each treatment mean (\\(\\overline{Y}_{ij\\cdot}\\)). The three summations are the same as for SSTotal; i.e., sum the squared residuals across **all* individuals. The within degrees-of-freedom is still the total number of individuals (\\(n\\)) minus the number of groups, because a separate mean is used for each treatment/group in the full model. Thus dfWithin=\\(abm-ab\\) or dfWithin=\\(ab(m-1)\\). The MSWithin is (as always) SSWithin divided by dfWithin and represents the variance of individuals around the treatment/group means (or full model). 11.3 Among SS, df, and MS The SSAmong is usually found by subtraction (i.e., SSTotal-SSWithin), which again indicates that SSAmong is the improvement in fit48 between the full and simple models. It can also be shown that \\[ \\text{SS}_{\\text{Among}} = m\\sum_{i=1}^{a}\\sum_{j=1}^{b}\\left(\\overline{Y}_{ij\\cdot}-\\overline{Y}_{\\cdot\\cdot\\cdot}\\right)^{2} \\] Again focus on the part being summed, which is the square of the difference between each treatment mean (\\(\\overline{Y}_{ij\\cdot}\\)) and the grand mean (\\(\\overline{Y}_{\\cdot\\cdot\\cdot}\\); Figure 11.7). Thus, as before, SSAmong measures how different the treatment means are. The rest of the formula simply sums the differences in means across all treatments49 and then multiplies by \\(m\\) to account for the \\(m\\) individuals that went into calculating each treatment mean.50 Figure 11.7: Mean tadpole body mass by density and UV-B light levels (not differentiated) with the grand mean of the simple model (red horizontal line) and the treatments means of the full model (blue horizontal lines) shown. Vertical dashed lines are residuals between the two types of means. Note that the y-axis scale is different than all previous plots. The among df may be obtained by subtraction (i.e., dfAmong=dfTotal-dfWithin), which indicates that dfAmong measures the difference in complexity51 between the simple and full models. It can also easily be shown that dfAmong=\\(ab-1\\), or the number of treatments/groups minus 1, which is exactly as it was with the One-Way ANOVA. Finally, MSAmong is equal to SSAmong divided by dfAmong and represents the variance of treatment/group means. Thus, the larger MSAmong is the more different the treatment/group means are. Of course, an F-ratio test statistic and corresponding p-value should be calculated to determine if MSAmong is large relative to MSWithin and whether we should conclude that there is a significant difference in treatment/group means. 11.3.1 Partitioning SSAmong To this point, everything in a Two-Way ANOVA has been the same as it was for a One-Way ANOVA, just with a few more symbols. However, an issue occurs if H0 is rejected in favor of HA. If this occurs, then we would conclude that there is a significant difference in treatment/group means. However, as discussed in Module 10, a difference in treatment means could be related to differences in Factor A level means, differences in Factor B level means, or differences in means due to the interaction of Factor A and Factor B. Which factor, factors, or their interaction is responsible for the difference in treatments means must be teased out in an objective way. Just as SSTotal partitioned into parts (i.e., SSAmong and SSWithin), SSAmong partitions into parts due to differences in the levels of Factor A, differences in the levels of Factor B, and differences in the interaction among the two factors. In other words, \\[ SS_{Among} = SS_{A} + SS_{B} + SS_{A:B} \\] where A:B represents the interaction between Factor A and Factor B. It can be shown that \\[ \\text{SS}_{\\text{A}} = mb\\sum_{i=1}^{a}\\left(\\overline{Y}_{i\\cdot\\cdot}-\\overline{Y}_{\\cdot\\cdot\\cdot}\\right)^{2} \\] Again, focus on the part that is summed, which is the square of the differences in the Factor A level means and the grand mean (Figure 11.8-Left). Thus, SSA measures how different the Factor A levels means are, just as you would expect. Note that the rest of the formula says that you must sum across the Factor A levels and then multiply by the number of individuals that went into calculating the Factor A levels means (i.e., \\(m\\) individuals across \\(b\\) levels of Factor B). Figure 11.8: Mean tadpole body mass by density and UV-B light levels (not differentiated) with the grand mean of the simple model (red horizontal line) and the level means shown for the tadpole densities (Left) or UV-B light intensities (Right). Vertical dashed lines are residuals between respective level means and the grand means. Similarly (Figure 11.8-Left), \\[ \\text{SS}_{\\text{B}} = ma\\sum_{j=1}^{b}\\left(\\overline{Y}_{\\cdot j\\cdot}-\\overline{Y}_{\\cdot\\cdot\\cdot}\\right)^{2} \\] The interaction SS is difficult to describe or to visualize, but it is easily calculated by subtraction: \\[ SS_{A:B} = SS_{Among} - SS_{A} - SS_{B} \\] The dfAmong partitions in the same way that SSAmong partitions; i.e., dfAmong=dfA+dfB+dfA:B. Further, dfA=\\(a-1\\) and dfB=\\(b-1\\); their respective number of level means minus 1, as you would expect. The dfA:B is most easily found by subtraction (dfA:B=dfAmong-dfA-dfB), but is also dfA:B=\\((a-1)(b-1)\\).) Of course, MSA, MSB, and MSA:B are all computed by dividing the corresponding SS by the df. Thus, MSA is the variance explained by Factor A, or the difference in the Factor A level means. If MSA is large relative to MSWithin then there is likely a difference in the Factor A level means and there is a so-called Factor A main effect. The same argument can be made for Factor B. The MSA:B is more difficult to describe, but can be thought of as the variance explained by the interaction between Factor A and Factor B. If MSA:B is large relative to MSWithin then there is likely a difference in means due to an interaction between factors A an B and there is a so-called interaction effect. 11.4 ANOVA Table The F-ratio test statistics and corresponding p-values for the Factor A and Factor B main effects and the interaction between the two are summarized in an ANOVA table. Table 11.1: An ANOVA table for testing if mean body mass of tadpoles differs by density, UV-B light intensity, or the interaction between density and UV-B light. Note that the Total row is not shown. Df Sum Sq Mean Sq F value Pr(&gt;F) density 2 2.434 1.217 10.381 0.0001 uvb 1 0.300 0.300 2.563 0.1131 density:uvb 2 0.299 0.149 1.275 0.2847 Residuals 84 9.846 0.117 The following observations or conclusions can be drawn from Table 11.1. There are three levels of density (i.e., one more that dfdensity). There are two levels of UV-B light intensity (i.e., one more that dfuvb). There are 90 individuals (or replicates) (i.e., one more than dfTotal=2+1+2+84=89.) The variance of individuals around the grand mean is MSTotal=0.145 (=\\(\\frac{2.434+0.300+0.299+9.846}{2+1+2+84}\\) = \\(\\frac{12.879}{89}\\)). The variance of individuals around the treatment means is MSWithin=0.117. The variance of treatment means around the grand mean is MSAmong=0.607 (=\\(\\frac{2.434+0.300+0.299}{2+1+2}\\) = \\(\\frac{3.033}{5}\\)). The variance of density level means around the grand mean is MSdensity=1.217. The variance of UV-B level means around the grand mean is MSuvb=0.300. There is not a significant interaction effect (p=0.2847). There is not a significant UV-B light intensity main effect (p=0.1131). There is a significant tadpole density effect (p=0.0001), which means that the mean body mass differs for at least one pair of tadpole densities.52 These terms are not defined specifically here as it is assumed that you were introduced to basic experimental design terms in your introductory statistics course. An experiment where each treatment has the same number of replicates is called a balanced design. This figure is similar to the interaction plots from Module ??. Thus, also the MS. Read summations from right-to-left  in this case the summation across \\(k\\) and then across \\(j\\) and then across \\(i\\) Really, the reduction in lack-of-fit First across levels of Factor B and then across levels of Factor A. Multiplying by m scales the summation to the same number of individuals as summed in SSTotal and SSWithin; i.e., allowing a comparison of apples to apples. Difference in number of estimated parameters in the models. We will discuss methods to identify which pairs differ in Module 12. "],["ANOVA2Analysis.html", "Module 12 Two-Way Analysis 12.1 Model Fitting in R 12.2 Assumptions 12.3 Main and Interaction Effects (ANOVA Table) 12.4 Multiple Comparisons 12.5 Graphing Results", " Module 12 Two-Way Analysis In this module, a thorough Two-Way ANOVA will be performed using the experiment introduced in Module 11, where the effect of tadpole density and UV-B light intensity on tadpole body mass was examined. 12.1 Model Fitting in R The data are loaded into R below. Because density was recorded as a number (i.e., 1, 2, and 4) rather than as an obvious grouping (i.e., one, two, and four), it must be explicitly converted to a factor before it can be used in a Two-Way ANOVA Model. tad &lt;- read.csv(&quot;http://derekogle.com/Book207/data/Tadpoles.csv&quot;) tad$density &lt;- factor(tad$density) str(tad) #R&gt; &#39;data.frame&#39;: 90 obs. of 3 variables: #R&gt; $ uvb : chr &quot;High&quot; &quot;High&quot; &quot;High&quot; &quot;High&quot; ... #R&gt; $ density: Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;4&quot;: 1 1 1 1 1 1 1 1 1 1 ... #R&gt; $ mass : num 0.91 0.65 1.58 0.98 1.07 0.84 0.88 1.47 0.94 0.72 ... An explanatory (or factor) variable must be a character or factor type in R before it can be used in lm() for a Two-Way ANOVA. When performing a Two-Way ANOVA with lm() the first argument must be a formula of the form response~factorA+factorB+factorA:factorB53 where response is the response variable, factorA and factorB are the two factor variables, and factorA:factorB tells lm() to include the interaction between the two factor variables. Thus, the Two-Way ANOVA model for the tadpole experiment is fit with lm1 &lt;- lm(mass~density+uvb+density:uvb,data=tad) As usual, the results are saved to an object that will be used to check assumptions, create an ANOVA table, and make multiple comparisons. 12.2 Assumptions The assumptions for a Two-Way ANOVA are exactly the same as for a One-Way ANOVA as shown in Module 7. Thus, as described in that module, assumptionCheck() is used with the saved lm() object to compute tests and create graphics to assess the assumptions. assumptionCheck(lm1) From these results it is seen that the variances across all treatments are equal (Levenes p=0.0776), the residuals are normally distributed (p=0.3332), and there are no significant outliers (p&gt;1). There was not much information given previously about this experiment, but as along as the tanks of tadpoles were kept separate such that no tank could impact any other tank then independence is likely adequately met. The analysis can continue with the untransformed data because all assumptions are adequately met. If the equal variances and normality assumptions (and possibly the no outliers assumption) are not met then try to transform the response variable to a scale where those assumptions are met. As before, start with the log transformation. 12.3 Main and Interaction Effects (ANOVA Table) The ANOVA table is extracted from the lm() object with anova(). anova(lm1) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: mass #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; density 2 2.4337 1.21686 10.3814 9.355e-05 #R&gt; uvb 1 0.3004 0.30044 2.5632 0.1131 #R&gt; density:uvb 2 0.2989 0.14947 1.2752 0.2847 #R&gt; Residuals 84 9.8461 0.11722 These results indicate that the interaction effect is insignificant (p=0.2847). Because the interaction term is insignificant, the main effects can be interpreted. The density main effect is strongly significant (p=0.0001), but the UV-B main effect is not significant (p=0.1131). Thus, it appears that the mean body mass of tadpoles differs among some of the density treatments but not between the two UV-B light intensities. Do not address main effects if there is a significant interaction effect. 12.4 Multiple Comparisons 12.4.1 Main Effects When an interaction is not present, as is the case here, then multiple comparisons can be conducted for factors related to any main effect that exists. However, multiple comparisons on the main effects are compromised by the interaction term in the model. This is seen by the warning from emmeans() below, where I tried to perform multiple comparisons for just the density main effect using lm1 that contains the interaction term. mc1 &lt;- emmeans(lm1,specs=pairwise~density) Thus, if the interaction term is not significant then you should fit a new model without the interaction term and then use that model when performing multiple comparisons. A model without an interaction term simply uses a formula of the form response~factorA+factorB in lm(). The ANOVA table is shown below to confirm that the interaction term is not in this new model. lm1_noint &lt;- lm(mass~density+uvb,data=tad) anova(lm1_noint) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: mass #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; density 2 2.4337 1.21686 10.3154 9.649e-05 #R&gt; uvb 1 0.3004 0.30044 2.5469 0.1142 #R&gt; Residuals 86 10.1450 0.11797 To assess main effects with multiple comparisons, first fit (and then use) a model without the insignificant interaction term. Multiple comparisons for a main effect factor variable are performed as described for a One-Way ANOVA in Section 6.3, but using the new model without the interaction term. mc1_noint &lt;- emmeans(lm1_noint,specs=pairwise~density) ( mc1sum_noint &lt;- summary(mc1_noint,infer=TRUE) ) #R&gt; $emmeans #R&gt; density emmean SE df lower.CL upper.CL t.ratio p.value #R&gt; 1 1.157 0.0627 86 1.033 1.282 18.456 &lt;.0001 #R&gt; 2 0.829 0.0627 86 0.704 0.953 13.215 &lt;.0001 #R&gt; 4 0.791 0.0627 86 0.667 0.916 12.620 &lt;.0001 #R&gt; #R&gt; Results are averaged over the levels of: uvb #R&gt; Confidence level used: 0.95 #R&gt; #R&gt; $contrasts #R&gt; contrast estimate SE df lower.CL upper.CL t.ratio p.value #R&gt; 1 - 2 0.3287 0.0887 86 0.117 0.540 3.706 0.0011 #R&gt; 1 - 4 0.3660 0.0887 86 0.154 0.578 4.127 0.0002 #R&gt; 2 - 4 0.0373 0.0887 86 -0.174 0.249 0.421 0.9070 #R&gt; #R&gt; Results are averaged over the levels of: uvb #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 3 estimates #R&gt; P value adjustment: tukey method for comparing a family of 3 estimates Again, results for the individual means are in the $emmeans portion of the output and the results for differences in paired means are in the $contrasts portion. From these results, it is seen that the mean body mass of tadpoles in the 1 tadpole treatment is between 0.117 and 0.540 g greater than the mean for the 2 tadpole treatment (p=0.0011) and between 0.154 and 0.578 g greater than the mean for the 4 tadpole treatment (p=0.0002). The mean body mass of tadpoles did not significantly differ between the 2 and 4 tadpole treatments (p=0.9070). 12.4.2 Interaction Effects If an interaction effect had been present in the original Two-Way ANOVA model, multiple comparisons must be carried out to determine which pairs of treatment means differ. This is easily accomplished with emmeans() by using the interaction variable in the pairwise~ formula. For example, if lm1 had had a significant interaction term, then multiple comparisons for all pairs of treatments would be computed as follows. mc1 &lt;- emmeans(lm1,specs=pairwise~density:uvb) ( mc1sum &lt;- summary(mc1,infer=TRUE) ) #R&gt; $emmeans #R&gt; density uvb emmean SE df lower.CL upper.CL t.ratio p.value #R&gt; 1 High 1.023 0.0884 84 0.848 1.199 11.576 &lt;.0001 #R&gt; 2 High 0.784 0.0884 84 0.608 0.960 8.869 &lt;.0001 #R&gt; 4 High 0.797 0.0884 84 0.621 0.972 9.012 &lt;.0001 #R&gt; 1 Low 1.291 0.0884 84 1.116 1.467 14.608 &lt;.0001 #R&gt; 2 Low 0.873 0.0884 84 0.698 1.049 9.879 &lt;.0001 #R&gt; 4 Low 0.786 0.0884 84 0.610 0.962 8.892 &lt;.0001 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; #R&gt; $contrasts #R&gt; contrast estimate SE df lower.CL upper.CL t.ratio p.value #R&gt; 1 High - 2 High 0.2393 0.125 84 -0.1253 0.6039 1.914 0.4007 #R&gt; 1 High - 4 High 0.2267 0.125 84 -0.1379 0.5913 1.813 0.4631 #R&gt; 1 High - 1 Low -0.2680 0.125 84 -0.6326 0.0966 -2.144 0.2754 #R&gt; 1 High - 2 Low 0.1500 0.125 84 -0.2146 0.5146 1.200 0.8357 #R&gt; 1 High - 4 Low 0.2373 0.125 84 -0.1273 0.6019 1.898 0.4103 #R&gt; 2 High - 4 High -0.0127 0.125 84 -0.3773 0.3519 -0.101 1.0000 #R&gt; 2 High - 1 Low -0.5073 0.125 84 -0.8719 -0.1427 -4.058 0.0015 #R&gt; 2 High - 2 Low -0.0893 0.125 84 -0.4539 0.2753 -0.715 0.9797 #R&gt; 2 High - 4 Low -0.0020 0.125 84 -0.3666 0.3626 -0.016 1.0000 #R&gt; 4 High - 1 Low -0.4947 0.125 84 -0.8593 -0.1301 -3.957 0.0021 #R&gt; 4 High - 2 Low -0.0767 0.125 84 -0.4413 0.2879 -0.613 0.9898 #R&gt; 4 High - 4 Low 0.0107 0.125 84 -0.3539 0.3753 0.085 1.0000 #R&gt; 1 Low - 2 Low 0.4180 0.125 84 0.0534 0.7826 3.344 0.0152 #R&gt; 1 Low - 4 Low 0.5053 0.125 84 0.1407 0.8699 4.042 0.0016 #R&gt; 2 Low - 4 Low 0.0873 0.125 84 -0.2773 0.4519 0.699 0.9816 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 6 estimates #R&gt; P value adjustment: tukey method for comparing a family of 6 estimates As before, results for the individual means are in the $emmeans portion of the output and the results for differences in paired means are in the $contrasts portion. While this is not an appropriate for this hypothetical set of results, one can see in the results above that the mean body mass for tadpoles in the 4 tadpole and high UVB treatment is between 0.130 and 0.859 less than that for tadpoles in the 1 tadpole and low UVB treatment (p=0.0021). If a significant interaction term is present, then use multiple comparisons (with the model that has the interaction term) to determine which treatment means differ. 12.5 Graphing Results 12.5.1 Interaction Plot The results of a Two-Way ANOVA are summarizaed in an interaction plot whether a significant interaction was present in the results or not. An interaction plot, which was introduced in Module 10, shows each treatment mean with the levels of one factor on the x-axis and the levels of other factor shown with different colors or symbols and sometimes connected with a line. The interaction plots made in this and subsequent modules will also include a confidence intervals for each treatment mean. The method shown below requires having saved the summary of the multiple comparisons procedure applied to the model that included the interaction term. This was created above and saved as mc1sum. The data to be plotted is in the $emmeans portion of this object (shown below for convenience). mc1sum$emmeans #R&gt; density uvb emmean SE df lower.CL upper.CL t.ratio p.value #R&gt; 1 High 1.023 0.0884 84 0.848 1.199 11.576 &lt;.0001 #R&gt; 2 High 0.784 0.0884 84 0.608 0.960 8.869 &lt;.0001 #R&gt; 4 High 0.797 0.0884 84 0.621 0.972 9.012 &lt;.0001 #R&gt; 1 Low 1.291 0.0884 84 1.116 1.467 14.608 &lt;.0001 #R&gt; 2 Low 0.873 0.0884 84 0.698 1.049 9.879 &lt;.0001 #R&gt; 4 Low 0.786 0.0884 84 0.610 0.962 8.892 &lt;.0001 #R&gt; #R&gt; Confidence level used: 0.95 Specifically, we want to plot the results in the emmean column with the confidence intervals in lower.CL and upper.CL against one of the factor variables. One issue that arises is that the confidence intervals for the multiple treatments defined by one level of the variable on the x-axis overlap. Thus, before plotting, a dodge amount is defined with position_dodge() that will shift the levels slightly left and right to eliminate the overlap. The width= argument defines the amount of shift. You may need to play with this value to get the exact look that you want. pd &lt;- position_dodge(width=0.1) The summary graphic is constructed with the code below. This code is similar to what was used for the summary graphic of a One-Way ANOVA in Section 6.3. However, this code is somewhat simpler because the individual observations are not plotted to eliminate clutter. Further, note the use of mc1sum$emmeans as the data, the use of density (i.e., one of the factor variables) as x=, the use of uvb (i.e., the other factor variale) in group= (so it will be dodged) and color= (so it will be denoted with different colors), that geom_line() is placed first so that the points and confidence intervals will be on top of the connecting lines, that alpha= is used in geom_line() so that the lines are subtle, and the use of pd from position_dodge() above in geom_errobar() and geom_point(). ggplot(data=mc1sum$emmeans,mapping=aes(x=density,group=uvb,color=uvb, y=emmean,ymin=lower.CL,ymax=upper.CL)) + geom_line(position=pd,size=1.1,alpha=0.25) + geom_errorbar(position=pd,size=2,width=0) + geom_point(position=pd,size=2,pch=21,fill=&quot;white&quot;) + labs(y=&quot;Body Mass (g)&quot;,x=&quot;Density (Tadpoles per Tank)&quot;) + theme_NCStats() 12.5.2 Main Effects Plot Some researchers prefer to plot just the main effects when there is no significant interaction effect in the data. Such a plot is called a main effects plot and can be constructed similarly from the multiple comparison results using the model without an interaction term. Note that group=1 must be used as shown below so that geom_line() will work properly. ggplot(data=mc1sum_noint$emmeans, mapping=aes(x=density,group=1,y=emmean,ymin=lower.CL,ymax=upper.CL)) + geom_line(size=1.1,alpha=0.25) + geom_errorbar(size=2,width=0) + geom_point(size=2,pch=21,fill=&quot;white&quot;) + labs(y=&quot;Body Mass (g)&quot;,x=&quot;Density (Tadpoles per Tank)&quot;) + theme_NCStats() This exact model may also be entered with the shorthand response~factorA*factorB. "],["ANOVA2Summary.html", "Module 13 Two-Way Summary 13.1 Suggested Workflow 13.2 Expected Prices (No Transformation) 13.3 Blood Pressure (No Transformation) 13.4 Crayfish Foraging (Transformation)", " Module 13 Two-Way Summary Specific parts of a full Two-Way ANOVA analysis were described in Module 12. In this module, a workflow for a full analysis is offered and that workflow is demonstrated with several examples. 13.1 Suggested Workflow The following is a process for fitting a Two-Way ANOVA model. Consider this process as you learn to fit Two-Way ANOVA models, but dont consider this to be a concrete process for all models. Perform a thorough EDA of the quantitative response variable. Pay special attention to the distributional shape, center, dispersion, and outliers within each treatment/group. Show the sample size per group and comment on whether the study was balanced (i.e., same sample size per group) or not. Address the independence assumption. If this assumption is not met then other analysis methods must be used. Fit the untransformed ultimate full model (i.e., both main effects and the interaction effect) model with lm(). Check the other three assumptions for the untransformed model with assumptionCheck(). Check equality of variances with a Levenes test and residual plot. Check normality of residuals with a Anderson-Darling test and histogram of residuals. Check for outliers with an outlier test, residual plot, and histogram of residuals. If an assumption or assumptions are violated, then attempt to find a transformation where the assumptions are met. Use the trial-and-error method with assumptionCheck(), theory, or experience to identify a possible transformation. Always try the log transformation first. If only an outlier exists (i.e., there are equal variances and normal residuals) and no transformation corrects the outlier then consider removing the outlier from the data set. Fit the ultimate full model with the transformed response or reduced data set. Construct an ANOVA table for the full model with anova(). If a significant interaction exists then do NOT interpret the main effects!! If a significant interaction does NOT exist then interpret the main effects. Fit a new model without the insignificant interaction term. If an effect exists, then use a multiple comparison technique with emmeans() and summary() to identify specific differences. Describe specific differences using confidence intervals. If a significant interaction exists then perform multiple comparisons on the interaction term using the model that contained an interaction term. If a significant interaction does not exist then perform multiple comparisons for each factor for which a main effect exists using the model without an interaction term. Create a summary graphic of treatment means (i.e., an interaction plot) on the original scale with 95% confidence intervals using ggplot() and results from emmeans() using the model with an interaction term. Write a succinct conclusion of your findings. 13.2 Expected Prices (No Transformation) Managers of a retail store felt that the price that consumers would expect to pay for a product would be influenced by how much the product was promoted and the advertised amount of discount. To examine this, they gathered 160 volunteers (from different households) who would receive information about the stores products for a 10-week period. Each volunteer was randomly chosen to receive promotions about one particular product 1, 3, 5, or 7 times during that period and with an advertised discount of 10, 20, 30, or 40%. At the end of the 10-week period the researchers asked each participant to report the price they would expect to pay for the product.54 The statistical hypotheses to be examined were \\[ \\begin{split} H_{0}&amp;: \\text{no promotions effect}: \\mu_{1} = \\mu_{3} = \\mu_{5} = \\mu_{7} \\\\ H_{A}&amp;: \\text{promotions effect}: \\text{At least one pair of level means is different} \\end{split} \\] \\[ \\begin{split} H_{0}&amp;: \\text{no discount effect}: \\mu_{10} = \\mu_{20} = \\mu_{30} = \\mu_{40} \\\\ H_{A}&amp;: \\text{discount effect}: \\text{At least one pair of level means is different} \\end{split} \\] \\[ \\begin{split} H_{0}&amp;: \\text{no interaction effect} \\\\ H_{A}&amp;: \\text{interaction effect} \\end{split} \\] where \\(\\mu\\) is the mean expected price and the subscripts identify the levels of each factor as defined above. This study was balanced as the number of participants was the same in each combination of number of promotions and amount of discount (Table 13.1). Table 13.1: Number of participants in each combination of number of promotions and amount of discount. Discounts 10 20 30 40 Promotions 1 10 10 10 10 3 10 10 10 10 5 10 10 10 10 7 10 10 10 10 Variances among the treatments appear to be constant (Levenes p=0.4162) and the boxplots of residuals appear fairly similar (Figure 13.1-Right); the residuals appear to be approximately normally distributed (Anderson-Darling p=0.6255; Figure 13.1-Left); and there are no significant outliers (outlier test p=0.6285), though some residuals appear somewhat larger in some treatments (Figure 13.1-Right). Figure 13.1: Histogram of residuals (Left) and residual plot (Right) for a Two-way ANOVA of expected price for each combination of number of promotions and discount rate. The participants were not randomly selected for the study but they were specifically not from the same household and they were randomly allocated to the combination of number of promotions and discount amount. Thus, there is no reason to believe that individuals are connected either within or among treatments. Thus, the independence assumption appears to have also been met. These data will be examined with a Two-Way ANOVA without transformation because the assumptions have been adequately met. There does not appear to be a significant interaction effect (p=0.9121; Table 13.2). There does however appear to be main effects for both the number of promotions (p&lt;0.00005) and amount of discount (p&lt;0.00005). Table 13.2: Two-way ANOVA results for expected price among different numbers of promotions and amounts of discount. Df Sum Sq Mean Sq F value Pr(&gt;F) Promo 3 6.024 2.008 34.385 0.0000 Discount 3 7.824 2.608 44.661 0.0000 Promo:Discount 9 0.231 0.026 0.439 0.9121 Residuals 144 8.409 0.058 Tukeys multiple comparison results suggest that the mean expected price does not differ between when one and three promotions are used (p=0.9476) but does decline from three to five promotions (p&lt;0.00005) and from five to seven promotions (p=0.0079; Table 13.3). For example, the mean expected price drops between 0.13 and 0.41 dollars from three to five promotions and between 0.03 and 0.31 dollars from five to seven promotions. Table 13.3: Tukeys multiple comparisons of differences in mean expected price among all pairs of numbers of promotions. contrast estimate lower.CL upper.CL p.value 1 - 3 0.03 -0.11 0.17 0.9476 1 - 5 0.30 0.16 0.43 0.0000 1 - 7 0.47 0.33 0.61 0.0000 3 - 5 0.27 0.13 0.41 0.0000 3 - 7 0.44 0.30 0.58 0.0000 5 - 7 0.17 0.03 0.31 0.0079 Tukeys multiple comparison results suggest that the mean expected price differed between all pairs of amounts of discount (p0.0021; Table 13.4). The mean expected price declined between 0.06 and 0.33 dollars from a discount rate of 10% to 20% (p=0.0019) and between 0.26 and 0.53 dollars from a discount rate of 20% to 30% (p&lt;0.00005), but increased between 0.06 and 0.33 dollars from a discount rate of 30% to 40% (p=0.0021). Table 13.4: Tukeys multiple comparisons of differences in mean expected price among all pairs of amounts of discount. contrast estimate lower.CL upper.CL p.value 10 - 20 0.19 0.06 0.33 0.0019 10 - 30 0.59 0.45 0.73 0.0000 10 - 40 0.40 0.26 0.54 0.0000 20 - 30 0.40 0.26 0.53 0.0000 20 - 40 0.20 0.07 0.34 0.0011 30 - 40 -0.19 -0.33 -0.06 0.0021 From these results it appears that if there is no difference in mean expected price for three or less promotions, but after that the mean expected price drops with increasing numbers of promotions, regardless of the amount of discount offered. Regardless of the number of promotions, consumers expect to pay less with increasing amount of discount up to 30%, but the mean expected price increased when the discount was increased to 40% (Figure 13.2). Figure 13.2: Mean expected price for each combination of number of promotions and discount amount. R Code and Results d &lt;- read.csv(&quot;http://derekogle.com/Book207/data/Discount.csv&quot;) d$Promo &lt;- factor(d$Promo) d$Discount &lt;- factor(d$Discount) lm1.d &lt;- lm(Eprice~Promo+Discount+Promo:Discount,data=d) xtabs(~Promo+Discount,data=d) assumptionCheck(lm1.d) anova(lm1.d) lm1.d.noint &lt;- lm(Eprice~Promo+Discount,data=d) mc1.d.promo &lt;- emmeans(lm1.d.noint,specs=pairwise~Promo) ( mc1sum.d.promo &lt;- summary(mc1.d.promo,infer=TRUE) ) mc1.d.discount &lt;- emmeans(lm1.d.noint,specs=pairwise~Discount) ( mc1sum.d.discount &lt;- summary(mc1.d.discount,infer=TRUE) ) 13.3 Blood Pressure (No Transformation) Sodium (Na) plays an important role in the genesis of high blood pressure, and the kidney is the principal organ that regulates the amount of sodium in the body. The kidney contains the Na-K-ATPase enzyme, which is essential for maintaining proper sodium levels. If the enzyme does not function properly, then high blood pressure may result. The activity of this enzyme has been studied in whole kidneys, even though the kidney is known to contain many functionally distinct sites. To see whether any particular site of Na-K-ATPase activity was abnormal with hypertension, Garg et al. (1985) studied Na-K-ATPase activity at different sites along the nephrons of normal rats and specially-bred rats which spontaneously develop hypertension. The sites in the kidney examined were the distal collecting tubule (DCT), cortical collecting duct (CCD), and outer medullary collecting duct (OMCD). The researchers hypothesized that the level of Na-K-ATPase would be depressed at all sites in the rats with hypertension. This translates to expecting a rat strain effect but not an interaction effect. The authors were also interested in determining if there was a significant difference in the level of Na-K-ATPase activity at the different sites. Thus, the statistical hypotheses to be examined were \\[ \\begin{split} H_{0}&amp;: \\text{no rat strain effect}: \\mu_{Normal} = \\mu_{Hyper} \\\\ H_{A}&amp;: \\text{rat strain effect}: \\mu_{Normal} \\neq \\mu_{Hyper} \\end{split} \\] \\[ \\begin{split} H_{0}&amp;: \\text{no site effect}: \\mu_{DCT} = \\mu_{CCD} = \\mu_{OMCD} \\\\ H_{A}&amp;: \\text{site effect}: \\text{At least one pair of level means is different} \\end{split} \\] \\[ \\begin{split} H_{0}&amp;: \\text{no interaction effect} \\\\ H_{A}&amp;: \\text{interaction effect} \\end{split} \\] where \\(\\mu\\) is the mean Na-K-ATPase activity and the subscripts identify the levels of each factor as defined above. Twelve rats were randomly selected for each strain of rat (i.e., normal rats and rats with hypertension) from all rats available in the authors laboratory. The site of the kidney (DCT, CCD, or OMCD) where the Na-K-ATPase activity (\\(pmol\\cdot(min\\cdot mm)^{-1}\\)) was recorded on a rat was also randomly selected so that measurements at each location were recorded from four rats.55 Table 13.5: Number of rats in each combination of rat strain and kidney site. Kidney Site CCD DCT OMCD Strain Hyper 4 4 4 Normal 4 4 4 Variances among treatments appear to be constant (Levenes p=0.4033) though the boxplots of residuals appear somewhat divergent (Figure 13.3-Right), likely due to the small number of rats per treatment; the residuals appear to be approximately normally distributed (Anderson-Darling p=0.5203; Figure 13.3-Left); and there are no significant outliers (outlier test p=0.1527). Figure 13.3: Histogram of residuals (Left) and residual plot (Right) for a Two-way ANOVA of Na-K-ATPase activity for each combination of rat type and measurement location. The rats are probably independent among strains as there is no evidence that normal and hypertensive rats are in any way related. Independence of rats within strains is suspect given that the rats came from the same pool of normal and hypertensive rats bred in the lab. This may be acceptable for this experiment, but drawing conclusions to a larger population of rats may be suspect. Finally, rats are likely independent among kidney site groups as a different site was examined for each individual rat. All-in-all, independence is likely met enough to continue with this analysis. Thus, these data will be examined with a two-way ANOVA without transformation because the assumptions have been adequately met. There appears to be a (weakly) significant interaction effect (p=0.0404; Table 13.6); thus, the main effects cannot be interpreted directly from these results. Table 13.6: Two-way ANOVA results for Na-K-ATPase activity levels among two strains of rats and three sites in the kidney. Df Sum Sq Mean Sq F value Pr(&gt;F) strain 1 459.4 459.4 7.139 0.0156 site 2 8287.0 4143.5 64.393 0.0000 strain:site 2 496.0 248.0 3.854 0.0404 Residuals 18 1158.2 64.3 Tukeys method was performed on the interaction effect to more specifically describe the differences among group means (Table 13.7). The mean level of Na-K-ATPase activity was significantly lower for the hypertensive rats then for the normal rats at the DCT site (p=0.0189), but not at the other two sites (p0.8359). For example, the mean level of Na-K-ATPase activity was between 2.7 and 38.8 units lower in hypertensive than normal rats at the DCT site. In addition, the mean level of Na-K-ATPase activity was significantly greater at the DCT site than at the CCD and OMCD sites within both strains (p0.0029), and Na-K-ATPase activity did not differ between the CCD and OMCD sites for either strain (p0.1367). For example, the mean level of Na-K-ATPase activity was between 36.7 and 72.8 units higher at the DCT than at the OMCD site for normal rats. Table 13.7: Tukeys multiple comparisons of differences in means among all pairs of combinations of rat strain and kidney measurement site. contrast estimate lower.CL upper.CL p.value CCD Hyper - DCT Hyper -25.75 -43.78 -7.72 0.0029 CCD Hyper - OMCD Hyper 7.00 -11.03 25.03 0.8148 CCD Hyper - CCD Normal -6.75 -24.78 11.28 0.8359 CCD Hyper - DCT Normal -46.50 -64.53 -28.47 0.0000 CCD Hyper - OMCD Normal 8.25 -9.78 26.28 0.6953 DCT Hyper - OMCD Hyper 32.75 14.72 50.78 0.0002 DCT Hyper - CCD Normal 19.00 0.97 37.03 0.0355 DCT Hyper - DCT Normal -20.75 -38.78 -2.72 0.0189 DCT Hyper - OMCD Normal 34.00 15.97 52.03 0.0001 OMCD Hyper - CCD Normal -13.75 -31.78 4.28 0.1997 OMCD Hyper - DCT Normal -53.50 -71.53 -35.47 0.0000 OMCD Hyper - OMCD Normal 1.25 -16.78 19.28 0.9999 CCD Normal - DCT Normal -39.75 -57.78 -21.72 0.0000 CCD Normal - OMCD Normal 15.00 -3.03 33.03 0.1367 DCT Normal - OMCD Normal 54.75 36.72 72.78 0.0000 It can be difficult to interpret multiple comparisons when an interaction exists, especially if there are many differences among treatment means. A strategy to handle this is to describe how one factor differs among levels of the other factor (e.g., how strain differed among sites) and then vice-versa (e.g., how sites differed among strains). There is some support for the researchers hypothesis that Na-K-ATPase activity levels would be lower in rats with hypertension (Figure 13.4). However, this support was found only for the distal collecting tubule (DCT) site. At all other sites, no difference between hypertensive and normal rats was observed. Furthermore, Na-K-ATPase activity was higher at the DCT site then either of the other two sites for both normal and hypertensive rats. Figure 13.4: Mean Na-K-ATPase activity for each combination of rat strain and kidnety measurement site. R Code and Results nak &lt;- read.csv(&quot;http://derekogle.com/Book207/data/NAKATPase.csv&quot;) lm1.nak &lt;- lm(activity~strain+site+strain:site,data=nak) xtabs(~strain+site,data=nak) assumptionCheck(lm1.nak) anova(lm1.nak) mc1.nak &lt;- emmeans(lm1.nak,specs=pairwise~site:strain) ( mc1sum.nak &lt;- summary(mc1.nak,infer=TRUE) ) pd &lt;- position_dodge(width=0.1) ggplot(data=mc1sum.nak$emmeans, mapping=aes(x=site,group=strain,color=strain, y=emmean,ymin=lower.CL,ymax=upper.CL)) + geom_line(position=pd,size=1.1,alpha=0.25) + geom_errorbar(position=pd,size=2,width=0) + geom_point(position=pd,size=2,pch=21,fill=&quot;white&quot;) + labs(y=&quot;Na-K-ATPase Activity&quot;,x=&quot;Kidney Measurement Site&quot;) + theme_NCStats() 13.4 Crayfish Foraging (Transformation) Nystrom and Graneli (1996) examined the importance of intraspecific competition for food as a factor regulating survival, growth, and fecundity in Noble Crayfish (Astacus astacus). In one aspect of their research they examined factors that increased the risk of predation. In this part of their study, the authors assumed that the number of active crayfish (i.e., not in shelters) was an indicator of predation risk (i.e., the crayfish are out of their shelters and are thus more vulnerable). The authors hypothesized that the crayfishs willingness to risk predation would be greater if competition for food was greater. Thus, the authors created two levels of competition by regulating how much food the crayfish received (with the assumption that competition is greater with lesser food). The two feeding regimes were that crayfish were fed ad libitum and that they were fed slightly less than a maintenance ration (called unfed). In addition, there is ample evidence that crayfish are more active near dusk and at night as darkness provides some protection from predatory fish. To test for this, the authors included a time of day factor in their study, that had three levels: 1200 (noon), 1700, and 1900. The authors had a large number of crayfish collected from a local lake that were available to them for this experiment. They randomly placed the crayfish into groups of 50 crayfish that were then stocked into plastic tubs that had been filled with sand, small pebbles, and artificial shelters. The tubs were placed haphazardly around an outside area exposed to natural light. Each tub was then assigned a treatment that consisted of a combination of feeding levels and the time of day when the number of active crayfish (out of 50) that were active (i.e., not in a shelter) would be recorded. The statistical hypotheses to be examined were \\[ \\begin{split} H_{0}&amp;: \\text{no competition effect}: \\mu_{Fed} = \\mu_{Unfed} \\\\ H_{A}&amp;: \\text{competition effect}: \\mu_{Fed} \\neq \\mu_{Unfed} \\end{split} \\] \\[ \\begin{split} H_{0}&amp;: \\text{no time effect}: \\mu_{1200} = \\mu_{1700} = \\mu_{1900} \\\\ H_{A}&amp;: \\text{time effect}: \\text{At least one pair of level means is different} \\end{split} \\] \\[ \\begin{split} H_{0}&amp;: \\text{no interaction effect} \\\\ H_{A}&amp;: \\text{interaction effect} \\end{split} \\] where \\(\\mu\\) is the mean number of active crayfish and the subscripts identify the levels of each factor as defined above. This study is not balanced (Table 13.8) as the authors chose to record more groups of crayfish at the 1700 (i.e., dusk) time. Table 13.8: Number of groups of crayfish in each combination of feeding regime and time of day when the number of active crayfish were recorded. Kidney Site 12 17 19 Strain Fed 6 12 6 Unfed 6 12 6 The authors appeared to take steps to meet the independence assumption. There appears to be independence across all treatments as they used a different set of 50 crayfish for each treatment. In addition, the tubs were placed haphazardly around the area so there should not be any spatial effect such as all unfed treatments being in the same area. Furthermore, they only recorded the number of active crayfish at one time for each tub of crayfish. It would have been much easier to record all three times for each tub of crayfish but this would have violated the independence assumption and required a different analytical method. Variances among the treatments appear not to be constant (Levenes p=0.0201) and the boxplots of residuals are quite divergent (Figure 13.5-Right); the residuals do not appear to be approximately normally distributed and are quite left-skwed (Anderson-Darling p&lt;0.00005; Figure 13.5-Left); and there are significant outliers (outlier test p=0.0002; Figure 13.5). Clearly the assumptions are not met and a transformation should be considered. Figure 13.5: Histogram of residuals (Left) and residual plot (Right) for a Two-way ANOVA of the number of active crayfish (out of 50) activity for each combination of feeding level and time of day. No transformation worked perfectly for these data. However, a log transformation resulted in equal variances (Levenes p=0.6259), with boxplots of residuals that are not wildly divergent (Figure 13.6-Right); the residuals do not appear to be approximately normally distributed (p=0.0004), but are not too strongly skewed (Figure 13.6-Left); and there are still significant outliers (outlier test p=0.0104; Figure 13.6), mostly in the Unfed-1700 group. I did not remove outliers as the sample size is already quite small. The assumptions are more closely met on the log scale, so I will continue to analyze the data with this transformation. Figure 13.6: Histogram of residuals (Left) and residual plot (Right) for a Two-way ANOVA of the number of active crayfish (out of 50) activity for each combination of feeding level and time of day. There appears to be a significant interaction effect (p=0.0006; Table 13.9); thus, the main effects cannot be interpreted directly from these results. Table 13.9: Two-way ANOVA results for number of active crayfish for two feeding levels and three times of day. Df Sum Sq Mean Sq F value Pr(&gt;F) feed 1 42.12 42.12 236.46 0.00000 time 2 7.73 3.86 21.69 0.00000 feed:time 2 3.14 1.57 8.81 0.00064 Residuals 42 7.48 0.18 Tukeys multiple comparisons (Table 13.10) show that mean number of active crayfish did not differ by time of day when the crayfish were fed ad libitum (p0.5042). In contrast, in the unfed treatments, the mean number of active crayfish increased from 1200 to 1700 (p&lt;0.00005), but not from 1700 to 1900 (p=0.3489). Additionally, the mean number of active fish was greater in the unfed than in the fed treatments for each time of day (p0.0013). For example, the mean number of active crayfish in the unfed treatment was between 5.63 and 24.12 times greater than the mean number of active crayfish in the fed treatment at 1900. Table 13.10: Tukeys multiple comparisons for ratios of means among all pairs of combinations of feeding levels and times of day. Results were back-transformed from the log scale. contrast ratio lower.CL upper.CL p.value Fed 12 / Unfed 12 0.35 0.17 0.72 0.0013 Fed 12 / Fed 17 0.69 0.37 1.30 0.5042 Fed 12 / Unfed 17 0.09 0.05 0.18 0.0000 Fed 12 / Fed 19 0.71 0.35 1.48 0.7396 Fed 12 / Unfed 19 0.06 0.03 0.13 0.0000 Unfed 12 / Fed 17 1.97 1.05 3.70 0.0279 Unfed 12 / Unfed 17 0.27 0.14 0.50 0.0000 Unfed 12 / Fed 19 2.04 0.99 4.23 0.0570 Unfed 12 / Unfed 19 0.18 0.08 0.36 0.0000 Fed 17 / Unfed 17 0.14 0.08 0.23 0.0000 Fed 17 / Fed 19 1.04 0.55 1.94 1.0000 Fed 17 / Unfed 19 0.09 0.05 0.17 0.0000 Unfed 17 / Fed 19 7.61 4.05 14.29 0.0000 Unfed 17 / Unfed 19 0.65 0.35 1.23 0.3489 Fed 19 / Unfed 19 0.09 0.04 0.18 0.0000 The researchers primary hypotheses was supported by this study  crayfish in a high competition situation (i.e., unfed) which more willing to take on predation risk by being active outside their shelters (Figure 13.7). Their thought that crayfish would be more active near dusk or at night was partially supported as this was only evident when crayfish were in the high competition scenario. Figure 13.7: Mean number of active crayfish for each combination of feeding rate and time of day. Means and confidence intervals are back-transformed from the log scale. R Code and Results cray &lt;- read.csv(&quot;http://derekogle.com/Book207/data/CrayfishCompetition.csv&quot;) cray$feed &lt;- factor(cray$feed) cray$time &lt;- factor(cray$time) lm1.cc &lt;- lm(active~feed+time+feed:time,data=cray) xtabs(~feed+time,data=cray) cray$logact &lt;- log(cray$active) lm1.cct &lt;- lm(logact~feed+time+feed:time,data=cray) assumptionCheck(lm1.cc,lambday=0) anova(lm1.cct) mc1.cct &lt;- emmeans(lm1.cct,specs=pairwise~feed:time,tran=&quot;log&quot;,type=&quot;response&quot;) ( mc1sum.cct &lt;- summary(mc1.cct,infer=TRUE) ) pd &lt;- position_dodge(width=0.1) ggplot(data=mc1sum.cct$emmeans, mapping=aes(x=time,group=feed,color=feed, y=response,ymin=lower.CL,ymax=upper.CL)) + geom_line(position=pd,size=1.1,alpha=0.25) + geom_errorbar(position=pd,size=2,width=0) + geom_point(position=pd,size=2,pch=21,fill=&quot;white&quot;) + labs(y=&quot;Active Crayfish (out of 50)&quot;,x=&quot;Time of Day&quot;) + theme_NCStats() This example is modified from Alwyn et al. (2020) who based it on Kalwani and Kim (1992). A better design would have measured the Na-K-ATPase activity at all three sites from the same rates. However, this would have violated the independence assumption and required other methods (repeated-measures or mixed-models) to analyze the data. "],["SLRFoundations.html", "Module 14 SLR Foundational Principles 14.1 Equation of a Line 14.2 Best-Fit Line 14.3 Best-Fit Line in R", " Module 14 SLR Foundational Principles Simple linear regression (SLR) is used when a single quantitative response and a single quantitative explanatory variable are considered. The goals of SLR are to use the explanatory variable to (1) predict future values of the response variable and (2) explain the variability of the response variable. A simple linear regression would be used in the following situations. Evaluate the variability of porcupine body mass based on days since the beginning of winter. Predict daily energy consumption from the body weight of penguins. Explain the variability in product sales from the price of the product. Explain variability in a measure of interpersonal avoidance and a reported self-esteem metric. Explain variability in number of deaths related to lung cancer and per capita cigarette sales. Predict change in duck abundance from the loss of wetlands. Explain variability in a pitchers earned run average (ERA) and the average pitch speed at the point of release. Evaluate the variability in clutch size relative to length of female spiders. The Data Throughout the SLR modules, an example data set will be used that is the actual mean air temperatures and altitude lapse rates taken during the winter at eleven locations at various altitudes on Mount Everest. The altitude lapse rate is an index that was designed to be related to air temperature but adjusted for altitude. In this case, the researchers are testing to see if this index can be used to adequately predict the actual air temperature. Thus, actual air temperature is the response variable and altitude lapse rate is the explanatory variable. Table 14.1: Actual air temperature (MeanAirTemp) and altitude lapse rate (Altitude) data for Mount Everest in the winter. Altitude MeanAirTemp Season 2076 10.36 Winter 2552 9.64 Winter 2578 6.07 Winter 2632 5.14 Winter 2857 6.57 Winter 2865 3.71 Winter 3009 3.14 Winter 3574 1.36 Winter 3978 -0.07 Winter 4220 -3.79 Winter 5018 -6.07 Winter 14.1 Equation of a Line Both goals of SLR are accomplished by finding the model56 that best fits the relationship between the response and explanatory variables.57 When examining statistical regression models, the most common expression for the equation of the best-fit line is \\[ \\mu_{Y|X} = \\alpha + \\beta X \\] where \\(Y\\) is the response variable, \\(X\\) is the explanatory variable, \\(\\alpha\\) is the y-intercept, and \\(\\beta\\) is the slope. The left-hand-side of this equation is read as the mean of Y at a given value of X. This terminology is used because the best-fit line models the mean values of \\(Y\\) at each value of \\(X\\) rather than the individuals themselves. This model is for the population and thus, \\(\\alpha\\) and \\(\\beta\\) are the population y-intercept and slope, respectively. The equation of the best-fit line determined from the sample is \\[ \\hat{\\mu}_{Y|X} = \\hat{\\alpha} + \\hat{\\beta}X \\] where a hat on a parameter means that the value is an estimate and thus a statistic. Therefore, \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\) are the sample y-intercept and slope. Remember that statistics like \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\) are subject to sampling variability (i.e., vary from sample to sample) and have corresponding standard errors (to be shown in Module 15). 14.2 Best-Fit Line A line is simply a model for data and from that model we can make predictions for the response variable by plugging a value of \\(x\\) into the line equation. For example, a prediction using the \\(i\\)th individuals value of \\(x\\) is given by \\(\\hat{\\mu}_{Y|X=x_{i}}=\\hat{\\alpha}+\\hat{\\beta}x_{i}\\), where \\(\\hat{\\mu}_{Y|X=x_{i}}\\) is read as the predicted mean of \\(Y\\) when \\(X\\) is equal to \\(x_{i}\\). Visually this prediction is found by locating the value of \\(x_{i}\\) on the x-axis, rising vertically until the line is met, and then moving horizontally to the y-axis. This is demonstrated in Figure 14.1 for individual #2. Figure 14.1: Scatterplot of actual mean air temperature versus altitude lapse rate with the best-fit line shown and the prediction demonstrated for individual 2. As noted in previous modules, the residual is the vertical difference between an individuals observed value of the response variable (i.e., \\(y_{i}\\)) and a predicted value of the response variable based on the equation of a line and the individuals value of the explanatory variable (i.e., \\(\\hat{\\mu}_{Y|X=x_{i}}\\)). Thus, a residual is \\(y_{i}-\\hat{\\mu}_{Y|X=x_{i}}\\) and measures how close the line is to that point. A residual for the second individual is demonstrated in Figure 14.2. Figure 14.2: Same as previous figure except that the residual for individual #2 is highlighted with the red vertical line. Based on previous modules, an overall measure of the lack-of-fit of the line to the data is the sum of all squared residuals or the residual sum-of-squares (RSS); i.e., \\[ RSS = \\sum_{i=1}^{n}\\left(y_{i}-\\hat{\\mu}_{Y|X=x_{i}}\\right)^{2} \\] The best-fit line is defined by the \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\) out of all possible choices58 for \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\) that minimize the RSS (Figure 14.3).59 Figure 14.3: Scatterplot with candidate best-fit lines (blue line) and residuals (vertical red dashed lines) in left pane and the residual sum-of-squares for all candidate lines (gray) with the current line highlighted with a red dot. Note how the candidate line is on the best-fit line when the RSS is smallest. Mathematical statisticians have proven that the \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\) that minimize the RSS are given by \\[ \\hat{\\beta}=r\\frac{s_{Y}}{s_{X}} \\] and \\[ \\hat{\\alpha} = \\overline{Y}-\\hat{\\beta}\\overline{X} \\] where \\(r\\) is the sample correlation coefficient, \\(s_{Y}\\) and \\(s_{X}\\) are the sample standard deviations of the respective variables, and \\(\\overline{Y}\\) and \\(\\overline{X}\\) are the sample means of the respective variables. RSS: Residual Sum-of-Squares The best-fit line is the line of all possible lines that minimizes the RSS. 14.3 Best-Fit Line in R The data for Mount Everest temperature data is loaded below and restricted to just the data from Winter. ev &lt;- read.csv(&quot;https://raw.githubusercontent.com/droglenc/NCData/master/EverestTemps.csv&quot;) ev &lt;- filter(ev,Season==&quot;Winter&quot;) A best-fit regression line is obtained using the familiar lm() with a formula of the form response~explanatory and the data frame in data=. As usual, the results of this function should be assigned to an object that can be given to other functions to extract specific results. lm1.ev &lt;- lm(MeanAirTemp~Altitude,data=ev) The estimated intercept and slope (i.e., the \\(\\hat{\\alpha}\\) and \\(\\hat{\\beta}\\)) and corresponding 95% confidence intervals are extracted from the lm() object with coef() and confint(), respectively. I like to column bind these two results together to make a synthetic summary table. cbind(Est=coef(lm1.ev),confint(lm1.ev)) #R&gt; Est 2.5 % 97.5 % #R&gt; (Intercept) 21.388856057 17.442040728 25.335671386 #R&gt; Altitude -0.005634136 -0.006822147 -0.004446125 These results show that the slope of the best-fit line is -0.0056 (95% CI: -0.0068 - -0.0044) and the intercept is 21.39 (95% CI: 17.44 - 25.34). Thus, the equation of the best-fit line is Mean Air Temperature = 21.39 - 0.0056Altitude Lapse Rate. From this slope, it appears that the actual air temperature will decrease by 0.0056, on average, for each 1 C/km increase in the altitude lapse rate. Of course, the mean actual air temperature can be predicted by plugging a value of the altitude lapse rate into the equation of the line. For example, the predicted mean actual air temperature if the altitude lapse rate is 2552 is 21.39 - 0.0056Ã—2552 = 7.10oC. This can also be found with predict() using the saved lm() object as the first argument and a data.frame with the value of the explanatory variable set equal to the name of the explanatory variable in the lm() object.60 predict(lm1.ev,newdata=data.frame(Altitude=2552)) #R&gt; 1 #R&gt; 7.010541 The coefficient of determination (\\(r^{2}\\)) explains the proportion of the total variability in \\(Y\\) that is explained by knowing the value of \\(X\\). Thus, \\(r^{2}\\) ranges between 0 and 1, with \\(r^{2}\\)=1 meaning that 100% of the variation in \\(Y\\) is explained by knowing \\(X\\). Visually, higher \\(r^{2}\\) values occur when the data are more tightly clustered around the best-fit line.61 The \\(r^{2}\\) can be extracted from the lm() object with rSquared(). rSquared(lm1.ev) #R&gt; [1] 0.9274753 Thus, in this case, 92.7% of the variability in actual mean air temperature is explained by knowing the altitude lapse rate. This indicates a tight fit between the two variables and suggests that the actual mean air temperate will be well predicted by the altitude lapse rate. The best-fit line can be visualized by creating a scatterplot with ggplot() and then using geom_smooth(method=\"lm\",se=FALSE) to superimpose the best-fit line. ggplot(data=ev,mapping=aes(x=Altitude,y=MeanAirTemp)) + geom_point(pch=21,color=&quot;black&quot;,fill=&quot;lightgray&quot;) + labs(x=&quot;Altitude Lapse Rate (C/km)&quot;,y=&quot;Mean Air Temperature (C)&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;,se=FALSE) Model is used here instead of line because in this course, models other than lines will be fit to some data. However, all models will be fit on a scale where the form of the relationship between the response and explanatory variable is linear. It is assumed that you covered the basics of simple linear regression in your introductory statistics course. Thus, parts of this section will be review, although the nomenclature used may differ somewhat. Actually out of all choices that go through the point (\\(\\overline{X}\\),\\(\\overline{Y}\\)). This process of finding the best-fit line is called least-squares or ordinary least-squares. The difference between the two results is because the hand-calculation used rounded values of the intercept and slope. It is assumed that you discussed \\(r^{2}\\) in your introductory statistics course and, thus, it is only cursorily covered here. "],["SLRInference.html", "Module 15 SLR Inference 15.1 Variability Around the Line 15.2 Slope 15.3 Intercept 15.4 Slope and Intercept in R 15.5 Predicting Means 15.6 Predicting Individuals 15.7 Predictions in R", " Module 15 SLR Inference The best-fit line is computed from a sample, thus it is a statistic that is subject to sampling variability. In other words, the best-fit line will vary from sample to sample taken from the same population (Figure 15.1). Figure 15.1: Scatterplot for a population of 500 points with the population line shown in gray. Each of 100 samples of 50 points and their respective best-fit line is shown in red in each frame of the animation. Note how each sample produces a similar but ultimately different best-fit line. Given the above, then any statistic derived from the best-fit line  such as \\(\\hat{\\alpha}\\), \\(\\hat{\\beta}\\), and \\(\\hat{\\mu}_{Y|X=x_{i}}\\) introduced in Module 14  will also be subject to sampling variability. Thus, to construct confidence intervals and perform hypothesis tests with these statistics we need to measure their standard errors (SE). \\(\\hat{\\alpha}\\), \\(\\hat{\\beta}\\), and \\(\\hat{\\mu}_{Y|X=x_{i}}\\) are all subject to sampling variability. In this module, a measurement for variability around the line is introduced and then used to derive SE for \\(\\hat{\\alpha}\\), \\(\\hat{\\beta}\\), and \\(\\hat{\\mu}_{Y|X=x_{i}}\\). These are then used to make inferences (confidence intervals and hypothesis tests) for \\(\\alpha\\), \\(\\beta\\), and \\(\\mu_{Y|X=x_{i}}\\). 15.1 Variability Around the Line The SEs for statistics related to the best-fit line (i.e., \\(\\hat{\\alpha}\\), \\(\\hat{\\beta}\\), and \\(\\hat{\\mu}_{Y|X=x_{i}}\\)) depend on the variability of observations around the best-fit line. The variability of observations around the line can be visualized as an envelope that contains most of the observations (Figure 15.2). The bigger the envelope then the more variability among observations there is. Figure 15.2: Scatterplot for different samples of 50 observations showing an ellipse that captures most of the points and the measure of natural variability around the line. Note how the measure increases with increasing spread of the observations (i.e., larger ellipse). However, more objective measure of variability around the line is needed. Recall from Section 14.2 that a residual measures the distance that an observation is from the line and the RSS is a synthetic measure of how far (in squared units) all individuals are from the line. Dividing the RSS by the corresponding df=\\(n-2\\) makes a mean-square, which is a true variance.62 Thus, the variance of individuals around the line is \\[ s^{2}_{Y|X} = \\frac{RSS}{n-2} = \\frac{\\sum_{i=1}^{n}\\left(y_{i}-\\hat{\\mu}_{Y|X=x_{i}}\\right)^{2}}{n-2} \\] where \\(s^{2}_{Y|X}\\) is read as the variance of \\(Y\\) at a given \\(X\\). Because of the homoscedasticity assumption, which you are familiar with from your introductory statistics course but will be discussed in more detail in Module 17, this variance is the same for all values of \\(X\\) and, thus, \\(s^{2}_{Y|X}\\) can be interpreted as the the variance of \\(Y\\) around the best-fit line. It is seen in Figure 15.2 that \\(s^{2}_{Y|X}\\) increases as the variability of observations around the line increases. The natural variability of individuals around the best-fit line is measured by \\(s^{2}_{Y|X}\\). Intuitively, if there is more natural variability around the line, then the best-fit line from different samples will vary more, statistics from the different lines will vary more, and their SEs will be larger. This is the same principle you learned in your introductory statistics course  more natural variability (observations around the line) leads to more sampling variability (statistics related to the line). The SEs of \\(\\hat{\\alpha}\\), \\(\\hat{\\beta}\\), and \\(\\hat{\\mu}_{Y|X=x_{i}}\\) are all positively related to \\(s^{2}_{Y|X}\\). 15.2 Slope The sampling distribution of \\(\\hat{\\beta}\\) follows a normal distribution,63 is unbiased (so centered on \\(\\beta\\)), and has a standard error of \\[ SE_{\\hat{\\beta}} = \\sqrt{\\frac{s^{2}_{Y|X}}{(n-1)s_{X}^{2}}} \\] Dont memorize this formula; rather note how \\(SE_{\\hat{\\beta}}\\) increases with increasing \\(s^{2}_{Y|X}\\)) but decreases with increasing \\(n\\) or \\(s_{X}^{2}\\). Variability in the slope increases with increasing variability of observations around the line, decreases with increasing sample size, and decreases with increasing variability in the explanatory variable. Hypotheses of the form \\[ \\begin{split} H_{0}&amp;: \\beta = \\beta_{0} \\\\ H_{A}&amp;: \\beta \\neq \\beta_{0} \\end{split} \\] where \\(\\beta_{0}\\) represents a specific value for \\(\\beta\\) can be tested with a t test statistic of \\[ t=\\frac{\\hat{\\beta}-\\beta_{0}}{SE_{\\hat{\\beta}}} \\] which has \\(n-2\\) df. Familiarly, a confidence interval for \\(\\beta\\) is constructed with \\(\\hat{\\beta} \\pm t^{*}SE_{\\hat{\\beta}}\\). The most common hypothesis to test in SLR is whether the slope is equal to zero or not. A slope of zero represents a flat best-fit line (Figure 15.3) which indicates that the mean of \\(Y\\) does not increase or decrease with increasing \\(X\\). If this is the case then \\(Y\\) and \\(X\\) are not related. Thus, testing \\(H_{0}: \\beta = 0\\) versus \\(H_{A}: \\beta \\ne 0\\) is testing whether \\(Y\\) and \\(X\\) are statistically related or not  a key question in SLR! Figure 15.3: Demonstration of what the best-fit lines would like for the null hypothesis that the slope is zero or there is no relationship between Y and X (red) or the alternative hypothesis that the slope is not zero and there is a relationship between Y and X (blue). Note that two possibilities are shown for the alternative hypothesis because the slope could be positive (solid) or negative (dashed) Testing that the slope of the best-fit line is 0 (or not) is the most important hypothesis test in SLR as it is the same as testing if the response and explanatory variables are related or not. 15.3 Intercept The sampling distribution of \\(\\hat{\\alpha}\\) is normally distributed,64 unbiased (so centered on \\(\\alpha\\)), and has a standard error of \\[ SE_{\\hat{\\alpha}} = \\sqrt{s^{2}_{Y|X}\\left(\\frac{1}{n}+\\frac{\\overline{X}^{2}}{(n-1)s_{X}^{2}}\\right)} \\] Again, dont memorize this formula; rather note that \\(SE_{\\hat{\\alpha}}\\), as did \\(SE_{\\hat{\\beta}}\\), increases with \\(s^{2}_{Y|X}\\)) but decreases with increasing \\(n\\) and \\(s_{X}^{2}\\). However, also note that \\(SE_{\\hat{\\alpha}}\\) increases with increasing \\(\\overline{X}\\). This positive relationship between \\(SE_{\\hat{\\alpha}}\\) and \\(\\overline{X}\\) indicates that \\(\\hat{\\alpha}\\) is more variable the further \\(\\overline{X}\\) is from \\(x=0\\). In other words, \\(\\hat{\\alpha}\\) is more variable when the intercept is more of an extrapolation. Variability in the intercept increases with increasing variability of observations around the line and increasing mean of the explanatory variable, but decreases with increasing sample size and increasing variability in the explanatory variable. Hypotheses of the form \\[ \\begin{split} H_{0}&amp;: \\alpha = \\alpha_{0} \\\\ H_{A}&amp;: \\alpha \\neq \\alpha_{0} \\end{split} \\] where \\(\\alpha_{0}\\) represents a specific value for \\(\\alpha\\) can be tested with a t test statistic of \\[ t=\\frac{\\hat{\\alpha}-\\alpha_{0}}{SE_{\\hat{\\alpha}}} \\] which has \\(n-2\\) df. Familiarly, a confidence interval for \\(\\alpha\\) is constructed with \\(\\hat{\\alpha} \\pm t^{*}SE_{\\hat{\\alpha}}\\). A common automatically computed hypothesis test in SLR is whether the intercept is equal to zero or not. This effectively tests whether the best-fit line goes through the origin or not.65 This hypothesis is rarely of interest because the intercept is often either an extreme extrapolation (i.e., \\(X=0\\) is far from the observed values of \\(X\\)) or \\(Y=0\\) does not make sense for \\(Y\\). For example, both of these issues are illustrated by asking whether it makes sense to test if the mean gas mileage (\\(Y\\)) is 0 for a car that weighs (\\(X\\)) 0 lbs? Testing if the y-intercept of the best-fit line (fit to raw data) is rarely of much interest as the intercept is often an extrapolation or a response value of 0 is non-sensical. The y-intercept, and tests about the y-intercept, can be made more useful by centering the explanatory variable. A variable is centered by subtracting the mean from every observation of that variable. For example, a new variable \\(X^{*}\\) is constructed by centering \\(X\\); i.e., \\(X^{*}=X-\\overline{X}\\). Centering \\(X\\) simply horizontally shifts the plot to being centered on \\(X^{*}=0\\) rather than on \\(X=\\overline{X}\\) (Figure 15.4). Figure 15.4: Example of centering the explanatory variable. The original data is centered on 5, whereas the centered data is centered on 0. The vertical dashed line highlights the mean value of X for the original and centered data. Note how the intercept but not the slope of the equation changes after centering. When examining Figure 15.4 note that the slope did not change because the general shape of the scatterplot is unchanged. However, the intercept changed dramatically because the intercept before centering was the mean value of \\(Y\\) when \\(X\\)=0 but after centering the intercept is the mean value of \\(Y\\) when \\(X^{*}\\)=0, which is the same as \\(X=\\overline{X}\\). Thus, the intercept from the centered model is the mean value of \\(Y\\) at the mean value of \\(X\\). For example, the centered intercept would be the mean miles per gallon at the mean weight of cars. The intercept after centering is imminently interpretable!! Despite this, it is not necessary in this course to center the explanatory variable unless you plan to interpret or perform a test with the intercept. Centering does have some added value in multiple linear regression and will be revisited when we learn Indicator Variable Regressions. The intercept after centering the explanatory variable represents the mean value of the response variable when the original explanatory variable is equal to its mean. Thus, the interpretation of the centered intercept is always interpretable. The interpretation of the slope is unaffected by centering. 15.4 Slope and Intercept in R As shown in Section 14.3 the best-fit line is obtained using lm() with a model of the form response~explanatory. Thus, the linear model for the Mount Everest temperature data is fit with lm1.ev &lt;- lm(MeanAirTemp~Altitude,data=ev) As shown in that section, a concise table of the estimated intercept and slope with 95% confidence intervals is constructed with cbind(), coef(), and confint(). cbind(Est=coef(lm1.ev),confint(lm1.ev)) #R&gt; Est 2.5 % 97.5 % #R&gt; (Intercept) 21.388856057 17.442040728 25.335671386 #R&gt; Altitude -0.005634136 -0.006822147 -0.004446125 While not discussed there, these confidence intervals were computed using \\(SE_{\\hat{\\alpha}}\\) and \\(SE_{\\hat{\\beta}}\\) and the confidence interval formulae discussed above. More summary information may be extracted by submitting the saved lm() object to summary(). summary(lm1.ev) #R&gt; Coefficients: #R&gt; Estimate Std. Error t value Pr(&gt;|t|) #R&gt; (Intercept) 21.3888561 1.7447131 12.26 6.42e-07 #R&gt; Altitude -0.0056341 0.0005252 -10.73 1.99e-06 #R&gt; #R&gt; Residual standard error: 1.462 on 9 degrees of freedom #R&gt; Multiple R-squared: 0.9275, Adjusted R-squared: 0.9194 #R&gt; F-statistic: 115.1 on 1 and 9 DF, p-value: 1.987e-06 There are two portions of output from summary(). The top portion under Coefficients: contains information about the intercept in the row labeled (Intercept) and information about the slope in the row labeled with the name of the explanatory variable. Thus \\(\\hat{\\alpha}\\) (=21.39) and \\(\\hat{\\beta}\\) (=-0.0056) are under Estimate and the \\(SE_{\\hat{\\alpha}}\\) (=1.74) and \\(SE_{\\hat{\\beta}}\\) (=0.00053) are under Std. Error. The values under t value and Pr(&gt;|t|) are the t test statistic and corresponding p-value for testing that the corresponding parameter is equal to zero or not. Because the specific value in the tests is zero, the t test statistic shown here is simply the Estimate divided by the Std. Error. For example, the test statistic for testing \\(H_{0}: \\beta = 0\\) versus \\(H_{A}: \\beta \\ne 0\\) is \\(t=\\frac{-0.0056}{0.0005}\\) = -10.73. The corresponding p-value (0.000002) suggests that \\(H_{0}\\) should be rejected and one would conclude that there is a significant relationship between the actual mean air temperature and the altitude lapse rate. The default p-values printed by most softwares are ONLY for the specific \\(H_{0}\\) that the corresponding parameter is equal to zero (vs. that it is not). The remaining output from summary() is largely redundant with what will be discussed more thoroughly in Module 16. However, it should be noted that \\(s_{Y|X}\\) is given after Residual standard error: Thus, in this case, the standard deviation of observations around the best-fit line is 1.462. The variance of the observations around the best fit line (\\(s_{Y|X}^{2}\\)) discussed in Section 15.1 is this value squared or 1.4622=2.137. 15.5 Predicting Means One of the major goals of linear regression is to use the best-fit line and a known value of the explanatory variable (generically labeled as \\(x_{0}\\)) to predict a future value of the response variable. This prediction is easily made by plugging \\(x_{0}\\) into the equation of the best-fit line for \\(X\\). Generically, this is \\[ \\hat{\\mu}_{Y|X=x_{0}} = \\hat{\\alpha} + \\hat{\\beta}x_{0} \\] Example predictions were made by hand and using predict() in R in Section 14.3. These predictions are the best estimate of the mean response for all individuals with an explanatory variable of \\(x_{0}\\)  i.e., \\(\\hat{\\mu}_{Y|X=x_{0}}\\) and is called a fitted value because the best-fit line actually fits the mean values of \\(Y\\) at a given value of \\(X\\). Fitted value: Predicted mean value of the response variable for all individuals with a given value of the explanatory variable  i.e., \\(\\hat{\\mu}_{Y|X=x_{0}}\\) The fitted value is a statistic that is subject to sampling variability. It is known that the fitted values have a sampling distributions that is normally distributed66 with a mean equal to \\(\\hat{\\mu}_{Y|X=x_{0}}\\) and a standard error of \\[ \\text{SE}_{\\text{fits}} = \\sqrt{s_{Y|X}^{2}\\left(\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{X}\\right)^{2}}{(n-1)s_{x}^{2}}\\right)} \\] Once again, dont memorize this formula but again note that \\(\\text{SE}_{\\text{fits}}\\) increases with increasing \\(s_{Y|X}^{2}\\) and decreases with increasing \\(n\\) and \\(s_{x}^{2}\\). However, also note that the \\(\\text{SE}_{\\text{fits}}\\) increases as \\(x_{0}\\) is further from \\(\\overline{X}\\). In other words, there is more variability in predicting the mean of \\(Y\\) for values of \\(X\\) further from the mean of \\(X\\). Thus, the most precise prediction of the mean of \\(Y\\) is made when \\(X=\\overline{X}\\). A confidence interval for \\(\\mu_{Y|X=x_{0}}\\) is computed with \\(\\hat{\\mu}_{Y|X=x_{0}}\\pm t^{*}\\text{SE}_{\\text{fits}}\\). Computing this confidence interval for all values of \\(x_{0}\\) and plotting it produces what is called a confidence band (Figure 15.5). Confidence bands will always have a saddle shape because, as stated above, the prediction of \\(\\mu_{Y|X=x_{0}}\\) is always most precise (narrowest) when \\(X=\\overline{X}\\). Figure 15.5: Confidence bands around a best-fit line. The confidence band shown in Figure 15.5 is a 95% confidence interval related to the placement of the line. To demonstrate this, lines from 100 random samples from the same population are plotted in Figure 15.6 along with the confidence band from Figure 15.5. At the end of this animation, it is evident that most (95%-ish) of the random regression lines were contained within the 95% confidence band. Figure 15.6: Animation of 100 samples with corresponding regression lines and how most of the regression lines fit within the confidence bands shown in the previous figure. Confidence bands are built from \\(\\text{SE}_{\\text{fits}}\\) and are confidence intervals for \\(\\mu_{Y|X=x_{0}}\\) and the placement of the best-fit line. 15.6 Predicting Individuals In addition to predicting the mean value of the response for all individuals with a given value of the explanatory variable, it is common to predict the value of the response for an individual. Given that our best guess for an individual is that they are average, this prediction is the same as that use for the mean, but will be labeled as \\(\\hat{Y}|X=x_{0}\\) to help keep it separate. This second objective (predict the individual) is called finding a predicted value. Predicted value: Predicted value of the response variable for an individual with a given value of the explanatory variable.  i.e., \\(\\hat{Y}|X=x_{0}\\) Once again, the predicted value is a statistic that is subject to sampling variability. It is known that the predicted values have a sampling distribution that is normally distributed67 with a mean equal to \\(\\hat{Y}|X=x_{0}\\) and a standard error of \\[ \\text{SE}_{\\text{prediction}} = \\sqrt{s_{Y|X}^{2}\\left(\\frac{1}{n}+\\frac{\\left(x_{0}-\\bar{X}\\right)^{2}}{(n-1)s_{x}^{2}}\\right)+s_{Y|X}^{2}} \\] This formula has two parts separate at the second plus sign. The first part in front of the plus sign is exactly the same as \\(\\text{SE}_{\\text{fits}}\\) and represents variability in placement of the line. The second part is \\(s_{Y|X}^{2}\\) and represents variability of individuals around the line. Thus, variability in predicting an individual consists of variability in placing the line and then variability of individuals around that line. A confidence interval for \\(Y|X=x_{0}\\) is computed with \\(\\hat{Y}|X=x_{0}\\pm t^{*}\\text{SE}_{\\text{prediction}}\\), but is called a prediction interval to keep it distinct from the prediction of the mean response. Computing this prediction interval for all values of \\(x_{0}\\) and plotting it produces what is called a prediction band (Figure 15.7). Prediction bands will always have a saddle shape from predicting the line placement an will be wider than the confidence bands because of the added variability of predicting an individual. Figure 15.7: Prediction (red) and confidence bands (blue) around a best-fit line. The prediction band shown in Figure 15.7 is a 95% confidence interval related to the placement of points. To demonstrate this, points and lines from 100 random samples from the same population are plotted in Figure 15.868 along with the prediction band from Figure 15.7. At the end of this animation, it is evident that most (95%-ish) of the random points were contained within the 95% prediction band. Figure 15.8: Animation of 100 samples with corresponding regression lines and points and how most of the points fit within the prediction bands shown in the previous figure. Prediction bands are built from \\(\\text{SE}_{\\text{prediction}}\\) and are confidence intervals for \\(Y|X=x_{0}\\) and the placement of individuals around the best-fit line. \\(\\text{SE}_{\\text{fits}}\\) measures only sampling variability related to predicting the mean value of the response variable at a given value of the explanatory variable. \\(\\text{SE}_{\\text{prediction}}\\) measures both sampling variability related to predicting the mean value of the response variable and natural variability related to predicting an individuals difference from that mean. Finally, note that making a prediction (i.e., plugging a value of \\(X\\) into the equation of a best-fit line) is simultaneously a prediction of (1) the mean value of the response variable for all individuals with a given value of the explanatory variable and (2) the value of the response variable for an individual with a given value of the explanatory variable. The difference is that the confidence interval for the mean value is narrower than the prediction interval for the individual. 15.7 Predictions in R As shown in Section 14.3 a prediction can be made in R with predict() using the saved lm() object as the first argument and a data.frame with the value of the explanatory variable set equal to the name of the explanatory variable in the lm() object. A confidence or prediction interval can be constructed by including interval=\"confidence\" or interval=\"prediction\", respectively. nd &lt;- data.frame(Altitude=2552) # create data.frame first to save typing predict(lm1.ev,newdata=nd,interval=&quot;confidence&quot;) #R&gt; fit lwr upr #R&gt; 1 7.010541 5.740331 8.28075 predict(lm1.ev,newdata=nd,interval=&quot;prediction&quot;) #R&gt; fit lwr upr #R&gt; 1 7.010541 3.468216 10.55287 Thus, one is 95% confident that the mean actual mean air temperature is between 5.74 and 8.28oC for all stations when the altitude lapse rate is 2552 C/km. In contrast one is 95% confident that the actual mean air temperature is between 3.47 and 10.55oC for a station when the altitude lapse rate is 2552 C/km. Note that multiple predictions can be made at once by including more values in the data frame given to predict(). nd &lt;- data.frame(Altitude=c(2552,3000)) predict(lm1.ev,newdata=nd,interval=&quot;confidence&quot;) #R&gt; fit lwr upr #R&gt; 1 7.010541 5.740331 8.280750 #R&gt; 2 4.486448 3.457386 5.515509 predict(lm1.ev,newdata=nd,interval=&quot;prediction&quot;) #R&gt; fit lwr upr #R&gt; 1 7.010541 3.468216 10.552866 #R&gt; 2 4.486448 1.023270 7.949626 The confidence band can be added to the scatterplot with the best-fit line (as shown in Section 14.3) by leaving off se=FALSE in geom_smooth(). Use color= to change the color of the best-fit line and fill= to change the color of the confidence band (of so desired). ggplot(data=ev,mapping=aes(x=Altitude,y=MeanAirTemp)) + geom_point(pch=21,color=&quot;black&quot;,fill=&quot;lightgray&quot;) + labs(x=&quot;Altitude Lapse Rate (C/km)&quot;,y=&quot;Mean Air Temperature (C)&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;,color=&quot;black&quot;,fill=&quot;lightgray&quot;) Scatterplots depicting the best-fit line should usually be augmented with the confidence band. Adding the prediction bands is more work because it is not automatically computed within any geom. Recall from Section 3.4. If the assumptions of an SLR are met; see Module 17 If the assumptions of an SLR are met; see Module 17 Here this means the mathematical origin where (\\(X\\),\\(Y\\))=(0,0). If the SLR assumptions are met; see Module 17. If the SLR assumptions are met; see Module 17. These are the same random samples as in Figure 15.6. "],["SLRModels.html", "Module 16 SLR Models 16.1 Models 16.2 ANOVA Table 16.3 Coefficient Of Determination", " Module 16 SLR Models As with all linear models, the important hypothesis tests of SLR can be reduced to comparing two models lack-of-fit to data. The description below relies heavily on your previous understanding of full and simple models (see Modules 3 and 4). 16.1 Models The full model in SLR is the equation of the best-fit line modified with an error term to represent individuals; i.e., \\[ Y_{i} = \\alpha + \\beta X_{i} + \\epsilon_{i} \\] where \\(i\\) is an index for individuals. The simple model corresponds with \\(H_{0}:\\beta=0\\) and is thus \\[ Y_{i} = \\alpha + \\epsilon_{i} \\] Furthermore, it can be shown algebraically that the \\(\\alpha\\) in the simple model is \\(\\mu_{Y}\\).69 Figure 16.1: Scatterplot illustrating two competing models for describing the relationship between actual mean temperature and altitude lapse rate for Mount Everest in the winter. The horizontal red line is placed at the mean actual mean air temperatures and represents the simple model, whereas the blue line is the best-fit line and represents the full model. The simple model in SLR represents a flat line at the mean of the response variable. The full model in SLR represents a line with a significant slope. Comparing Figure 16.1 to Figure 15.3 reveals that testing the simple versus the full model is the same as testing that the slope is equal to zero or not. In other words, testing for a relationship between \\(Y\\) and \\(X\\) is the same as testing that the mean value of \\(Y\\) is the same for all \\(X\\)s (i.e., simple model with no slope) or whether the mean value of \\(Y\\) depends on the value of \\(X\\) (i.e., full model with a slope). Determining whether the simple or full model should be used in SLR is a test of whether the two variables are statistically related. 16.2 ANOVA Table Of course, the lack-of-fit of the a model is measured by summing the squared residuals using predictions from the model. The lack-of-fit of the simple model is calculated with residuals from the mean value of the response variable (Figure ??-Left) or \\[ \\text{SS}_{\\text{Total}} = \\sum_{i=1}^{n}\\left(y_{i}-\\overline{Y}_{\\cdot}\\right)^{2} \\] This calculation is exactly the same as that discussed for the one- and two-way ANOVAs. The lack-of-fit of the full model is calculated with residuals from the best-fit regression line (Figure ??-Center) or \\[ \\text{SS}_{\\text{Residual}} = \\sum_{i=1}^{n}\\left(y_{i}-\\hat{\\mu}_{Y|X}\\right)^{2} = \\sum_{i=1}^{n}\\left(y_{i}-\\left(\\hat{\\alpha}+\\hat{\\beta}x_{i}\\right)\\right)^{2} \\] This is termed SSResidual in SLR, but it is exactly analogous to SSWithin from Modules 5 and (ANOVA2Foundations2). Figure 16.2: Scatterplots illustrating two competing models for describing the relationship between actual mean air temperature and altitude lapse rate for Mount Everest in winter. The horizontal red line is placed at the mean actual mean air temperature and represents the simple model. The blue line is the best-fit line and represents the full model. Residuals for each model are shown on the respective graphs. Figure 16.3: Scatterplots illustrating two competing models for describing the relationship between actual mean air temperature and altitude lapse rate for Mount Everest in winter. The horizontal red line is placed at the mean actual mean air temperature and represents the simple model. The blue line is the best-fit line and represents the full model. Residuals for each model are shown on the respective graphs. Figure 16.4: Scatterplots illustrating two competing models for describing the relationship between actual mean air temperature and altitude lapse rate for Mount Everest in winter. The horizontal red line is placed at the mean actual mean air temperature and represents the simple model. The blue line is the best-fit line and represents the full model. Residuals for each model are shown on the respective graphs. SSTotal measures the lack-of=fit of the simplest model, which is just the mean of the response variable. Thus, SSTotal measures the maximum lack-of-fit of any model to the response variable. As always, SSTotal partitions into two parts, labeled here as SSResidual and SSRegression. As stated above SSResidual is exactly analogous to SSWithin. Similarly SSRegression is exactly analogous to SSAmong. Thus, SSRegression measures the reduction in lack-of-fit from using the full model over the simple model (i.e., how much better the full model fits) and is a measure of the signal in the data. Specifically, SSRegression is calculate from the difference in predictions between the full and simple models (Figure ??-Right); i.e., \\[\\text{SS}_{\\text{Regression}} = \\sum_{i=1}^{n}\\left((\\hat{\\alpha}+\\hat{\\beta}x_{i})-\\overline{Y}\\right)^{2}\\] The df are similar to those discussed for a One-Way and Two-Way ANOVA. The dfTotal are \\(n-1\\) as before and because there is only one parameter in the simple model. The dfResidual is \\(n-2\\) because the full model has two parameters (i.e., \\(\\alpha\\) and \\(\\beta\\)). The dfTotal partitions as before which leaves dfRegression=1, which is the difference in parameters between the full and simple models. As you can see, dfRegression is exactly analogous to dfAmong. dfRegression is always 1 in SLR. Per usual, MS are calculated by dividing SS by their respective df. As with the other models MSTotal=\\(s_{Y}^{2}\\) an is the total natural variability of observations (around the simple model of a single mean). The MSResidual is the natural variability of observations around the best-fit line (i.e., the full model) and is, thus, \\(s_{Y|X}^{2}\\), which was discussed in Section 15.1. Finally, MSRegression is a measure of the variability of the best-fit line around the simple mean. The F test statistic is computed as a ratio of the variance explained by the full model (i.e., the signal) the variance unexplained by the full model (i.e., the noise) as described in Section 4.6, In SLR, this translates to \\[ F = \\frac{MS_{Regression}}{MS_{Residual}} \\] which will have dfRegression numerator and dfResidual denominator df. Once again, this is exactly analogous to what we did with the One- and Two-Way ANOVAs. The SS, MS, df, F, and p-value just discussed are summarized in an ANOVA table. Even though this is called an ANOVA table, the method is still a Simple Linear Regression. The ANOVA table is simply a common way to summarize the calculations needed to compare two models, whether those models are part of the One-Way ANOVA, Two-Way ANOVA, or Simple Linear Regression methods. The ANOVA table for the Mount Everest air temperature and altitude lapse rate analysis is in Table 16.1. These results indicate that there is a significant relationship between the actual mean air temperature and the altitude lapse rate at stations on Mount Everest in the Winter (p=0.0001). This same result indicates that a full model with a slope term is significantly better at fitting the observed data then a simple model that does not contain a slope term. Table 16.1: An ANOVA table for the simple linear regression of actual mean air temperature on altitude lapse rate for locations on Mount Everest in the Winter. Note that the Total row is not shown. Df Sum Sq Mean Sq F value Pr(&gt;F) Altitude 1 245.934 245.934 115.096 0 Residuals 9 19.231 2.137 In addition to the primary objective of comparing the full and simple models, several items of interest can be identified from the ANOVA table in Table 16.1. The variance of individuals around the regression line (\\(s_{Y|X}^{2}\\)) is given by MSResidual as 2.137). The variance of individuals around the overall mean (\\(s_{Y}^{2}\\)) is given by MSTotal as 26.516 (=\\(\\frac{245.934+19.231}{1+9}\\) = \\(\\frac{265.165}{10}\\)). The F test statistic is equal to the square of the t test statistic from testing \\(H_{0}:\\beta =0\\) (see results from summary() in Section 15.4).70 The ANOVA table for a SLR is obtained by submitting the saved lm() object to anova(). For example, Table 16.1 was obtained with anova(lm1.ev). Note also that the F-ratio test statistic, dfRegression, dfResidual, and the p-value from the ANOVA table are shown on the last line of the output from summary(), which was introduced in Section 14.3. Also, as noted before, MSResidual is the square of the value following Residual standard error: in the summary() output. Thus, many of the key components of the ANOVA table are also in the summary() results. summary(lm1.ev) #R&gt; Coefficients: #R&gt; Estimate Std. Error t value Pr(&gt;|t|) #R&gt; (Intercept) 21.3888561 1.7447131 12.26 6.42e-07 #R&gt; Altitude -0.0056341 0.0005252 -10.73 1.99e-06 #R&gt; #R&gt; Residual standard error: 1.462 on 9 degrees of freedom #R&gt; Multiple R-squared: 0.9275, Adjusted R-squared: 0.9194 #R&gt; F-statistic: 115.1 on 1 and 9 DF, p-value: 1.987e-06 16.3 Coefficient Of Determination The coefficient of determination (\\(r^{2}\\)) was introduced in Section 14.3 as a measure of the proportion of the total variability in the response variable that is explained by knowing the value of the explanatory variable. This value is actually calculated with \\[ r^{2} = \\frac{SS_{Regression}}{SS_{Total}} \\] Note also that the coeffcient of determination is found in the summary() results shown above behind the Multiple R-squared: label. By substituting the formula for the intercept (\\(\\alpha=\\mu_{Y} - \\hat{\\beta}\\mu_{X}\\)) into \\(\\mu_{Y|X} = \\alpha + \\beta X\\), an alternative form of the equation of the line is \\(\\mu_{Y|X} =\\mu_{Y}+\\beta\\left(X-\\mu_{X}\\right)\\). Thus, if \\(\\beta=0\\) as in \\(H_{0}\\) then the simple model in \\(H_{0}\\) reduces to \\(\\mu_{Y|X}=\\mu_{Y}\\). This is a general rule between the t and F distributions. An F with \\(1\\) numerator df and \\(\\nu\\) denominator df is equal to the square of a t with \\(\\nu\\) df. "],["SLRAssumptions.html", "Module 17 SLR Assumptions 17.1 Residual Plot 17.2 Independence 17.3 Homoscedasticity 17.4 Normality 17.5 No Outliers or Influential Points 17.6 Linearity 17.7 Testing Assumptions in R", " Module 17 SLR Assumptions Simple linear regressions requires five assumptions be met so that the calculations made in Modules 14-16 mean what we said they would mean. The five assumptions for a SLR are: independence of individuals, the variances of \\(Y\\) at each given value of \\(X\\) are equal (homoscedasticity assumption). the values of \\(Y\\) at each given value of \\(X\\) are normally distributed (normality assumption) no outliers or influential points, and the mean values of \\(Y\\) at each given value of \\(X\\) fall on a straight line (linearity assumption). The first four assumptions are the same as for the One- and Two-Way ANOVAs, though they manifest slightly different in SLR. Each of these assumptions is discussed in more detail below. However, the concept of a residual plot is introduced first, as it is the primarily tool for assessing whether the SLR assumptions have been met or not. 17.1 Residual Plot For any given best-fit line, the predicted values of \\(Y\\) for each observed value of \\(X\\) is obtained by plugging each \\(X\\) into the equation of the line. Predicted values are relatively large where the line is highest and relatively small where the line is lowest relative to the y-axis. A residual is computed for each value of \\(X\\) as well by subtracting the predicted value of \\(Y\\) from the observed value of \\(Y\\). Observations near the best-fit line have relatively small residuals, those far from the best-fit line have relatively large residuals. In addition, observations above the line have positive residuals whereas those below the line have negative residuals.71 A residual plot is a scatterplot of these residuals on the y-axis and the predicted values on the x-axis. The residual plot transforms the scatterplot by first flattening the best-fit line and placing it at 0 on the y-axis and then expanding the y-axis to remove any dead white space in the plot. This transformation effectively zooms in on the best-fit line so that you can better see how the points relate to the line. Figure 17.1 shows a scatterplot with the best-fit line on the left and the corresponding residual plot on the right. Four points are shown to help understand how the two plots are related. This example is fairly straightforward as the residual plot essentially flattens the best-fit line and then zooms in the y-axis scale. Figure 17.1: Scatterplot with best-fit line and four points highlighted (Left) and residual plot with same four points highlighted (Right). Figure 17.2 is arranged similarly to Figure 17.1. However, in this case the scatterplot exhibits a negative relationship which makes the transformation to the residual plot not as obvious. With a negative relationship, the largest predicted values correspond to points on the left side of the scatterplot, but they end up on the right side of the residual plot. Of course, vice-versa is also true. This is most obvious with the 38th and 39th points in Figure 17.2. Figure 17.2: Scatterplot with best-fit line and four points highlighted (Left) and residual plot with same four points highlighted (Right). Residual plots are like putting the scatterplot with the best-fit line under a microscope; i.e., they zoom in on the best-fit line to help identify how the points are arranged relative to the line. If the homoscedasticity and linear assumptions (discussed below) are adequately met then the residual plot should exhibit no discernible or obvious pattern. Most importantly no curve nor cone or funnel-shape should be evident in the plot. Figure 17.3 is an example of a residual plot where the homoscedasticity and linearity assumptions HAVE been adequately met. Figure 17.3: Residual plot where the homoscedasticity and linearity assumptions HAVE been adequately met. A residual plot that exhibits no discernible or obvious patterns suggests that the homoscedasticity and linearity assumptions have been met. No pattern on a residual plot is a good thing!! 17.2 Independence The independence assumption is largely the same as it was for a One- and Two-Way ANOVA, except that there is no need to compare within and among groups as there are no groups in an SLR. Thus, in an SLR, you need to ascertain whether individuals are independent of each other or not. This is accomplished by considering the sampling design as you did before. Individuals that are dependent are usually connected in space or time with the most common dependency occurring when multiple measurements are made on the same individuals.72 17.3 Homoscedasticity Strictly speaking homoscedasticity means that the the variances of \\(Y\\) at each given value of \\(X\\) are equal. Seldom will you have enough multiple observations at the same value of \\(X\\) to test this explicitly. Thus, in practice, homoscedasticity translates into assessing whether the same general variance or scatter of points exists around the line for all values of \\(X\\). Heteroscedasticity, or non-constant variance around the line, will generally appear as a cone or funnel shape on a residual plot (Figure 17.4). Sometimes the funnel-shape may be difficult to see if the linearity assumption is also not met (Figure 17.4-Right). Make sure to compare these residual plots to Figure 17.3. Figure 17.4: Residual plot where the homoscedasticity assumption has NOT been adequately met. 17.4 Normality The normality assumption for SLR is assessed exactly as it was for a One- and Two-Way ANOVA; i.e., with an Anderson-Darling test and a histogram of residuals (see Section 7.3). 17.5 No Outliers or Influential Points The no outliers assumption for SLR is assessed exactly as it was for a One- and Two-Way ANOVA; i.e., with an outlier test and a histogram of residuals (see Section 7.4). In SLR, some individuals may be considered influential points that draw the best-fit line towards them. Some very highly influential points may so strongly draw the line to them that the line will come very close to the point and the outlier test will not identify the point as an outlier (Figure 17.5-Left). Thus, I strongly urge you to look for abnormal points in your residual plots (Figure 17.5-Right) rather than relying solely on the outlier test to identify problem points. Figure 17.5: Scatterplot with a best-fit line for all points (dashed red) and all points excluding the red point (solid black) (Left) and the residual plot from the fit to all points (Right). Influential points are a huge problem in SLR because they make the best-fit line not represent the vast majority of the data. Influential points should be removed from the data if they are clearly an error. However, if they are not an error then the SLR should be fit both with and without the point and then a narrative should be constructed that describes how the points influences the regression results. Influential Point: An individual whose inclusion in the data set substantially impacts the coefficients of the fitted line. 17.6 Linearity The linearity assumption is the most important assumption in SLR; i.e., the form of the bivariate relationship must be linear in order to fit a line to it! Problems with the linearity assumption are diagnosed by examination of the residual plot. The most common departures from linearity look like parabolas on the residual plot (Figure 17.6), but more complicated structures may also be noted. A non-linearity may be difficult to diagnose if the homoscedasticity assumption is also not met (Figure 17.6-Right). Make sure to compare these residual plots to Figure 17.3. Figure 17.6: Residual plot where linearity assumption has NOT been adequately met. 17.7 Testing Assumptions in R The residual plot, histogram of residuals, Anderson-Darling test p-value, and outlier test p-value can all be constructed by submitting the saved lm() object to assumptionCheck().73 For example, the results below indicated that all assumptions are adequately met for the Mount Everest air temperature and altitude lapse rate regression  i.e., there is no discernible or obvious curve or funnel-shape to the residual plot, the Anderson-Darling p-value indicates that the residuals are normally distributed, and the outlier test p-value does not indicate the presence of any outliers. It should be noted, however, that the sample size is very small in this case. assumptionCheck(lm1.ev) If the linearity, homoscedasticity, normality, or no outliers assumptions are not met then transformations for the response variable, explanatory variable, or both should be considered (see Module 18). The concepts of predicted values and residuals was discussed in Module 14. If individuals are ordered by time or space then the Durbin-Watson statistic can be used to determine if the individuals are serially correlated or not. Generally, the H0: not serially correlated and HA: is serially correlated are the hypotheses for the Durbin-Watson test. Thus, p-values &lt; result in the rejection of H0 and the conclusion of a lack of independence. In this case, the regression assumption would be violated and other methods, primarily time-series methods, should be considered. This is exactly as you did for a One- and Two-Way ANOVA. "],["SLRTransformations.html", "Module 18 SLR Transformations 18.1 Transformations from Theoretical Relationships 18.2 Trial-and-Error Method 18.3 Back-Transformation in SLR 18.4 Examples", " Module 18 SLR Transformations The five assumptions of SLR and methods to assess their validity were introduced in Module 17. If one or more of the linearity, homoscedasticity, normality, or outlier assumptions are violated, then the data may be transformed to a different scale where the assumptions are met. Either the response variable, explanatory variable, or both may be transformed. In general, the family of power transformations (see Section 8.1) will be considered for both the response and explanatory variables, although some special transformations can be used in specific situations (e.g., \\(\\sin^{-1}\\sqrt{Y}\\) for proportions or percentage data). Power transformations may be selected based on theory, trial-and-error until assumptions are met, or from paste experience. Transformations from two common theoretical relationships and the trial-and-error method are discussed in the next two sections. 18.1 Transformations from Theoretical Relationships 18.1.1 Power Functions A power function is represented by \\(Y=aX^{b}\\) where \\(Y\\) and \\(X\\) are variables (as always) and \\(a\\) and \\(b\\) are parameters to be estimated. The power function is quite common and has been used to model relationships between the weight and length (or height) of animals, demand for money based on inventory theory, metabolic rate and body mass, money over time (with discretely compounded interest), and drug dose and size, among other applications. Functions with exponents will generally be non-linear.74 Thus, a power function is non-linear and will show a period of increasing increase if \\(b&gt;1\\), decreasing increase if \\(0&lt;b&lt;1\\), or decreasing decrease if \\(b&lt;0\\) (Figure 18.1). Figure 18.1: Shapes of power function for three values of the b exponent. Note that this is plotted on the raw or original scale. Also, as a general rule, if a simple function has an exponent then taking the logarithm75 of both sides tends to linearize the function. To show this relies on the following three properties of logarithms. The log of a product is the sum of the logs  i.e., \\(log(uv)=log(u)+log(v)\\) The log of a base with an exponent is the exponent times the log of the base  i.e., \\(log(u^{v})=vlog(u)\\) The log of the number \\(e\\) is 1  i.e., \\(log(e)=1\\) With these rules, taking the logarithm of both sides of the power function simplifies as follows: \\[ \\begin{split} log(Y) &amp;= log(aX^{b}) \\\\ log(Y) &amp;= log(a) + log(X^{b}) \\\\ log(Y) &amp;= log(a) + blog(X) \\end{split} \\] Here \\(log(Y)\\) and \\(log(X)\\) are still variables and \\(log(a)\\) is still a constant. Thus, this is the equation of the line where the response variable is \\(log(Y)\\), the explanatory variable is \\(log(X)\\), the y-intercept is \\(log(a)\\), and the slope is \\(b\\). The power functions shown in Figure 18.1 are shown again in Figure 18.2 but are plotted with both axes on the log scale. Figure 18.2: Same as previous figure but with both axes plotted on the logarithm scale. Transforming both the response and explanatory variable to the logarithm scale will linearize a power function relationship. In some instances the researcher may be interested in the value of \\(a\\) and \\(b\\) from the original power function. These values can be found by fitting a SLR to \\(log(Y)\\) and \\(log(X)\\) and noting from above that the y-intercept is an estimate of \\(log(a)\\) and the slope is an estimate of \\(b\\). Thus, \\(b\\) is simply the slope. An estimate of \\(a\\) requires back-transforming the y-intercept value as shown below \\[ \\begin{split} \\text{y-intercept} &amp;= log(a) \\\\ e^{\\text{y-intercept}} &amp;= e^{log(a)} \\\\ e^{\\text{y-intercept}} &amp;= a \\end{split} \\] Thus, \\(a\\) is estimated by raising the estimated y-intercept to the power of \\(e\\). The parameters for a power function are estimated by fitting a SLR to \\(log(Y)\\)-\\(log(X)\\) transformed data and estimating \\(b\\) with the slope and \\(a\\) with the back-transformed intercept, i.e., \\(a=e^{\\text{y-intercept}}\\) 18.1.2 Exponential Functions An exponential function is represented by \\(Y=ae^{bX}\\) where \\(Y\\), \\(X\\), \\(a\\) and \\(b\\) are define as with a power function. Exponential functions are also quite common and have been used to model growth of organisms over time (with unlimited resources), change in money over time with continuously compounded interest, prognostication for recover and number of days in the hospital, and radioactive decay over time. Figure 18.3: Shapes of an exponential function for two values of the b parameter. Note that this is plotted on the raw or original scale. Again, the exponential function has an exponent so we can try to linearize this function by applying logarithms to both sides. \\[ \\begin{split} log(Y) &amp;= log(ae^{bX}) \\\\ log(Y) &amp;= log(a) + log(e^{bX}) \\\\ log(Y) &amp;= log(a) + bX \\end{split} \\] Here \\(log(Y)\\) is still a variable and \\(log(a)\\) is still a constant. Thus, this is the equation of the line where the response variable is \\(log(Y)\\), the explanatory variable is unchanged at \\(X\\), the y-intercept is \\(log(a)\\), and the slope is \\(b\\). The exponential functions shown in Figure 18.3 are shown again in Figure 18.4 but are plotted with the y-axis on the log scale. Figure 18.4: Same as previous figure but plotted with the y-axis on the logarithm scale. Transforming only the response variable to the logarithm scale will linearize an exponential function relationship. Estimates of \\(a\\) and \\(b\\) from the original exponentnial function are found by fitting a SLR to \\(log(Y)\\) and \\(X\\) and noting from above that the y-intercept is an estimate of \\(log(a)\\) and the slope is an estimate of \\(b\\). Thus, \\(b\\) is simply the slope and \\(a\\) is estimated with \\(e^{\\text{y-intercept}}\\), exactly as with the power function. The parameters for an exponentnial function are estimated by fitting a SLR to \\(log(Y)\\)-\\(X\\) data and estimating \\(b\\) with the slope and \\(a\\) with the back-transformed intercept, i.e., \\(a=e^{\\text{y-intercept}}\\) 18.2 Trial-and-Error Method Transformations can be chosen by trying power transformations until the assumptions are met, as was discussed in Section 8.1. The big difference with SLR is that either the response, the explanatory, or both variables can be transformed. The following rules can be followed to simplify the process of finding a transformation or transformations by trial-and-error. Try transforming only the response variable first. Work though the list of power transformations as described in Section 8.1 (i.e., start with a log transformation, then the square root, cube root, etc.). If transforming the response does not meet the assumptions then try transforming the explanatory variable with the logarithms (and with the response variable untransformed). If transforming the explanatory to logarithms alone does not meet the assumptions then leave the explanatory variable transformed to logarithms and then work through the ladder of transformations for the response. Note that with the above process that you will (i) try to find a transformation of just the response variable first and (ii) will only every transform the explanatory variable to the logarithm scale. Additionally, you should try hard to avoid odd combinations of transformations. In other words, it is better to use logs for both the response and explanatory variable if the assumptions are slightly not met then to use, for example, the square root of the response variable and the logarithm of the explanatory variable. The trial-and-error method can be completed with assumptionCheck() largely as descried in Section 8.1 but noting that both lambday= and lambdax= may be used for the \\(Y\\) and \\(X\\) variables, respectively. 18.3 Back-Transformation in SLR Back-transformations were discussed in detail in Section 8.3 and many of those details pertain here. In SLR, the y-intercept, fitted values, and predicted values are all point estimates and can be back-transformed without issue. In other words, you can simply reverse the transformation for these values, not matter what transformation was used, and interpret the value directly on the original scale. The slope, however, is a difference in means and can only be back-transformed if a log transformation was used, as discussed in Section 8.3. A slope back-transformed from the log scale (for the response variable) has a specific mean but the exact wording of that meaning depends on whether the eplanatory variable was log-transformed or not. We begin by addressing the slope back-transformed from the log-scale for the situation where the explanatory variable was NOT log-transformed. First, note that the the slope (\\(\\beta\\)) on the log-transformed scale describes how the mean log of \\(Y\\) changes for a one unit change in \\(X\\); i.e., \\[ \\begin{split} log\\left(\\mu_{Y|X+1}\\right)-log\\left(\\mu_{Y|X}\\right) &amp;= \\left[\\alpha+\\beta (X+1)\\right] - \\left[\\alpha+\\beta X\\right] \\\\ &amp;= \\left[\\alpha+\\beta X\\right]+\\beta - \\left[\\alpha+\\beta X\\right] \\\\ &amp;= \\beta \\end{split} \\] Thus, \\(log(Y)\\) changes by adding \\(\\beta\\) as \\(X\\) increases by 1 unit. In other words, \\(\\beta\\) is a difference in two means (the mean of \\(log(Y)\\) at \\(X\\)s that are 1 unit apart). For example, in Figure 18.5-Left, the slope on the log-transformed scale indicates that for a one unit increase in \\(X\\) that the predicted value of \\(log(Y)\\) increases by adding 0.25 units. Figure 18.5: Demonstration of the additive nature of the slope on the log-scale (Left) and multiplicative nature of the back-transformed slope on the original scale (Right). However, when both sides of the above equation are raised to the power of \\(e\\) (i.e., back-transformed) \\[ \\begin{split} e^{\\beta} &amp;= e^{log(\\mu_{Y|X+1})-log(\\mu_{Y|X})} \\\\ &amp;= e^{log\\left(\\frac{\\mu_{Y|X+1}}{\\mu_{Y|X}}\\right)} \\\\ &amp;= \\frac{\\mu_{Y|X+1}}{\\mu_{Y|X}} \\end{split} \\] it becomes clear that \\(e^{\\beta}\\) is no longer a difference in means, rather it is a ratio of two means. Thus, the mean of \\(Y\\) (on the original scale) at \\(X+1\\) is a multiple of the mean of \\(Y\\) at \\(X\\). Therefore, on the original scale you multiply rather than add when increasing \\(X\\) by 1 unit. For example, in Figure 18.5-Right, a one unit increase in \\(X\\) (the original scale) results in a \\(Y\\) that increases by a multiple of 1.284. For example, an increase in \\(X\\) from 4 to 5 results in an increase in \\(Y\\) from 2.72 to 3.49 (=2.27Ã—1.284). Similarly, an increase in \\(X\\) from 8 to 9 results in an incrase in \\(Y\\) from 7.39 to 9.49 (=7.39Ã—1.284). For negative relationships, the same principle holds except that the back-transformed slope will be less than 1 so that an increase in \\(X\\) results in a multiplicative decrease in \\(Y\\) (Figure 18.6). Figure 18.6: Demonstration of the additive nature of the slope on the log-scale (Left) and multiplicative nature of the back-transformed slope on the original scale (Right). The slope back-transformed from a log-transformation represents the ratio of two means separated by one unit of the explanatory variable on the original scale when the explanatory variable was not transformed. If the explanatory variable was also log-transformed then the interpretation of the back-transformed slope is more complicated. In this case, we must also back-transform the one unit increase in \\(log(X)\\) when considering the the back-transformed slope on the original scale. Thus, the slope backtransformed from the case where both the response and explanatory variable were log-transformed is the multiplicative change in \\(Y\\) when \\(X\\) is multiplied by \\(e^{\\beta}\\)=2.718. For exapmle, in Figure 18.7 the slope on the log-log-transformed scale is 0.25. Thus, \\(log(Y)\\) increases by adding 0.25 when \\(log(X)\\) increases by 1 unit. However, on the original scale \\(Y\\) increases by a multiple of \\(e^{0.25}\\)=1.284 each time that \\(X\\) increases by a multiple of \\(e^{1}\\)=2.718. For example, when \\(X\\) increases from 7.39 to 20.98 (7.39Ã—2.718) then \\(Y\\) increases from 1.65 to 2.12 (=1.65Ã—1.284). As another example, when \\(X\\) increases from 54.60 to 148.41 (54.60Ã—2.718) then \\(Y\\) increases from 2.72 to 3.49 (=2.72Ã—1.284). Figure 18.7: Demonstration of the additive nature of the slope on the log-log-scale (Left) and multiplicative nature of the back-transformed slope (and multiplicative change along the x-axis) on the original scale (Right). The slope back-transformed from a log-transformation represents the ratio of two means separated by a multiple of 2.178 units of the explanatory variable on the original scale when the explanatory variable was log-transformed. A slope back-transformed from the log-scale represents a multiplicative (rather than additive) change in the mean response. Do NOT back-transform slopes if other than a log transformation was used. 18.4 Examples The following are some quick examples of transforming data, fitting new models, and interpretations of those model results. These are not full examples in the sense that all assumptions are thoroughly met, etc. Full examples will be demonstrated in Module 19. 18.4.1 Petrels Croxall (1982) examined the weight loss of adult petrels during periods of egg incubation. He examined 13 species but some had measurements for both sexes such that 19 measurements were recorded. For each measurement the mean initial weight (g) and mean weight lost (g/g/d) were recorded. The intent of this part of the study was to determine if the mean initial weight significantly explained variability in mean weight lost for the petrel species. The data are loaded below, the initial SLR is fit with weight loss as the response variable, and the assumptions are quickly checked. It is clear that the form of the relationship is not linear. The other assumptions are also not met, but these are likely affected by the non-linearity. petrels &lt;- read.csv(&quot;http://derekogle.com/Book207/data/Petrels.csv&quot;) str(petrels) #R&gt; &#39;data.frame&#39;: 19 obs. of 4 variables: #R&gt; $ species : chr &quot;Diomedea exulans&quot; &quot;Diomedea exulans&quot; &quot;Diomedea melanophris&quot; &quot;Diomedea melanophris&quot; ... #R&gt; $ sex : chr &quot;male&quot; &quot;female&quot; &quot;male&quot; &quot;female&quot; ... #R&gt; $ weight : int 10577 9022 3922 3694 3751 3624 3305 3000 2996 668 ... #R&gt; $ weight.loss: num 0.0087 0.0096 0.013 0.011 0.01 0.012 0.011 0.0125 0.0109 0.0128 ... lm.ptrls1 &lt;- lm(weight.loss~weight,data=petrels) assumptionCheck(lm.ptrls1) Through a process of trial-and-error, it appears that log-transforming both weight loss and initial weight results in the assumptions being met. Thus, log-transformations for both variables were added to the data.frame and were used in a second linear model. assumptionCheck(lm.ptrls1,lambday=0,lambdax=0) petrels$logwtloss &lt;- log(petrels$weight.loss) petrels$logwt &lt;- log(petrels$weight) lm.ptrls2 &lt;- lm(logwtloss~logwt,data=petrels) There is a significant relationship between log mean weight loss and log mean initial weight (p&lt;0.00005). It appears that 89.2% of the variability in log mean weight loss is explained by knowing the log mean initial weight of the birds. anova(lm.ptrls2) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: logwtloss #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; logwt 1 6.5113 6.5113 140.65 1.204e-09 #R&gt; Residuals 17 0.7870 0.0463 rSquared(lm.ptrls2) #R&gt; [1] 0.8921662 ggplot(data=petrels,mapping=aes(x=logwt,y=logwtloss)) + geom_point(pch=21,color=&quot;black&quot;,fill=&quot;lightgray&quot;) + labs(x=&quot;log Mean Initial Weight&quot;,y=&quot;log Mean Weight Loss&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;) The slope indicates that as the log mean initial weight increases by 1 then the log mean weight loss will decrease by between 0.276 and 0.396. Because both the response and the explanatory variable were log-transformed, the back-transformed slope means that as the mean initial weight increases by a multiple of 2.718 then the mean weight loss is multiplied by between 0.673 and 0.758. In other words, as the mean initial weight increases by a multiple of 2.718 then the mean weight loss decreases by between 24.2 and 32.7%. ( cfs &lt;- cbind(Ests=coef(lm.ptrls2),confint(lm.ptrls2)) ) ## log-log scale #R&gt; Ests 2.5 % 97.5 % #R&gt; (Intercept) -1.7340329 -2.1516113 -1.3164546 #R&gt; logwt -0.3363196 -0.3961507 -0.2764885 exp(cfs) ## back-transformed to original scale #R&gt; Ests 2.5 % 97.5 % #R&gt; (Intercept) 0.1765709 0.1162966 0.2680841 #R&gt; logwt 0.7143948 0.6729053 0.7584423 The predicted log mean weight loss for a bird species with a mean initial weight of 4000 g is between -4.998 and -4.049. However, back-transformed to the original scale, the predicted mean weight loss for a bird species with a mean initial weight of 4000 g is between 0.0068 and 0.0174 g/g/d. iw &lt;- 4000 nd &lt;- data.frame(logwt=log(iw)) ( p4000 &lt;- predict(lm.ptrls2,newdata=nd,interval=&quot;predict&quot;) ) # log scale #R&gt; fit lwr upr #R&gt; 1 -4.523484 -4.998201 -4.048767 exp(p4000) # back-transformed to original scale #R&gt; fit lwr upr #R&gt; 1 0.01085115 0.006750078 0.01744386 18.4.2 BAC and Crashing A study was published in 2007 that investigated the relative risk of being in a crash (RRC) relative to a persons blood alcohol content (BAC). The researchers examined data from 2871 crashes and derived a measure of the relative risk of being in a car accident. The relative risk was scaled so that individuals with a blood alcohol content of 0 had a relative risk of 1. Thus, all other relative risk values are in comparison to a driver with a BAC of 0. For example, a relative risk of 3 would mean that persons with that BAC level are three times more likely to be in a car accident than a person with a BAC of 0. The researchers wanted to explain how the relative risk of a crash was related to BAC level. [Note that BAC was multiplied by 100 so that a one unit change would be within the range of the data and, thus, would be meaningful.] The data are loaded below, the initial SLR is fit with relative risk of a crash as the response variable, and the assumptions are quickly checked. It is clear that the form of the relationship is not linear. The scatterplot also clearly shows that a linear model is not appropriate for these data. The other assumptions are also not met, but these are likely affected by the non-linearity. cr &lt;- read.csv(&quot;http://derekogle.com/Book207/data/crash.csv&quot;) str(cr) #R&gt; &#39;data.frame&#39;: 12 obs. of 2 variables: #R&gt; $ BAC: int 0 1 3 5 7 9 11 13 15 17 ... #R&gt; $ RRC: num 1 1.24 1.85 3.37 7.17 ... lm.cr &lt;- lm(RRC~BAC,data=cr) assumptionCheck(lm.cr) ggplot(data=cr,mapping=aes(x=BAC,y=RRC)) + geom_point(pch=21,color=&quot;black&quot;,fill=&quot;lightgray&quot;) + labs(x=&quot;Blood Alcohol Content (x100)&quot;,y=&quot;Relative Risk of a Crash&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;) Through a process of trial-and-error, it appears that log-transforming just the relative risk of a crash results in the assumptions being met. A second linear model was fit with log relative risk of a crash. assumptionCheck(lm.cr,lambday=0) cr$logRRC &lt;- log(cr$RRC) lm.cr2 &lt;- lm(logRRC~BAC,data=cr) There is a significant relationship between log relative risk of a crash and blood alcohol content (p&lt;0.00005). It appears that 99.3% of the variability in log relative risk of a crash is explained by knowing the blood alcohol content. anova(lm.cr2) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: logRRC #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; BAC 1 33.690 33.690 1452.2 3.692e-12 #R&gt; Residuals 10 0.232 0.023 rSquared(lm.cr2) #R&gt; [1] 0.9931612 ggplot(data=cr,mapping=aes(x=BAC,y=logRRC)) + geom_point(pch=21,color=&quot;black&quot;,fill=&quot;lightgray&quot;) + labs(x=&quot;Blood Alcohol Content (x100)&quot;,y=&quot;log Relative Risk of a Crash&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;) The slope indicates that as the blood alcohol content increases by 0.01 (because the BAC was multiplied by 100) then the log relative risk of a crash will increase by between 0.233 and 0.262. Because only the response variable was log-transformed, the back-transformed slope means that as the blood alcohol content increases by 0.01 then the relative risk of an accident increases by a multiple of between 1.262 and 1.299. So, as the blood alcohol content increases by 0.01 then the relative risk of an accident increases by between 26.2 and 29.9%. ( cfs &lt;- cbind(Est=coef(lm.cr2),confint(lm.cr2))) #R&gt; Est 2.5 % 97.5 % #R&gt; (Intercept) -0.003342789 -0.1789921 0.1723065 #R&gt; BAC 0.247289672 0.2328310 0.2617483 exp(cfs) #R&gt; Est 2.5 % 97.5 % #R&gt; (Intercept) 0.9966628 0.8361125 1.188042 #R&gt; BAC 1.2805500 1.2621682 1.299200 The predicted mean log relative risk of a crash for all drivers with a blood alcohol content of 0.10 (so 10 for the BAC variable) is between 2.116 and 2.823. However, back-transformed to the original scale, the predicted relative risk of a crash for all drivers with a blood alcohol content of 0.10 is between 8.30 and 16.82. nd &lt;- data.frame(BAC=10) ( p10 &lt;- predict(lm.cr2,newdata=nd,interval=&quot;predict&quot;) ) #R&gt; fit lwr upr #R&gt; 1 2.469554 2.116327 2.822781 exp(p10) #R&gt; fit lwr upr #R&gt; 1 11.81717 8.300589 16.82358 Except for trivial choices of the exponent, such as \\(b=0\\) or \\(b=1\\) in the power function. As we have throughout this course, we are using natural logarithms here. "],["SLRSummary.html", "Module 19 SLR Summary 19.1 Suggested Workflow 19.2 Climate Change Data (No Transformation) 19.3 Forest Allometrics (Transformation)", " Module 19 SLR Summary Specific parts of a full Simple Linear Regression (SLR) analysis were described in Modules 14-18. In this module, a workflow for a full analysis is offered and that workflow is demonstrated with several examples. 19.1 Suggested Workflow The following is a process for fitting a SLR. Consider this process as you learn to fit SLR models, but dont consider this to be a concrete process for all models. Perform a thorough EDA. Pay close attention to the form, strength, and outliers on the scatterplot of the response and explanatory variables. Show the overall sample size. Address the independence assumption. If this assumption is not met then other analysis methods must be used. Fit the untransformed full model with lm(). Check the other four assumptions for the untransformed model with assumptionCheck(). Check the linearity of the relationship with the residual plot. Check homoscedasticity with the residual plot. Check normality of residuals with an Anderson-Darling test and histogram of residuals. Check outliers and influential points with the outlier test and residual plot. If an assumption or assumptions are violated, then attempt to find a transformation where the assumptions are met. Use trial-and-error with assumptionCheck(), theory (e.g., power or exponential functions), or experience to identify possible transformations for the response variable and, possibly, for the explanatory variable. Attempt transformations with the response variable first. Generally only ever transform the explanatory variable with logarithms. If only an outlier or influential observation exists (i.e., linear, homoscedastic, and normal residuals) and no transformation corrects the problem, then consider removing that observation from the data set. Fit the full model with the transformed variable(s) or reduced data set. Construct an ANOVA table for the full model with anova() and interpret the overall F-test. Summarize findings with coefficient results and confidence intervals with cbind(coef(),confint()). Create a summary graphic of the fitted line with 95% confidence band using ggplot(). Make predictions with predict(), if desired. Write a succinct conclusion of your findings. 19.2 Climate Change Data (No Transformation) Climate researchers examined the relationship between global temperature anomaly and the concentration of CO2 in the atmosphere. Temperature anomaly data was recorded as the Global Land-Ocean Temperature Index from the Goddard Institute of Space Studies (GISTEMP). It is reported in units of 1/100oC increase above the 1950-1980 mean. The CO2 data are from The Earth System Research Laboratory of the National Oceanic and Atmospheric Administration (NOAA). Specifically, these data are a record of annual mean atmospheric CO2 concentration at Mauna Loa Observatory, Hawaii, and constitute the longest continuous record of atmospheric CO2 concentration. This remote location at high altitude in Hawaii was chosen because it is relatively unaffected by any local emissions and so is representative of the global concentration of a well-mixed gas like CO2. These observations were started by C. David Keeling of the Scripps Institution of Oceanography in March of 1958 and are often referred to as the Keeling Curve. Data are reported as a dry mole fraction defined as the number of molecules of carbon dioxide divided by the number of molecules of dry air multiplied by one million (ppm). Our goal here is to determine if the variability in the temperature anomaly records can be reasonably explained by the CO2 values in the same year. The statistical hypotheses to be examined are \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{no relationship between temperature anomaly and CO2 values}&#39;&#39; \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{is a relationship between temperature anomaly and CO2 values}&#39;&#39; \\\\ \\end{split} \\] Data was recorded for 32 years. The data between years is likely not independent as knowing the temperature anomaly and CO2 values in any given year likely are a good indicator of the values in the next year. This temporal dependence should probably be included in the analysis. However, these data are recorded on an annual basis and it does not make much sense to include only a random sample of years. Thus, to better understand the relationship between these two variables, I will continue with this analysis assuming independence. The assumptions are met as the residual plots show no obvious curvature or funneling (Figure 19.1-Right), the histogram of residuals is not strongly skewed (Figure 19.1-Left) and the Anderson-Darling tests suggests that it is approximately normal (p=0.4313), and the there are not obvious outliers (p&gt;1). Thus, the analysis can continue without any transformations. Figure 19.1: Histogram of residuals (Left) and residual plot (Right) for a simple linear regression of temperature anomaly on CO2 data. The temperature anomaly and CO2 data appear to be significantly related (p&lt;0.00005; Table 19.1). In fact, 74.1% of the variability in the temperature anomaly is explained by knowing the value of the CO2 concentration. Table 19.1: ANOVA table for simple linear regression of temperature anomaly on CO2 data. Df Sum Sq Mean Sq F value Pr(&gt;F) CO2 1 7717.1 7717.1 85.918 0 Residuals 30 2694.6 89.8 In fact, it appears that as as the CO2 levels increase by 1 ppm then the temperature anomaly increases by between 0.80 and 1.26 1/100oC (Table 19.2; Figure 19.2). Table 19.2: Intercept and slope, along with 95% confidence intervals, for simple linear regression of temperature anomaly on CO2 data. Est 2.5 % 97.5 % (Intercept) -338.25 -420.24 -256.25 CO2 1.03 0.80 1.26 Figure 19.2: Scatterplot of temperature anomaly versuse CO2 concentration with the best-fit line and 95% confidence band superimposed. Finally, the predicted mean temperature anomaly for all times when the CO2 concentration was 360 ppm is between 29.2 and 36.0. R Code and Results cc &lt;- read.csv(&quot;http://derekogle.com/NCMTH107/modules/CE/GSI_data.csv&quot;) str(cc) lm.cc &lt;- lm(Temp~CO2,data=cc) assumptionCheck(lm.cc) anova(lm.cc) rSquared(lm.cc) cbind(Est=coef(lm.cc),confint(lm.cc)) ggplot(data=cc,mapping=aes(x=CO2,y=Temp)) + geom_point(pch=21,color=&quot;black&quot;,fill=&quot;lightgray&quot;) + labs(x=&quot;CO2 Concentration (ppm)&quot;,y=&quot;Temperature Anomaly (1/100C)&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;) nd &lt;- data.frame(CO2=360) predict(lm.cc,newdata=nd,interval=&quot;confidence&quot;) 19.3 Forest Allometrics (Transformation) Understanding the carbon dynamics in forests is important to understanding ecological processes and managing forests. The amount of carbon stored in a tree is related to tree biomass. Measuring the biomass of a tree is a tedious process that also results in the harvest (i.e., death) of the tree. However, biomass is often related to other simple metrics (e.g., diameter-at-breast-height (DBH) or tree height) that can be made without harming the tree. Thus, forest scientists have developed a series of equations (called allometric equations) that can be used to predict tree biomass from simple metrics for a variety of trees in a variety of locations. The Miombo Woodlands is the largest continuous dry deciduous forest in the world. It extends across much of Central, Eastern, and Southern Africa including parts of Angola, the Democratic Republic of Congo, Malawi, Mozambique, Tanzania, Zambia, and Zimbabwe. The woodlands are rich in plant diversity and have the potential to contain a substantial amount of carbon. There is, however, significant uncertainty in the amount of biomass carbon in the Miombo Woodlands. The objective of this study (Kuyah et al. 2016) is to develop allometric equations that can be used to reliably estimate biomass of trees in the Miombo Woodlands so that biomass carbon can be more reliably estimated. Trees for building allometric models were sampled from three 10 km by 10 km sites located in the districts of Kasungu, Salima, and Neno. A total of 88 trees (33 species) were harvested from six plots in Kasungu, seventeen plots in Salima, and five plots in Neno. The DBH (cm) of each tree was measured using diameter tape. Each tree was felled by cutting at the lowest possible point using a chainsaw. The length (m) of the felled tree was measured along the longest axis with a measuring tape. This measurement was used as the total tree height in the analysis. Felled trees were separated into stem, branches, and twigs (leaves and small branches). Total biomass (kg) of the tree (above-ground biomass; AGB) and the separate biomasses (kg) of the stems, branches, and twigs was recorded. The data are stored in TreesMiombo.csv (data, meta). This analysis will attempt to predict AGB from DBH. The statistical hypotheses to be examined are \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{no relationship between above ground biomass and diameter at breast height}&#39;&#39; \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{is a relationship between above ground biomass and diameter at breast height}&#39;&#39; \\\\ \\end{split} \\] There is some concern over independence because some of the trees presumably came from the same plot and it is possible that one tree might have an impact on another tree. That impact may have been on the overall growth of the tree through density-dependent factors and it is hard to imagine how one tree could effect another tree with respect to the relationship between above ground biomass and diameter at breast height. Thus, I will continue with analysis assuming independence. The residual plot (Figure 19.3-Right) indicates a lack of linearity and homoscedasticity as there is both a clear curve and funnel present. There also appears to be a lack of normality in the residuals (Anderson-Darling p=0.0041) and the presence of outliers (outlier test p&lt;0.00005). These results all indicate that a transformation should be explored. Figure 19.3: Histogram of residuals (Left) and residual plot (Right) for a simple linear regression of above ground biomass on diameter at breast height for trees from the Miombo Woodlands. Allometric relationships between weights (i.e., biomass) and lengths (i.e., height) tend to follow power functions, which can be linearized with the log of both variables. When both variables were transformed the relationship was largely linear and homoscedastic (Figure 19.4-Right), the residuals appear to be normal (Anderson-Darling p=0.4463; Figure 19.4-Left), and no outliers are present (outlier test p&gt;1). Thus, the linear regression model was fit to the log-log transformed data as all assumptions were met. Figure 19.4: Histogram of residuals (Left) and residual plot (Right) for a simple linear regression of log above ground biomass on log diameter at breast height for trees from the Miombo Woodlands. The log above ground biomass and log diameter at breast height appear to be significantly related (p&lt;0.00005; Table 19.3). In fact, 96.3% of the variability in the above ground biomass is explained by knowing the value of the diameter at breast height. Table 19.3: ANOVA table for simple linear regression of log above ground biomass on log diameter at breast height for trees from the Miombo Woodlands. Df Sum Sq Mean Sq F value Pr(&gt;F) logDBH 1 244.86 244.86 2238.21 0 Residuals 86 9.41 0.11 In fact, it appears that as as the log diameter at breast height increases by 1 unit then the log above ground biomass increases by between 2.17 and 2.37 units (Table 19.4; Figure 19.5). More importantly, as the diameter at breast height increases by a multiple of 2.718 the above ground biomass increases by a multiple of between 8.80 and 10.65. Table 19.4: Intercept and slope, along with 95% confidence intervals, for simple linear regression of log above ground biomass on log diameter at breast height for trees from the Miombo Woodlands. Est 2.5 % 97.5 % (Intercept) -1.94 -2.26 -1.63 logDBH 2.27 2.17 2.37 Figure 19.5: Scatterplot of log above ground biomass on log diameter at breast height for trees from the Miombo Woodlands. with the best-fit line and 95% confidence band superimposed. Finally, the predicted above ground biomass for a tree with a diameter at breast height of 50 cm is between 529.9 and 2002.1 kg. In conclusion, a significant and very strong relationship was found between the natural log above-ground biomass and the natural log diameter-at-breast-height for trees in the Miombo Woodlands. A model was developed from this relationship that can be used to predict above-ground biomass of a tree from the measured DBH of the tree. R Code and Results tm &lt;- read.csv(&quot;https://raw.githubusercontent.com/droglenc/NCData/master/TreesMiombo.csv&quot;) tm &lt;- filterD(tm,!outlier) ## data entry error removed lm.tm1 &lt;- lm(AGB~DBH,data=tm) assumptionCheck(lm.tm1) assumptionCheck(lm.tm1,lambday=0,lambdax=0) tm$logDBH &lt;- log(tm$DBH) tm$logAGB &lt;- log(tm$AGB) lm.tm2 &lt;- lm(logAGB~logDBH,data=tm) anova(lm.tm2) rSquared(lm.tm2) ggplot(data=tm,mapping=aes(x=logDBH,y=logAGB)) + geom_point(pch=21,color=&quot;black&quot;,fill=&quot;lightgray&quot;) + labs(x=&quot;log Diameter at Breast Height&quot;,y=&quot;log Above Ground Biomass&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;) aov.p.tm2 &lt;- anova(lm.tm2)$&quot;Pr(&gt;F)&quot;[1] ( cfs.tm2 &lt;- cbind(Est=coef(lm.tm2),confint(lm.tm2)) ) exp(cfs.tm2) nd &lt;- data.frame(logDBH=log(50)) ( pl50 &lt;- predict(lm.tm2,newdata=nd,interval=&quot;prediction&quot;) ) exp(pl50) "],["IVRVariables.html", "Module 20 IVR Variables 20.1 Indicator Variables 20.2 Interaction Variables", " Module 20 IVR Variables Simple linear regression is a powerful tool used to evaluate the relationship between two quantitative variables (Modules 14-19). It is common for a researcher to compare simple linear regression models fit to separate groups of individuals. Indicator variable regression (IVR),76 is a method to make these comparisons. For example, IVR methods could be used in each of the following situations. Determine if the relationship between propodus height and claw closing force differs among three types of crabs (Yamada and Boulding 1998). Determine if the proportional area covered by an invasive plant differs between sites after adjusting for different resident times for the plant (i.e., how long it has been present at a site) (Mullerova et al. 2005). Determine if the relationship between the sales of a product and the price of the product differs among regions of the country. Determine if the relationship between total body electrical conductivity and lean body mass (a method used to measure body fat) differs between live and dead birds of various species (Castro et al. 1990). Determine if the relationship between a pitchers earned run average (ERA) and the average pitch speed at the point of release differs among pitchers in the National and American Leagues. As shown in each of these examples, an IVR consists of a quantitative response variable, a single quantitative explanatory variable, and a second categorical explanatory variable that identifies the groups. As is common with IVRs, the quantitative explanatory variable will be referred to as a covariate and the categorical explanatory variable will be referred to as a factor.77 Covariate: The quantitative explanatory variable in an IVR model. In this course, we will only consider one factor, though the methods described here easily extend to multiple factors. An IVR with a single factor variable is called a one-way IVR model. Example Data Throughout this and the next few modules, we will refer to a study by Makarewicz et al. (2003), who examined the relationship between the concentration of mirex in the tissue and the weight of salmon.78 They collected these data on Coho Salmon (Oncorhynchus kisutch) and Chinook Salmon (Oncorhynchus tshawytscha) in six different years. They were interested in determining if the relationship between mirex and weight differed between the two species or if it differed among years (Table 20.1). Table 20.1: Subset of the Mirex in salmon data. year weight mirex species 1977 0.41 0.16 chinook 1977 4.77 0.22 coho 1982 2.92 0.22 chinook 1986 1.70 0.12 coho 1986 9.53 0.41 chinook 1996 0.90 0.07 coho 1999 2.61 0.03 coho 1999 11.82 0.09 chinook 20.1 Indicator Variables Only Two Levels The factor variable must be converted to numeric codes to be included in a linear model. An indicator variable contains the numeric codes created from the factor variable. Specifically, an indicator variable consists of 0s and 1s, where a 1 indicates that the individual has a certain characteristic and a 0 indicates that it does not have the characteristic.79 Indicator Variable: A variable that is a numerical representation of a dichotomous (or binary or binomial) categorical variable. For example, the species factor variable in the salmon mirex data could be converted to an indicator variable of \\[ COHO = \\left\\{\\begin{array}{l} 1 \\text{ if a Coho salmon }\\\\ 0 \\text{ if NOT a Coho salmon} \\end{array} \\right. \\] Alternatively, it could also be cast as \\[ CHINOOK = \\left\\{\\begin{array}{l} 1 \\text{ if a Chinook salmon }\\\\ 0 \\text{ if NOT a Chinook salmon} \\end{array} \\right. \\] Importantly, both of these indicator variables would not be used as each one exhausts the possibilities. For example if COHO=1 you know you have a Coho Salmon and if COHO=0 you know that you have a Chinook Salmon. Indicator variables will be coded as 0 for individuals that do NOT have the characteristic of interest and 1 for individuals that do have the characteristic of interest. An indicator variable should be named after the characteristic denoted by a 1. This will provide consistency so that it will be easy to remember what the indicator variable represents and how the coding was made. The two examples above followed this rule  the COHO indicator variable was a 1 when the fish was a Coho Salmon and the CHINOOK indicator variable was a 1 when the fish was a Chinook Salmon. Indicator variables should be named after the 1 group so that it is easy to remember the coding scheme being used. So, if a factor with two levels can be cast as two indicator variables, but only one of those indicator variables is needed, then which one should be used? For the most part, it does not matter as there will be some differences in the analytical output but the ultimate conclusions will be the same. However, the levels of factor variables in R are ordered alphabetically. With this, the first level is assigned a 0 in R and the second level is assigned a 1. Thus, R will create indicator variables named after the alphabetically second group. To maintain consistency with R we will follow this convention. Thus, we would use the COHO indicator variable as Coho comes after Chinook. The relationship between the original factor variable and the indicator variable is easy to keep track of when there are only two groups, it is more work when there are more groups (see next section). To prepare for this, we often organize a table such as that below, where the groups are shown in the left-most column and the indicator variable(s) with its codes are shown in the right-most column(s). species COHO chinook 0 coho 1 More than Two Levels Combinations of indicator variables can be used to code factor variables that consist of more than two levels. For example, Makarewicz et al. (2003) were also interested in determining if the relationship between mirex concentrations and weight of the salmon differed among six collection years. For simplicity and space considerations, lets consider that they were interested in only three years  1977, 1982, and 1986. In this simpler situation, two indicator variables would be created to represent the year factor variable. \\[ YEAR1982 = \\left\\{\\begin{array}{l} 1 \\text{ if collected in 1982 }\\\\ 0 \\text{ if NOT collected in 1982 } \\end{array} \\right. \\] and \\[ YEAR1986 = \\left\\{\\begin{array}{l} 1 \\text{ if collected in 1986 }\\\\ 0 \\text{ if NOT collected in 1986} \\end{array} \\right. \\] Note that it is possible to create a third dummy variable to represent salmon collected in 1977. However, this indicator variable is redundant with the YEAR1982 and YEAR1986 indicator variables because if YEAR1982=0 and YEAR1986=0 then the salmon must have been collected in 1977. This illustrates the rule that the number of indicator variables required is one less than the number of levels to be coded.80 year YEAR1982 YEAR1986 1977 0 0 1982 1 0 1986 0 1 One less indicator variable is needed then the number of categories in the factor variable. The level denoted by the group with 0s for all related indicator variables is called the reference group. In the last example above, the salmon collected in 1977 would be considered the reference group. It will be shown in Module 21 that all comparisons of intercepts and slopes in the analysis will refer to this group of individuals. Suppose, for illustration purposes, that fish collected in 1982 were to be considered the reference group rather than fish collected in 1977. In this situation, the indicator variable would be replaced with the indicator variable in the model and the table relating the year variable to the indicator variables would be as shown below. year YEAR1977 YEAR1986 1977 1 0 1982 0 0 1986 0 1 Reference group: The category or group that is represented by zeroes for all indicator variables. Changing the reference group in an analysis requires changing the indicator variables used in the analysis. 20.2 Interaction Variables An interaction variable is an explanatory variable that is the product of two or more other explanatory variables (see Module 10). In IVR models, interaction variables are created between the covariate and each of the indicator variables. Thus, there will always be as many interaction variables as there are indicator variables in an IVR. For example, in the example with Coho and Chinook Salmon, there would be one interaction variable  COHO:Weight. However, in the the example with the three years of data there would be two interaction variables  YEAR1982:Weight and YEAR1986:Weight. In IVR, interaction variables are constructed from the covariate and each indicator variable. Thus, there are as many interaction as indicator variables in an IVR. Interaction variables serve the same purpose in an IVR as they did in a Two-Way ANOVA (see Modules 10). That is, the interaction variable is used to identify if the effect of one explanatory variable (here the covariate) on the response variable differs depending on the other explanatory variable (here the factor). In other words, an interaction variable will be used to determine if the effect of the covariate on the response variable differs among roups (i.e., levels of the factor). For example, the interaction variable will allow us to determine if the effect of weight of the salmon on the concentration of mirex in the tissue differs by species of salmon. Interaction variables in IVR are used to determine if the effect of the covariate on the response variable differs among groups defined by the indicator variable(s). The interaction between two variables in an IVR model may best be illustrated by looking at the examples in Figure 20.1. In the panel on the left, the effect of salmon weight (the covariate) on mirex concentration in the tissue (the response) is the same for Coho and Chinook Salmon. This is illustrated by each group having the same slope.81 However, in the panel on the right, different slopes indicate that the effect of salmon weight on mirex concentration in the tissue differs between the two species. In this particular example, the relationship is flatter for Coho than for Chinook Salmon. Thus, an interaction exists for the situation depicted in Figure 20.1-Right, because the effect of the covariate on the response depends on which group is being considered. Graphically, an interaction is illustrated by non-parallel lines. Figure 20.1: Idealized fitted-line plots representing SLR fit to two groups. The graph on the left indicates the absence of an interaction. The graph on the right indicates the presence of an interaction. Parallel lines indicate no interaction effect; non-parallel lines indicate an interaction effect. This is not a standard name. Some authors call it dummy variable regression (e.g., Fox 1997), whereas others call it Analysis of Covariance (ANCOVA). I will not use either of these terms as I prefer the word indicator to dummy and I will reserve the ANCOVA method for the situation where the separate SLR models are known or assumed to have equal slopes. Thus, ANCOVA models are a subset of the IVR models discussed here. It should also be noted that some authors (e.g., Weisberg 2005) do not use a separate name for IVR but simply include it as a multiple linear regression model. Similar to what was one with the One- and Two-Way ANOVAS in Modules 5-13. Mirex is a chlorinated hydrocarbon that was commercialized as an insecticide. Use of mirex was banned in 1976 because of its impact on the environment. Other coding schemes exist. For example, contrast coding uses -1 and 1. However, the 0 and 1 coding scheme leads to simpler interpretations and calculations and, thus, is used throughout this course. This is only true if an intercept term exists in the regression model, which will be the case for all models in this course. In regression the effect of the explanatory variable on the response variable is measured by the slope. "],["IVRModels.html", "Module 21 IVR Models &amp; Sub-Models 21.1 Ultimate Full Model 21.2 Sub-Models 21.3 Interpreting Parameter Estimates 21.4 Ultimate Full Model in R", " Module 21 IVR Models &amp; Sub-Models Covariate, indicator, and interaction variables (see Module 20) can be entered into a single model that will allow one to determine if simple linear regression lines differ among groups. As such, possible differences among slopes, intercepts, or both can be determined. In this module, the model for this Indicator Variable Regression (IVR) analysis is introduced. Hypothesis testing for slopes and intercepts is introduced in Module 22. 21.1 Ultimate Full Model Consider the situation introduced in Module 20 where researchers examined the effect of salmon weight on mirex concentration in the tissue for two species of salmon (Coho and Chinook). In this case, there is one quantitative response variable (\\(MIREX\\)), one covariate (\\(WEIGHT\\)), and one indicator variable (\\(COHO\\)) generated from a factor variable with only two categories (i.e., species). In addition, there is an interaction variable between \\(WEIGHT\\) and \\(COHO\\). The ultimate full model for this situation is \\[ \\mu_{MIREX|WEIGHT,COHO} = \\alpha+\\beta WEIGHT+\\delta_{1}COHO+\\gamma_{1}WEIGHT:COHO \\] This is called the ultimate full model because the model cannot get more complicated that this for this situation as all variables of interest are included in the model. In subsequent modules, simpler models with fewer variables (and parameters) than this one will also be considered. The covariate, indicator, and interaction variables are entered in that order into the ultimate full model of an IVR to allow for consistent and simple interpretations. Specific parameters are used in the ultimate full model of an IVR as shown above. Specifically, they are as follows: \\(\\alpha\\): an overall intercept term. \\(\\beta\\): coefficient on the covariate. \\(\\delta_{i}\\): coefficient on the ith indicator variable. \\(\\gamma_{i}\\): coefficient on the interaction between the covariate and the ith indicator variable. Each of these parameters has a specific meaning or interpretation that will be better understood by reducing the ultimate full model to its constituent sub-models. 21.2 Sub-Models The ultimate full model in IVR contains sub-models that are SLR models for each group represented by the indicator variables. The sub-models can be revealed by substituting appropriate values for the indicator variables in the ultimate full model. For example \\(COHO=0\\) for the non-Coho group (i.e., Chinook). Thus, to find the sub-model for Chinook Salmon, plug 0 for \\(COHO\\) in the ultimate full model and simplify. \\[ \\begin{split} \\mu_{MIREX|WEIGHT,COHO} &amp;= \\alpha+\\beta WEIGHT+\\delta_{1}COHO+\\gamma_{1}WEIGHT:COHO \\\\ &amp;=\\alpha+\\beta WEIGHT+\\delta_{1}0+\\gamma_{1}WEIGHT:0\\\\ &amp;=\\alpha+\\beta WEIGHT+0+0\\\\ &amp;=\\alpha+\\beta WEIGHT\\\\ \\end{split} \\] Similarly, the sub-model for Coho is found by plugging 1 for \\(COHO\\) in the ultimate full model and simplifying. \\[ \\begin{split} \\mu_{MIREX|WEIGHT,COHO} &amp;= \\alpha+\\beta WEIGHT+\\delta_{1}COHO+\\gamma_{1}WEIGHT:COHO \\\\ &amp;=\\alpha+\\beta WEIGHT+\\delta_{1}1+\\gamma_{1}1WEIGHT \\\\ &amp;=\\alpha+\\beta WEIGHT+\\delta_{1}+\\gamma_{1}WEIGHT \\\\ &amp;=\\alpha+\\delta_{1}+\\beta WEIGHT+\\gamma_{1}WEIGHT \\\\ &amp;=(\\alpha+\\delta_{1})+(\\beta+\\gamma_{1})WEIGHT \\\\ \\end{split} \\] Sub-models are found by appropriately substituting 0s and 1s for the indicator variable(s) in the IVR ultimate full model and simplifying. These sub-models can be appended to the tables from Module 20 to provide a succinct summary. Species COHO Sub-Model (\\(\\mu_{MIREX|WEIGHT}=\\)) Chinook (Reference) 0 \\(\\alpha+\\beta WEIGHT\\) Coho 1 \\((\\alpha+\\delta_{1})+(\\beta+\\gamma_{1})WEIGHT\\) Examination of the sub-models for each group shows that each sub-model is itself an SLR model. The sub-model for Chinook Salmon is an SLR with a slope of \\(\\beta\\) and an intercept of \\(\\alpha\\). In contrast, the sub-model for Coho Salmon is an SLR with a slope of \\(\\beta+\\gamma_{1}\\) and an intercept of \\(\\alpha+\\delta_{1}\\). Each sub-model is an SLR for one of the groups represented in the IVR ultimate full model. The process is similar when there are more than two groups, except that 0s and 1s must be substituted for multiple indicator variables. For example, the ultimate full model for the situation when three years (1977, 1982, and 1986) were considered is \\[ \\begin{split} \\mu_{MIREX|WEIGHT,\\cdots} = &amp; \\alpha+\\beta WEIGHT + \\delta_{1}YEAR1982 + \\delta_{2}YEAR1986 + \\\\ &amp; \\gamma_{1}WEIGHT:YEAR1982 + \\gamma_{2}WEIGHT:YEAR1986 \\\\ \\end{split} \\] To find the sub-model for 1982, for example, requires plugging 1 in for \\(YEAR1982\\) and 0 for \\(YEAR1986\\) and simplifying \\[ \\begin{split} \\mu_{MIREX|WEIGHT,\\cdots} &amp;= \\alpha+\\beta WEIGHT + \\delta_{1}1 + \\delta_{2}0 + \\gamma_{1}WEIGHT:1 + \\gamma_{2}WEIGHT:0 \\\\ &amp;= \\alpha+\\beta WEIGHT + \\delta_{1} + 0 + \\gamma_{1}WEIGHT + 0 \\\\ &amp;= (\\alpha+\\delta_{1}) + (\\beta+\\gamma_{1})WEIGHT \\end{split} \\] A similar process can be used to find the sub-models for 1977 and 1986.82 The sub-models are then summarized in the following table. Year YEAR1982 YEAR1986 Sub-Model (\\(\\mu_{MIREX|WEIGHT}=\\)) 1977 (Reference) 0 0 \\(\\alpha+\\beta WEIGHT\\) 1982 1 0 \\((\\alpha+\\delta_{1})+(\\beta+\\gamma_{1})WEIGHT\\) 1986 0 1 \\((\\alpha+\\delta_{2})+(\\beta+\\gamma_{2})WEIGHT\\) Once again, each sub-model is itself an SLR model. For example, the slopes are \\(\\beta\\), \\(\\beta+\\gamma_{1}\\), and \\(\\beta+\\gamma_{2}\\) for the years 1977, 1982, and 1986, respectively. The sub-model for the reference group is always \\(\\mu_{Y|X}=\\alpha+\\beta X\\). The slopes for the other groups always have a \\(\\gamma_{i}\\) added to \\(\\beta\\) and the intercepts always have a \\(\\delta_{i}\\) added to \\(\\alpha\\). 21.3 Interpreting Parameter Estimates Careful examination of the sub-models in the tables above help illustrate what the model parameters (i.e., \\(\\alpha\\), \\(\\beta\\), \\(\\delta_{i}\\), and \\(\\gamma_{i}\\)) mean. The sub-model for the reference groups is always \\(\\mu_{Y|X}=\\alpha+\\beta X\\); thus, \\(\\alpha\\) is the intercept and \\(\\beta\\) is the slope for the reference group. From above, it is also evident that the intercept for the \\(i\\)th group is \\(\\alpha+\\delta_{i}\\) and the slope for the \\(i\\)th group is \\(\\beta+\\gamma_{i}\\). However, what are \\(\\delta_{i}\\) and \\(\\gamma_{i}\\)? To answer this, consider the following algebra for the difference in intercepts between the \\(i\\)th group and the reference group. \\[ \\begin{split} i\\text{th Group&#39;s Intercept} - \\text{Reference Group&#39;s Intercept} &amp;= (\\alpha+\\delta_{i}) - \\alpha \\\\ &amp;= \\delta_{i} \\end{split} \\] Thus, \\(\\delta_{i}\\) is the additive difference between intercepts for the \\(i\\)th and reference groups. Similar algebra shows that \\(\\gamma_{i}\\) is the additive difference in slopes between the \\(i\\)th group and the reference group. \\[ \\begin{split} i\\text{th Group&#39;s Slope} - \\text{Reference Group&#39;s Slope} &amp;= (\\beta+\\gamma_{i}) - \\beta \\\\ &amp;= \\gamma_{i} \\end{split} \\] In summary, the parameters in the ultimate full model have the following interpretations (see Figure 21.1). \\(\\alpha\\): y-intercept term for the reference group. \\(\\beta\\): slope for the reference group. \\(\\delta_{i}\\): difference in y-intercepts between the \\(i\\)th group and the reference group. \\(\\gamma_{i}\\): difference in slopes between the \\(i\\)th group and the reference group. Figure 21.1: Representation of two sub-models fit with the ultimate full model in an IVR with the geometric meaning of each parameter. The red line is the sub-model for the reference group. Note that \\(\\alpha\\)=2, \\(\\beta\\)=0.4, \\(\\delta_{1}\\)=-1.6, and \\(\\gamma_{1}\\)=0.45 in this example. These interpretations show why the first group is called the reference group. The parameters in the reference sub-model represent the intercept and slope for that group. These parameters also appear in the other sub-models, but each has another parameter added to it to account for differences between the non-reference group and the reference group. In other words, every difference in slopes or intercepts is computed relative to the slope or intercept for the reference group. Thus, \\(\\delta_{i}\\) and \\(\\gamma){i}\\) are only meaningful relative to the reference group. Coefficients on indicator variables (i.e., the \\(\\delta_{i}\\)) always measure differences in intercepts between a non-reference group and the reference group. Coefficients on interaction variables (i.e., the \\(\\gamma_{i}\\)) always measure differences in slopes between a non-reference group and the reference group. The ultimate full model of an IVR can represent four situations between two groups depending on values of the \\(\\delta_{1}\\) and \\(\\gamma_{1}\\) parameters (Figure 21.2). Coincident Lines: A single regression line represents the relationship between the response variable and the covariate for both groups (i.e., \\(\\delta_{1}=0\\) and \\(\\gamma_{1}=0\\)). Parallel Lines: Separate parallel lines with different y-intercepts are needed for both groups (i.e., \\(\\delta_{1}\\neq0\\) and \\(\\gamma_{1}=0\\)). Same Intercept: Separate non-parallel lines with the same y-intercept are needed for both groups (i.e., \\(\\delta_{1}=0\\) and \\(\\gamma_{1}\\neq0\\)) Completely Separate Lines*: Two completely separate lines are needed for both groups (i.e., \\(\\delta_{1}\\neq0\\) and \\(\\gamma_{1}\\neq0\\)). Figure 21.2: Hypothetical depictions of four situations that can occur for the relationship between a response variable and a covariate for two groups. 21.4 Ultimate Full Model in R Fitting ultimate full model in R is straightforward because it is essentially the same as fitting a Two-Way ANOVA with lm() (see 12.1) and R automatically creates the indicator variables behind the scenes. The ultimate full model for an IVR is fit in lm() with a formula of the form response~covariate+factor+covariated:factor (in that order to match what we did above).83 ivr1 &lt;- lm(mirex~weight+species+weight:species,data=Mirex) Extracting Parameter Estimates The parameter estimates and their confidence intervals are extractd with coef() and confint(), which can be bound together with cbind() to create a succinct summary. cbind(Ests=coef(ivr1),confint(ivr1)) #R&gt; Ests 2.5 % 97.5 % #R&gt; (Intercept) 0.135451558 0.093132341 0.17777078 #R&gt; weight 0.009607284 0.003886599 0.01532797 #R&gt; speciescoho -0.050914887 -0.113215438 0.01138566 #R&gt; weight:speciescoho 0.012110273 -0.001079885 0.02530043 The parameter estimates are under the Ests column and are in rows that are generally labeled as the variables in the ultimate full model. Do note that R prepends the indicator variable with the name of the original factor variable. Thus, what we called COHO, R calls speciescoho. From this then, \\(\\hat{\\alpha}\\)=0.135, \\(\\hat{\\beta}\\)=0.010, \\(\\hat{\\delta}_{1}\\)=-0.051, and \\(\\hat{\\gamma}_{1}\\)=0.012. Thus, for example, the sample slope for Chinook Salmon (the reference groups) is 0.010 and the sample slope for Coho Salmon is 0.012 greater than the sample slope for Chinook Salmon. Furthermore, for example, one is 95% confident that \\(\\beta\\) is between 0.004 and 0.015 and \\(\\gamma_{1}\\) is between -0.001 and 0.025. Of course, inferential methods are needed to determine if these results suggest a real difference in parameters between populations. For example, a statistical test of whether \\(\\gamma_{1}=0\\) would be used to determine if the population slopes differed between Coho and Chinook salmon. These types of tests are introduced in Module 22. Fitted Line Plots A visual of the fitted IVR model is constructed the same as the visual for an SLR model except that the color of the points and the regression line for each group is mapped to the factor variable. The plotting character and colors should then be removed from geom_point(). For example, note the color=species in mapping=aes() and the simplicity of geom_point() in the code below. ggplot(data=Mirex,mapping=aes(x=weight,y=mirex,color=species)) + geom_point() + labs(x=&quot;Weight (kg)&quot;,y=&quot;Mirex Concentration (mg/kg)&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;,se=FALSE) From this plot, note that the intercept for Coho is less than the intercept for Chinook (as you would expect because \\(\\hat{\\delta}_{1}\\)=-0.051) and the slope for Coho is greater than (i.e., steeper) than that for Chinook (as you would expect because \\(\\hat{\\gamma}_{1}\\)=0.012) Predictions Predicted values for IVR models are constructed by submitting the lm() object and a data frame of observed values of the explanatory variables to predict(), as was described for SLR models (see Section 15.7). One must make sure, though, that the data frame contains an observed value for each explanatory variable found in the lm() object. For example, the predicted value, with a 95% prediction interval, for a 3 kg Coho Salmon is found with nd &lt;- data.frame(weight=3,species=&quot;coho&quot;) predict(ivr1,newdata=nd,interval=&quot;prediction&quot;) #R&gt; fit lwr upr #R&gt; 1 0.1496893 -0.03240232 0.331781 Similarly, the predicted values, with 95% prediction intervals, for 5 kg Chinook AND a 3 kg Coho Salmon are found with nd &lt;- data.frame(weight=c(5,3),species=c(&quot;chinook&quot;,&quot;coho&quot;)) predict(ivr1,newdata=nd,interval=&quot;prediction&quot;) #R&gt; fit lwr upr #R&gt; 1 0.1834880 0.001557795 0.3654182 #R&gt; 2 0.1496893 -0.032402319 0.3317810 The results may be easier to read if you bind together the new data.frame and the prediction results. nd &lt;- data.frame(weight=c(5,3),species=c(&quot;chinook&quot;,&quot;coho&quot;)) cbind(nd,predict(ivr1,newdata=nd,interval=&quot;prediction&quot;)) #R&gt; weight species fit lwr upr #R&gt; 1 5 chinook 0.1834880 0.001557795 0.3654182 #R&gt; 2 3 coho 0.1496893 -0.032402319 0.3317810 You should do this to make sure that you understand how to properly substitute in the 0s and 1s. Shorthand for fitting this model is response~covariate*factor. "],["IVRTesting.html", "Module 22 IVR Testing 22.1 F-ratio Test Statistic 22.2 Parallel Lines Test 22.3 Coincident Lines Test 22.4 Relationship Test 22.5 All Tests in R 22.6 More Groups (Different Slopes) 22.7 More Groups (Same Slopes)", " Module 22 IVR Testing Hypothesis testing in an Indicator Variable Regression (IVR) is the same as that for a One-Way ANOVA, Two-Way ANOVA, and Simple Linear Regression (SLR). However, it can feel different. Fortunately, this is where all of your hard work with respect to comparing models is going to pay off. Lets revisit the F-ratio test statistic (from Section 4.6) before discussing three specific hypotheses of an IVR. 22.1 F-ratio Test Statistic The F-ratio test statistic was \\(\\text{F}=\\frac{\\text{MS}_{\\text{Among}}}{\\text{MS}_{\\text{Within}}}\\) for a One-Way ANOVA, the same for a Two-Way ANOVA except that MSAmong was replaced with MSA, MSB, or MSA:B, and was \\(\\text{F}=\\frac{\\text{MS}_{\\text{Regression}}}{\\text{MS}_{\\text{Residual}}}\\) for SLR. While these F-ratios all have different symbols in them they are all \\[ \\text{F}=\\frac{\\text{Variance EXPLAINED by the full model}}{\\text{Variance UNEXPLAINED by the ultimate full model}}=\\frac{``\\text{Signal&#39;&#39;}}{``\\text{Noise&#39;&#39;}} \\] Note that the noise is always the residual MS from fitting the ultimate full model. In other words, the noise is the unexplained variance after all explanatory variables have been considered. The signal or variance explained by the full model (that is not explained by the simple model) is a bit tricky with an IVR because what exactly the simple and full models are depends on the hypotheses being tested. These hypotheses and models are discussed in the next three sections. However, the variability explained by the full model is simply the difference in lack-of-fit between the two models divided by the difference in number of parameters between the two models. This is the benefit-to-cost ratio from Section 4.6 and is generically \\[ ``\\text{Signal&#39;&#39;}=\\frac{\\text{RSS}_{\\text{Simple}}-\\text{RSS}_{\\text{Full}}}{\\text{df}_{\\text{Simple}}-\\text{df}_{\\text{Full}}} = \\frac{``\\text{Benefit (decrease in lack-of fit)&#39;&#39;}}{``\\text{Cost (increase in parameters)&#39;&#39;}} \\] This means that the generic F-ratio test statistic is \\[ \\text{F}=\\frac{``\\text{Signal&#39;&#39;}}{``\\text{Noise&#39;&#39;}}=\\frac{\\frac{\\text{RSS}_{\\text{Simple}}-\\text{RSS}_{\\text{Full}}}{\\text{df}_{\\text{Simple}}-\\text{df}_{\\text{Full}}}}{\\text{RMS}_{\\text{Ultimate Full}}} \\] This formula will be applied in the next three sections. 22.2 Parallel Lines Test Testing if groups have the same relationship between the response variable and the covariate is a common and important question. For example, one may ask if the relationship between mirex concentration and weight is the same for Coho and Chinook Salmon. Be clear, this is not asking if mirex concentration is the same for Coho and Chinook Salmon, rather it is asking if the relationship or rate of change of mirex concentration relative to weight is the same between the two species. Mirex concentrations may be higher or lower in Coho than Chinook, but here the question is if mirex changes at the same rate or not for the two species. Asking if the relationship is the same among groups is the same as asking if the slopes are the same among groups, which is the same as asking if the lines are parallel. Thus, the test for answering this question is is called a parallel lines test. Parallel Lines Test: An F test to determine if all groups in an IVR can be described by lines with the same slope. In words, the hypotheses for a parallel lines test are \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{The Coho and Chinook lines are parallel&#39;&#39;} \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{The Coho and Chinook lines are NOT parallel&#39;&#39;} \\\\ \\end{split} \\] More usefully these translate into the following models84 \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: \\mu_{MIREX|\\cdots} = \\alpha+\\beta WEIGHT+\\delta_{1}COHO \\\\ \\text{H}_{\\text{A}}&amp;: \\mu_{MIREX|\\cdots} = \\alpha+\\beta WEIGHT+\\delta_{1}COHO+\\gamma_{1}WEIGHT:COHO \\\\ \\end{split} \\] Take note that the HA includes the interaction term, whereas H0 does not. Recall from Section 21.3 that coefficients on the interaction terms correspond to differences in slopes. Without this parameter, the H0 corresponds to lines that are parallel, whereas the HA with this parameter corresponds to lines with different slopes (and, thus, lines that are not parallel; Figure 22.1). Figure 22.1: Hypothetical depictions of the models for the null and alternative hypotheses of the parallel lines test. A parallel lines test is conducted by comparing the ultimate full model to the model that contains only the covariate and indicator variables (i.e., no interaction variables with the quantitative variable are included). Parallel Lines Test from Two Models in R The ultimate full model provides the residual MS for the F-ratio and also serves as the full model for the parallel lines test. The ultimate full model was fit in Section @ref(ultimate-full-model-in r) as ivr1 &lt;- lm(mirex~weight+species+weight:species,data=Mirex) The simple model for the parallel lines test is the ultimate full model without the interaction variable(s). ivr2 &lt;- lm(mirex~weight+species,data=Mirex) The comparison of the simple and full models can be summarized by submitting the two models to anova() (simple model first). anova(ivr2,ivr1) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Model 1: mirex ~ weight + species #R&gt; Model 2: mirex ~ weight + species + weight:species #R&gt; Res.Df RSS Df Sum of Sq F Pr(&gt;F) #R&gt; 1 119 1.00708 #R&gt; 2 118 0.97964 1 0.027444 3.3057 0.07158 The first two columns of these results (Res.Df and RSS) are the residual df and RSS for each model (the simple model is listed first). As the full model here is also the ultimate full model, the residual MS for the denominator (bottom part) of the F-ratio is computed from the second row of these two columns. The next two columns (Df and Sum of Sq) are the differences between the residual df and SS of the two models; thus, these columns contain the four parts needed for the numerator (top part) of the F-Ratio. Thus, the F-ratio is computed with \\[ \\text{F}=\\frac{\\frac{\\text{RSS}_{\\text{Simple}}-\\text{RSS}_{\\text{Full}}}{\\text{df}_{\\text{Simple}}-\\text{df}_{\\text{Full}}}}{\\text{RMS}_{\\text{Ultimate Full}}} =\\frac{\\frac{1.00708-0.97964}{119-118}}{\\frac{0.97964}{118}} = \\frac{\\frac{0.027444}{1}}{0.00830} = \\frac{0.02744}{0.00830} = 3.30566 \\] This calculation is the same (within rounding) as the value under F in the anova() results. The corresponding p-value is under the Pr(&gt;F) column. This p-value is larger than our typical rejection level of 0.05. Thus, we conclude that H0 is NOT rejected, the simple model is adequate (as compared to the full model), the slopes appear to be equal, and the lines are parallel. With parallel lines, one concludes that the relationship between mirex concentration in the tissue and weight of the salmon is the same for Coho and Chinook. Two other hypothesis tests are considered in the next two sections. However, note that the parallel lines test is always considered first. The parallel lines test uses the interactions between the covariate and indicator variable(s). Thus, this is exactly the same as what we did with the Two-Way ANOVA, where the significance of the interaction effect was assessed first, before deciding whether main effects could be considered. The parallel lines test is ALWAYS conducted first as it involves the interaction variable(s). 22.3 Coincident Lines Test If the groups are found to be parallel (i.e., have equal slopes) then you should proceed to determine if the groups also have equal intercepts. If the lines are both parallel and have equal intercepts then they are the same line, or are coincident. Thus, this test is called the coincident lines test. Coincident Lines Test: An F test to determine if all groups in an IVR can be described by lines with the same intercept given that the lines have equal slopes. In words, the hypotheses for a coincident lines test are \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{Coho and Chinook lines are coincident&#39;&#39;} \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{Coho and Chinook lines are parallel but not coincident&#39;&#39;} \\\\ \\end{split} \\] More usefully these translate into the following models \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: \\mu_{MIREX|\\cdots} = \\alpha+\\beta WEIGHT \\\\ \\text{H}_{\\text{A}}&amp;: \\mu_{MIREX|\\cdots} = \\alpha+\\beta WEIGHT+\\delta_{1}COHO \\\\ \\end{split} \\] There are several important things to consider here. First, the HA here was the H0 in the parallel lines test. This illustrates that some models can be either a full or a simple model depending on the hypothesis being tested. Second, interaction variables are not present in either model because the coincident lines test is only considered for parallel lines (and, thus, the interaction term depicting the difference in slopes is not included). Third, the difference in the two models is the inclusion of the indicator variable and its \\(\\delta_{i}\\) coefficient. Recall from Section 21.3 that \\(\\delta_{i}\\) measures the differences in intercepts. Without this parameter (and the \\(\\gamma_{i}\\)), the H0 corresponds to two lines that are exactly the same, whereas the HA with this parameter corresponds to two line with different intercepts (but the same slope; Figure 22.2). Figure 22.2: Hypothetical depictions of the models for the null and alternative hypotheses of the coincident lines test. This needs to be very clear  the coincident lines test is relevant only if the lines have already been found to be parallel. Thus, you will only test for equal intercepts AFTER having determined that the lines are parallel. If the lines are not parallel then you will NOT conduct a coincident lines test. The reasoning for this can be thought of in at least two ways. First, differences in intercepts come from examining the indicator variable(s). The indicator variables stem from one original factor variable and, thus, can be thought of as a main effect. If the parallel lines test indicates non-parallel lines then a significant interaction term has been found to be an important contributor to the model. As was learned with a two-way ANOVA, if an interaction exists in the model then the main effect terms should not be interpreted. Second, if the lines are not parallel then the significance of the intercept term depends on the relative magnitude of the slopes and how far the observed data is from \\(X=0\\). For example, the intercepts in Figure 22.3-Left are statistically different. However, if the center of the observed data was on \\(X=0\\) as in Figure 22.3-Right then the intercepts would not be statistically different. In summary, the test for equal intercepts is not useful if the slopes differ between groups. Figure 22.3: Representation of two sub-model fits with non-parallel lines. The left plot illustrates a situation where X=0 is at the left margin of the observed data. The right plot illustrates a situation where X=0 is at the center of the observed data. Overall, the two plots illustrate how the difference in intercepts depends on where X=0 is relative to the two fitted lines. A coincident lines test is only appropriate if the lines are parallel. On the other hand, if the lines are parallel then the coincident lines test is very important. With parallel lines the difference in intercepts is a measure of the vertical difference between the lines for every value of the covariate. Thus, the difference in intercepts is a measure of the difference in the response variable between the groups at the same value of the covariate. The coincident lines test tests whether this constant difference is significantly different than 0 or not. In other words, do the values of \\(Y\\) for each group differ for every value of \\(X\\). Figure 22.4: Representation of two sub-model fits that are parallel but with different intercepts (not coincident). The difference in intercepts is shown at X=0, but since the lines are parallel this is the same difference at every value of X, four others of which are shown. The coincident lines test (assuming parallel lines) tests whether the mean of the response variable differs between groups for all values of covariate. Coincident Lines Test from Two Models in R The full model for the coincident lines test was the simple module for the parallel lines test and was fit previously and saved into ivr2. The simple model for the coincident lines test is the simple linear regression model (i.e., no difference in slopes or intercepts); i.e., ivr3 &lt;- lm(mirex~weight,data=Mirex) These models are compared with anova(); however, the ultimate full model must be included as well so that the proper residual MS (i.e., from the ultimate full model) will be used. anova(ivr3,ivr2,ivr1) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Model 1: mirex ~ weight #R&gt; Model 2: mirex ~ weight + species #R&gt; Model 3: mirex ~ weight + species + weight:species #R&gt; Res.Df RSS Df Sum of Sq F Pr(&gt;F) #R&gt; 1 120 1.00758 #R&gt; 2 119 1.00708 1 0.0004983 0.0600 0.80690 #R&gt; 3 118 0.97964 1 0.0274436 3.3057 0.07158 These results are organized similar to before, but we can focus on the first two rows as RMSUltimate Full was calculated previously when completing the parallel lines test. Thus, the F-ratio is calculated with \\[ \\text{F}=\\frac{\\frac{\\text{RSS}_{\\text{Simple}}-\\text{RSS}_{\\text{Full}}}{\\text{df}_{\\text{Simple}}-\\text{df}_{\\text{Full}}}}{\\text{RMS}_{\\text{Ultimate Full}}} =\\frac{\\frac{1.00758-1.00708}{120-119}}{0.00830} = \\frac{\\frac{0.00050}{1}}{0.00830} = \\frac{0.00050}{0.00830} = 0.06002 \\] Again, this is the F test-statistic (within rounding) shown in the anova() results. This p-value (p=0.8087) is larger than our typical rejection level of 0.05. Thus, we conclude that the H0 is NOT rejected, the simple model is adequate (as compared to the full model), the intercepts appear to be equal, and the lines are coincident. With coincident lines, one can conclude, in addition to the relationship not differing between groups (i.e., parallel lines), that the mean mirex concentration in the tissue does NOT differ between Coho and Chinook Salmon of the same weight, no matter what that weight is. 22.4 Relationship Test If the lines are found to be parallel then you should also determine if the lines represent a relationship or not. This reduces to determining if the slope of the reference group is different from zero (a flat line) or not (not a flat line). As the lines are parallel, the decision for the reference group will extend to the other groups. Relationship Test:: An F test to determine if a relationship exists between the response variable and the covariate in an IVR given that the lines are parallel. In words, the hypotheses for the relationship test are \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{There is no relationship between mirex and weight&#39;&#39;} \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{There is a relationship between mirex and weight (for the coincident lines)&#39;&#39;} \\\\ \\end{split} \\] More usefully these translate into the following models \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: \\mu_{MIREX|\\cdots} = \\alpha+ \\\\ \\text{H}_{\\text{A}}&amp;: \\mu_{MIREX|\\cdots} = \\alpha+\\beta WEIGHT \\\\ \\end{split} \\] At first glance, this appears to be the same models used in an SLR (Figure 22.5). However, in an IVR, the denominator in the F-ratio is from the ultimate full model. Therefore, the measure of noise in an IVR considers more variables than are considered in an SLR. Thus, the conclusion could differ between a relationship test in an IVR and the similar looking SLR. Figure 22.5: Hypothetical depictions of the models for the null and alternative hypotheses of the relationships test. Notice in these models that the full model in the relationship test is the same as the simple model in the coincident lines test. Thus, the relationship test follows a coincident lines test. However, the relationship test can be conducted and interpreted regardless of the outcome of the coincident lines test. The relationship test should, however, only be conducted if the lines are found to be parallel. The relationship test is concerned solely with the covariate and, thus, can be thought of as a main effect, which should only be considered in the absence of an interaction effect (i.e., parallel lines). Additionally, if the lines are not parallel that means the relationship between the response and covariate differs among groups and there is not one relationship to describe, as the relationship test attempts to do. A relationship test is only appropriate if the lines are parallel. Relationship Test from Two Models in R The full model for the relationship test was the simple module for the coincident lines test and was fit previously and saved into ivr3. The simple model for the relationship test is the so-called ultimate simple model85 and is fit with ivr4 &lt;- lm(mirex~1,data=Mirex) These models are compared with anova(), again with the ultimate full model included so that the proper residual MS will be used. anova(ivr4,ivr3,ivr1) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Model 1: mirex ~ 1 #R&gt; Model 2: mirex ~ weight #R&gt; Model 3: mirex ~ weight + species + weight:species #R&gt; Res.Df RSS Df Sum of Sq F Pr(&gt;F) #R&gt; 1 121 1.23056 #R&gt; 2 120 1.00758 1 0.222980 26.8586 9.155e-07 #R&gt; 3 118 0.97964 2 0.027942 1.6828 0.1903 These results are organized similar to before; thus, the F-ratio is calculated with \\[ \\text{F}=\\frac{\\frac{\\text{RSS}_{\\text{Simple}}-\\text{RSS}_{\\text{Full}}}{\\text{df}_{\\text{Simple}}-\\text{df}_{\\text{Full}}}}{\\text{RMS}_{\\text{Ultimate Full}}} =\\frac{\\frac{1.23056-1.00758}{121-120}}{0.00830} = \\frac{\\frac{0.22298}{1}}{0.00830} = \\frac{0.22298}{0.00830} = 26.8586 \\] Again, this is the F test-statistic (within rounding) shown in the anova() results. This p-value (p&lt;0.00005) is less than our typical rejection level of 0.05. Thus, one would conclude that H0 is rejected, the simple model is not adequate and the full model is needed, the slope for the coincident lines is not 0, and there is a relationship between mirex in the tissue and the weight of the salmon. 22.5 All Tests in R The parallel lines, coincident lines, and relationship tests of an IVR appears to require fitting four models as shown in the previous three sections. However, these tests can be calculated more succinctly by submitting ONLY the ultimate full model (i.e., ivr1) to anova(). anova(ivr1) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: mirex #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; weight 1 0.22298 0.222980 26.8586 9.155e-07 #R&gt; species 1 0.00050 0.000498 0.0600 0.80690 #R&gt; weight:species 1 0.02744 0.027444 3.3057 0.07158 #R&gt; Residuals 118 0.97964 0.008302 A close comparison of this one set of results to the results in the three previous sections shows that The weight:species (i.e., the interaction variable) row corresponds to the parallel lines test. The species (i.e., the factor variable) row corresponds to the coincident lines test. The weight (i.e., the covariate) row corresponds to the relationship test. Thus, as with a Two-Way ANOVA, this table should be read from the bottom to the top. If the interaction variable is significant (i.e., non-parallel lines) then the two main effects should not be considered. However, if no interaction effect is present (i.e., parallel lines) then the other two effects can be considered. So, in reality, fit the ultimate full model and submitting it to anova() to construct this one table from which all three tests (if appropriate) can be assessed. The parallel lines, coincident lines, and relationship test results are in the rows from anova() labeled with the interaction variable, the original factor variable, and the covariate, respectively. 22.6 More Groups (Different Slopes) The previous example with two groups (Coho and Chinook Salmon) can be extended to more than two groups. In this example, we will continue to examine the relationship between mirex concentration in the tissue and weight of the salmon, but among three years (with both species combined). Before continuing, take note that the year variable in the Mirex data frame is considered to be numeric. str(Mirex) #R&gt; &#39;data.frame&#39;: 122 obs. of 4 variables: #R&gt; $ year : int 1977 1977 1977 1977 1977 1977 1977 1977 1977 1977 ... #R&gt; $ weight : num 0.41 0.45 1.04 1.09 1.24 1.25 1.3 1.34 1.37 1.49 ... #R&gt; $ mirex : num 0.16 0.19 0.19 0.1 0.13 0.19 0.28 0.16 0.17 0.2 ... #R&gt; $ species: Factor w/ 2 levels &quot;chinook&quot;,&quot;coho&quot;: 1 1 1 2 1 1 1 2 2 2 ... The IVR requires that the grouping variable be considered as a factor. If it is not then lm() will not form indicator variables and will instead perform what is called a multiple linear regression. Thus, year must be converted to a factor. Mirex$year &lt;- factor(Mirex$year) str(Mirex) #R&gt; &#39;data.frame&#39;: 122 obs. of 4 variables: #R&gt; $ year : Factor w/ 6 levels &quot;1977&quot;,&quot;1982&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... #R&gt; $ weight : num 0.41 0.45 1.04 1.09 1.24 1.25 1.3 1.34 1.37 1.49 ... #R&gt; $ mirex : num 0.16 0.19 0.19 0.1 0.13 0.19 0.28 0.16 0.17 0.2 ... #R&gt; $ species: Factor w/ 2 levels &quot;chinook&quot;,&quot;coho&quot;: 1 1 1 2 1 1 1 2 2 2 ... Also, for the sake of having a simple example, only the last three years in the data will be used. MirexLast3 &lt;- filter(Mirex,year %in% c(1992,1996,1999)) The ultimate full model is then fit and the ANOVA table is extracted with86 ivrY1 &lt;- lm(mirex~weight+year+weight:year,data=MirexLast3) anova(ivrY1) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: mirex #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; weight 1 0.115886 0.115886 30.6459 1.615e-06 #R&gt; year 2 0.205825 0.102912 27.2149 2.028e-08 #R&gt; weight:year 2 0.042176 0.021088 5.5767 0.00694 #R&gt; Residuals 44 0.166385 0.003781 In this case, the p-value for the interaction (p=0.0069) is less than 0.05, which suggests that the interaction term is important to the model (it explains a significant portion of variability) and that at least one of the groups has a different slope than the other groups (Figure 22.6). Note the at least in the previous sentence. This is the same issue you ran into with One- and Two-Way ANOVAs  rejecting H0 simply means that there is some difference among the groups, not that they are all different. Multiple comparisons for slopes will be introduced in the next module. Figure 22.6: Fitted regression lines for mirex in tissue by salmon weight for 1992, 1996, and 1999. Note that the IVR indicated that these lines are not parallel. If there are more than two groups, then a significant parallel lines test means that at least one group has a different slope. A multiple comparison method (Module 23) is needed to identify which groups have different slopes. 22.7 More Groups (Same Slopes) For the purposes of having another simple example, suppose that only the first three years from the previous example were considered. MirexFirst3 &lt;- filter(Mirex,year %in% c(1977,1982,1986)) ivrY2 &lt;- lm(mirex~weight+year+weight:year,data=MirexFirst3) anova(ivrY2) #R&gt; Analysis of Variance Table #R&gt; #R&gt; Response: mirex #R&gt; Df Sum Sq Mean Sq F value Pr(&gt;F) #R&gt; weight 1 0.32844 0.32844 89.9408 6.064e-14 #R&gt; year 2 0.05719 0.02859 7.8306 0.0008881 #R&gt; weight:year 2 0.00089 0.00044 0.1218 0.8855178 #R&gt; Residuals 66 0.24101 0.00365 With these results it is seen that the lines for the three years are parallel (p=0.8855); thus, the relationship between mirex concentration in the tissue and weight of the salmon does not differ across the three years (Figure 22.7). There does appear to be a significant relationship between mirex concentration in the tissue and weight of the salmon (p&lt;0.00005). Finally, it appears the mirex concentration in the salmon at the same weight of salmon differ between at least one pair of years (p=0.0009). Again, in the next module, multiple comparison methods for distinguishing which pairs of means have different intercepts will be introduced. Figure 22.7: Fitted regression lines for mirex in tissue by salmon weight for only 1977, 1982, and 1986. Note that the IVR indicated that these lines are parallel, there is a signficant relationship, and at least one of the lines has a different intercept. If there are more than two groups, then a significant coincident lines test means that at least one group has a different intercept. A multiple comparison method (Module 23) is needed to identify which groups have different intercepts. The variables in this model were defined in Modules 20-21. Because you cannot get any simpler than fitting a model without any variables. Assumptions should be checked and will be introduced in the next module. "],["IVRAnalysis.html", "Module 23 IVR Analysis 23.1 Assumptions &amp; Transformations 23.2 Multiple Comparisons for Slopes 23.3 Multiple Comparisons for Intercepts", " Module 23 IVR Analysis Modules 20-22 build a conceptual and analytical foundation for an indicator variable regresion (IVR). Three more analytical topics need to be addressed before a full IVR can be completed in Module 24. Those topics  assumptions and transformations, multiple comparisons for slopes, and multiple comparisons for intercepts  are introduced in this module. 23.1 Assumptions &amp; Transformations The assumptions for an IVR are the same as those for an SLR  independence, linearity, homoscedasticity, normality, and no outliers (see Module 17). Methods for assessing the validity of these assumptions are also essentially the same as those used for an SLR. In other words, residual plots will be used to examine linearity and assess homoscedasticity, an Anderson-Darling test and a histogram of the residuals will be used to assess the normality of residuals, and a residual plot and an outlier test will be used to diagnose outliers and influential points. The assumptions of an IVR are the same as the assumptions for an SLR. Thus, methods for assessing the assumptions are the same as those methods used for an SLR An important point to note, though, is that the IVR assumptions are assessed on the ultimate full model. If the assumptions are not met on the ultimate full model, then transformations for the response and the covariate87 should be considered such that a transformed version of the ultimate full model meets the assumptions.88 Once an ultimate full model is found where all of the assumptions are met, then it is assumed that all assumptions will be met for any subset of the ultimate full model that has non-significant explanatory variables removed. IVR assumptions are assessed for the ultimate full model. Assumptions do not need to be assessed for simpler models that only have variables from the ultimate full model removed. 23.2 Multiple Comparisons for Slopes In Section 22.6 of the last module, the IVR indicated that some slopes between mirex concentration in the tissue and salmon weight differed among 1992, 1996, and 1999 (Figure 23.1). An examination of Figure 23.1 suggests that the slopes for 1992, 1996, and 1999 are all likely not the same. However, an objective method is needed to determine which pairs of slopes actually differ. Parallel lines tests for IVRs taking two years at a time could be used but this is inefficient and would increase the experiment-wise error rate (recall from Section 6.1). Figure 23.1: Fitted regression lines for mirex in tissue by salmon weight for 1992, 1996, and 1999. Note that the IVR indicated that these lines are not parallel. The emtrends() function from the emmeans package89 can be used to test for differences among all pairs of slopes using a Tukey-like correction. This function requires the ultimate full model as its first argument (ivrY1 here as fit in Section 22.2), a specs= argument with pairwise~ followed by the name of the factor variable in the ultimate full model, and var= followed by the name of the covariate in the ultimate full model.90 The results of this function should be saved to an object. smc &lt;- emtrends(ivrY1,pairwise~year,var=&quot;weight&quot;) That saved object is then the first argument to summary(), which also includes infer=TRUE. The results are in sections labeled as $emmeans and $contrasts. ( smcsum &lt;- summary(smc,infer=TRUE) ) #R&gt; $emtrends #R&gt; year weight.trend SE df lower.CL upper.CL t.ratio p.value #R&gt; 1992 0.02653 0.00483 44 0.01679 0.0363 5.489 &lt;.0001 #R&gt; 1996 0.01225 0.00306 44 0.00609 0.0184 4.004 0.0002 #R&gt; 1999 0.00386 0.00499 44 -0.00620 0.0139 0.773 0.4434 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; #R&gt; $contrasts #R&gt; contrast estimate SE df lower.CL upper.CL t.ratio p.value #R&gt; 1992 - 1996 0.01428 0.00572 44 0.000403 0.0282 2.496 0.0425 #R&gt; 1992 - 1999 0.02267 0.00695 44 0.005815 0.0395 3.262 0.0059 #R&gt; 1996 - 1999 0.00839 0.00586 44 -0.005813 0.0226 1.433 0.3331 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 3 estimates #R&gt; P value adjustment: tukey method for comparing a family of 3 estimates The $contrasts section contains the Tukey-corrected tests for each pair of slopes. The important columns in these results are estimate: the difference in group sample slopes, lower.CL and upper.CL: 95% confidence interval for the difference in slopes, and p.value: p-value for testing that the difference in group population slopes is 0 or not. For example, the sample slope for 1992 is 0.01428 greater than the sample slope for 1996, one is 95% confident that the population slope for 1992 is between 0.000403 and 0.0282 greater than the population slope for 1996, and that the population slopes differ between these two years (p=0.0425). In contrast, the sample slope for 1996 is 0.00839 greater than the sample slope for 1999, one is 95% confident that the population slope for 1996 is between 0.005813 less than and 0.0226 greater than the population slope for 1999, and the population slopes do NOT differ between these two years (p=0.3331). An examination of all of the $contrast results suggests that the slope from 1992 differed significantly from the slopes of 1996 (p=0.0425) and 1999 (p=0.0059), but the slopes for 1996 and 1999 did not differ (p=0.3331). The difference in group slopes with 95% confidence intervals and p-values are shown in the $contrasts section of the results. The $emtrends section of the output contains information about the individual slopes, specifically. XXX.trend: the sample slope (note that XXX will be replaced with the name of the covariate in the model), lower.CL and upper.CL: 95% confidence interval for the slope, and p.value: p-value for the test whether the slope is 0 or not (i.e., is there a relationship or not). For example, the sample slope for 1992 is 0.02653, one is 95% confidence interval that the population slope for 1992 is between 0.01679 and 0.0363, and there was a significant relationship between mirex in the tissue and salmon weight in 1992 (p&lt;0.00005). An examination of all of the results in $emtrends shows that the only slope that was not significantly different from 0 was for 1999. Thus, there was a significant relationship between mirex concentration in the tissue and salmon weight for 1992 and 1996, but not for 1999. The slopes with 95% confidence intervals and p-values for testing if the slope is 0 or not are shown in the $emtrends section of the results. 23.3 Multiple Comparisons for Intercepts In Section 22.7 of the last module, the IVR indicated that the first three years (1977, 1982, and 1986) had the same slopes and that at least some of those years had different intercepts (Figure 23.2).91 An examination of Figure 23.2 suggests that the intercept for 1977 may be greater than the intercepts for 1982 and 1986, which likely do not differ significantly. Again, an objective method is needed to determine which pairs of intercepts significantly differ. Figure 23.2: Fitted regression lines for mirex in tissue by salmon weight for only 1977, 1982, and 1986. Note that the IVR indicated that these lines are parallel, there is a signficant relationship, and at least one of the lines has a different intercept. The emmeans() function from the emmeans package can be used to determine which pairs of intercepts differ (using a Tukeys correction). However, before using this function a new model with the insignificant interaction term removed should be fit. ivrY2a &lt;- lm(mirex~weight+year,data=MirexFirst3) The use of emmeans here is exactly the same as it was in Section 6.3. Specifically, the model without the interaction term is the first argument and pairwise~ is followed by the name of the factor variable in the model. The results are then submitted to summary() with infer=TRUE and the results are given in two sections labeled $emmeans and $contrasts. imc &lt;- emmeans(ivrY2a,pairwise~year) ( imcsum &lt;- summary(imc,infer=TRUE) ) #R&gt; $emmeans #R&gt; year emmean SE df lower.CL upper.CL t.ratio p.value #R&gt; 1977 0.238 0.0123 68 0.213 0.262 19.392 &lt;.0001 #R&gt; 1982 0.184 0.0122 68 0.159 0.208 15.091 &lt;.0001 #R&gt; 1986 0.172 0.0123 68 0.148 0.197 14.015 &lt;.0001 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; #R&gt; $contrasts #R&gt; contrast estimate SE df lower.CL upper.CL t.ratio p.value #R&gt; 1977 - 1982 0.0542 0.0173 68 0.0128 0.0956 3.139 0.0070 #R&gt; 1977 - 1986 0.0655 0.0175 68 0.0235 0.1075 3.736 0.0011 #R&gt; 1982 - 1986 0.0113 0.0173 68 -0.0302 0.0529 0.653 0.7913 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 3 estimates #R&gt; P value adjustment: tukey method for comparing a family of 3 estimates The important parts of the $contrasts portion are estimate: the difference in sample intercepts, lower.CL and upper.CL: 95% confidence intervals for the difference in intercepts, and p.value: p-value for whether the differences in intercepts is 0. For example, the sample intercept for 1977 is 0.0542 mg/kg greater than the intercept for 1982, the population intercept for 1977 is between 0.0128 and 0.0956 greater than the population intercept for 1982, and the intercepts for these two years are significantly different (p=0.0070). Because these two years are parallel, the sample mean mirex concentration for 1977 is 0.0542 mg/kg greater than the sample mean mirex concentration for 1982 for all salmon weights. The difference in group intercepts with 95% confidence intervals and p-values are shown in the $contrasts section of the results. The results in $emmeans portion contains information about the mean of the response variable at the mean of the covariate. In other words, this information is about the intercepts for the centered covariate (see Section 15.3). Specifically, emmean: sample mean of the response variable at the sample mean of the covariate, lower.CL and upper.CL: 95% confidence interval for the population mean of the response variable at the sample mean of the covariate, and p.value: a p-value for testing if the population mean of the response variable at the sample mean of the covariate is equal to 0 or not. For example, the sample mean mirex concentration in 1977 for a salmon with the sample mean weight of all salmon is 0.238, one is 95% confident that the population mean mirex concentration in 1977 for a salmon with the sample mean weight of all salmon is between 0.213 and 0.262 mg/kg, and the population mean mirex concentration at the sample mean salmon weight in 1977 is not equal to 0 (p&lt;0.00005). A visual of the sample means under emmeans is shown in Figure 23.3. Figure 23.3: Fitted regression lines for mirex in tissue by salmon weight for only 1977, 1982, and 1986. The mean mirex concentration at the mean salmon weight is shown for each year to demonstrate the results of the emmeans() function. The mean value of the response at the mean value of the covariate, along with 95% confidence intervals and p-values, are shown in the $emmeans section of the results. The emmeans() function defaults to showing the mean value of the response for the mean value of the covariate because the intercept is often an extreme extrapolation as discussed in Section 15.3. It is possible to compute the mean values of the response at other values of the covariate by using cov.reduce= in emmeans(). For example, the code below computes the mean values of the response at the minimum value of the covariate (and shown in Figure 23.4).92 Because the lines are parallel this does not change anything in the $contrasts portion of the output. However, the $emmeans portion is changed because the mean values of the response is computed at, in this example, the minimum value rather than the mean value of the covariate. Using the default calculation at the mean of covariate is probably most appropriate for most situations in general and all situations in this course. imc2 &lt;- emmeans(ivrY2a,pairwise~year,cov.reduce=min) ( imc2sum &lt;- summary(imc2,infer=TRUE) ) #R&gt; $emmeans #R&gt; year emmean SE df lower.CL upper.CL t.ratio p.value #R&gt; 1977 0.1460 0.0143 68 0.1174 0.175 10.181 &lt;.0001 #R&gt; 1982 0.0918 0.0151 68 0.0617 0.122 6.097 &lt;.0001 #R&gt; 1986 0.0805 0.0163 68 0.0479 0.113 4.928 &lt;.0001 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; #R&gt; $contrasts #R&gt; contrast estimate SE df lower.CL upper.CL t.ratio p.value #R&gt; 1977 - 1982 0.0542 0.0173 68 0.0128 0.0956 3.139 0.0070 #R&gt; 1977 - 1986 0.0655 0.0175 68 0.0235 0.1075 3.736 0.0011 #R&gt; 1982 - 1986 0.0113 0.0173 68 -0.0302 0.0529 0.653 0.7913 #R&gt; #R&gt; Confidence level used: 0.95 #R&gt; Conf-level adjustment: tukey method for comparing a family of 3 estimates #R&gt; P value adjustment: tukey method for comparing a family of 3 estimates Figure 23.4: Fitted regression lines for mirex in tissue by salmon weight for only 1977, 1982, and 1986. The mean mirex concentration at the MINIMUM salmon weight is shown for each year to demonstrate the results of the emmeans() function. If the covariate is transformed then any interaction terms with the covariate should be recreated using the transformed covariate. The methods and rules for transforming these variables in an IVR are the same as those used for an SLR (see 18). The emmeans package was introduced in Section 6.3. Except for var= this is the same as for emmeans() described in Section 6.3 Recall from last module that those three years were chosen simply to serve as an example. Choosing these years has nothing to do with the analysis from the previous section. You can get the mean values of the response at a covariate of 0 (i.e., the actual y-intercepts) by using cov.reduce=function(x) 0. "],["IVRSummary.html", "Module 24 IVR Summary 24.1 Suggested Workflow 24.2 Fish Energy Density (No Transformation) 24.3 Shrub Allometry (Transformation)", " Module 24 IVR Summary Specific parts of a full Indicator Variable Regression (IVR) analysis were described in Modules 20-23. In this module, a workflow for a full analysis is offered and that workflow is demonstrated with several examples. 24.1 Suggested Workflow The following is a process for fitting an IVR. Consider this process as you learn to fit IVR models, but dont consider this to be a concrete process for all models. Perform a thorough EDA. Pay close attention to the form, strength, and outliers on the scatterplot of the response and explanatory variables separated by each level of the factor (You can add facet_wrap(vars(FACTOR))) (where FACTOR is replaced with the factor variable in the IVR) to ggplot() code that constructs a scatterplot to separate by groups.) Show the sample size by group using xtabs(). Assess the independence assumption. If this assumption is not met then other analysis methods must be used. Fit the untransformed ultimate full model with lm(). Check the other four assumptions for the untransformed model with assumptionCheck(). Check the linearity of the relationship with the residual plot. Check homoscedasticity with the residual plot. Check normality of residuals with an Anderson-Darling test and histogram of residuals. Check outliers and influential points with the outlier test and residual plot. If an assumption or assumptions are violated, then attempt to find a transformation where the assumptions are met. Use trial-and-error with assumptionCheck(), theory (e.g., power or exponential functions), or experience to identify possible transformations for the response variable and, possibly, for the explanatory variable. Attempt transformations with the response variable first. Generally only ever transform the explanatory variable with logarithms. If only an outlier or influential observation exists (i.e., linear, homoscedastic, and normal residuals) and no transformation corrects the problem, then consider removing that observation from the data set. Fit the ultimate full model with the transformed variable(s) or reduced data set. Construct an ANOVA table for the ultimate full model with anova(). If a significant interaction exists then do NOT interpret the main effects!! If a significant interaction does NOT exist then interpret the main effects (i.e., interpret the coincident lines and relationship test p-values). As appropriate, perform multiple comparisons to identify specific differences. If a significant interact exists (i.e., non-parallel lines) then use emtrend() and summary() to identify specific slopes that differ. If a significant interaction does not exist (i.e., parallel lines) but the lines are not coincident (i.e., different slopes)  Fit a new model without the insignificant interaction term. Use emmeans() and summary() to identify specific mean values of the response at the mean value of the covariate that differ. Create a summary graphic of the fitted lines using the ggplot(). Include the 95% confidence band and the observed data as long as the plot is not overly cluttered. If it is, just show the fitted lines. Make predictions with predict(), if desired. Write a succinct conclusion of your findings. Make sure you address  whether the relationship between the response variable and the covariate differs among groups. whether the mean value of the response variable at the mean value of the covariate differs among groups (if appropriate to address this). whether there is a significant relationship between the response variable and the covariate (may need to do separately for each group). 24.2 Fish Energy Density (No Transformation) Some ecologists study the transfer of energy through the ecosystem. Energy is passed up trophic levels through predation. How much energy is transferred depends on a number of things, including the energy density of the prey. Hartman and Brandt (1995) provided a meta-analysis of energy densities for a wide variety of prey fishes. In one part of that study they more closely examined the energy densities of Bay Anchovy (Anchoa mitchilli), Bluefish (Pomatomus saltatrix), Striped Bass (Morone saxatilis), and Weakfish (Cynoscion regalis) collected from Chesapeake Bay , Maryland. Hartman and Brandt (1995) were primarily interested in describing differences in energy density between the four species. However, it is commonly known that the amount of energy in a fish is partly dependent on the percent dry weight of the fish.93 Thus, their objectives were to (i) describe the relationship between energy density and dry weight and determine if that relationship differed among the four species and (ii) determine if the mean energy density at a constant dry weight differed among the four species. The first hypothesis to be tested (i.e, parallel lines test) is \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{the relationship between energy density and dry weight does not differ by species&#39;&#39;} \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{the relationship between energy density and dry weight does differ by species&#39;&#39;} \\\\ \\end{split} \\] If this H0 is not rejected (i.e., the lines are parallel) then the following two sets of hypotheses will be tested (i.e., coincident lines and relationship tests), \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{the mean energy density at the mean dry weight does not differ among species&#39;&#39;} \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{the mean energy density at the mean dry weight does differ among species&#39;&#39;} \\\\ \\end{split} \\] and \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{there is not a relationship between energy density and dry weight&#39;&#39;} \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{there is a relationship between energy density and dry weight&#39;&#39;} \\\\ \\end{split} \\] The sample size is quite unbalanced, with essentially twice as many Bay Anchovy as any other species (Table 24.1). The sample size for Bluefish, Striped Bass, and Weakfish is quite small. Table 24.1: Sample size for each species. species Freq bayanchovy 26 bluefish 13 stripedbass 14 weakfish 11 There is very little information to fully assess independence. However, as long as any individual fish does not affect the dry weight or the energy density of any other fish, than the independence assumption is likely met. It is hard to imagine how any one fish could affect any other single fish for these two metrics, so I suspect that independence is adequately met. The residual plot (Figure 24.1-Right) does not exhibit any curvature or funneling pattern; thus the linearity and homoscedasticity assumptions are met. The residuals appear approximately normal (Anderson-Darling p=0.4549; Figure 24.1-Left) and no outliers are present (outlier test p&gt;1). No transformation is needed as all assumptions appear to be met. Figure 24.1: Histogram of residuals (left) and residual plot (right) for the IVR analysis of energy density by percent dry weight and species. The relationship between energy density and percent dry weight differed among some of the species (p&lt;0.00005; Table 24.2). It appears that the slope for Bay Anchovy is less than the slope for all other species (p0.0002; Table 24.3). The slopes do not differ among the other three species (p0.1444; Table 24.3). Table 24.2: ANOVA table for the IVR analysis of energy density by percent dry weight and species. Df Sum Sq Mean Sq F value Pr(&gt;F) dw 1 170693154 170693154 1859.0 0e+00 species 3 10592036 3530679 38.5 0e+00 dw:species 3 4105617 1368539 14.9 3e-07 Residuals 56 5142008 91822 Table 24.3: Tukeys multiple comparisons for all pairs of slopes for the IVR analysis of energy density by percent dry weight and species. contrast estimate lower.CL upper.CL p.value bayanchovy - bluefish -208.3 -291.2 -125.5 0.0000 bayanchovy - stripedbass -157.6 -241.3 -73.9 0.0000 bayanchovy - weakfish -149.6 -237.4 -61.8 0.0002 bluefish - stripedbass 50.7 -15.9 117.3 0.1948 bluefish - weakfish 58.7 -12.9 130.4 0.1444 stripedbass - weakfish 8.0 -64.6 80.6 0.9912 As only Bay Anchovy had a different slope, I removed this species so that I could determine how the mean energy density at the mean percent dry weight differed among the the other three species. Assuming parallel lines for these three species (from the analysis above), it appears that the intercepts differed among some of the species (p=0.0005; Table 24.4). Tukeys multiple comparisons indicate that the intercept for Bluefish is less than the intercept for both Striped Bass and Weakfish (p0.0178; Table 24.5). The intercepts for Striped Bass and Weakfish did not differ (p=0.7088; Table 24.5). Table 24.4: ANOVA table for the IVR analysis of energy density by percent dry weight and species with Bay Anchovy excluded and assuming parallel lines (from the previous analysis). Df Sum Sq Mean Sq F value Pr(&gt;F) dw 1 104962559 104962559 782.4 0.00000 species 2 2583571 1291785 9.6 0.00049 Residuals 34 4561501 134162 Table 24.5: Tukeys multiple comparisons for all pairs of mean energy density at the mean percent dry weight by species. contrast estimate lower.CL upper.CL p.value bluefish - stripedbass -631.4 -988.4 -274.4 0.0004 bluefish - weakfish -506.5 -935.9 -77.1 0.0178 stripedbass - weakfish 124.9 -260.3 510.2 0.7088 Through this analysis it appears that Bay Anchovy has a less steep relationship between energy density and percent dry weight than the other species (Figure 24.2). So, energy density does not increase as quickly with increasing dry weight for Bay Anchovy as it does for the other species. Among the other species, it appears that Bluefish has a lower mean energy density at all percent dry weights than Striped Bass and Weakfish. Striped Bass and Weakfish appear to have the same mean energy density at all percent dry weights. Thus, for fish of the same percent dry weight, Striped Bass and Weakfish have a higher mean energy density than Bluefish. Figure 24.2: Fitted lines for the regression of energy density on percent dry weight separated by species of fish. R Code and Results nrg &lt;- read.csv(&quot;http://derekogle.com/Book207/data/FishEnergyDensity.csv&quot;) xtabs(~species,data=nrg) ivr1.nrg &lt;- lm(ed~dw+species+dw:species,data=nrg) assumptionCheck(ivr1.nrg) anova(ivr1.nrg) mc1.nrg &lt;- emtrends(ivr1.nrg,specs=pairwise~species,var=&quot;dw&quot;) ( mc1sum.nrg &lt;- summary(mc1.nrg,infer=TRUE) ) anova(ivr2.nrg) mc2.nrg &lt;- emmeans(ivr2.nrg,specs=pairwise~species) ( mc2sum.nrg &lt;- summary(mc2.nrg,infer=TRUE) ) ggplot(data=nrg,mapping=aes(x=dw,y=ed,color=species)) + geom_point() + labs(x=&quot;Percent Dry Weight&quot;,y=&quot;Energy Density (J/g)&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;,se=FALSE) 24.3 Shrub Allometry (Transformation) Allometric models are useful for assessing above-ground biomass (AGB) and net primary productivity (ANPP) of forests and shrubs. These models are widely used for forest inventory and management because they offer a non-destructive, relatively accurate, and labor-efficient method for estimating these difficult to measure metrics. The AGB and ANPP of plants are important components of the global carbon cycle. Above-ground biomass can be used to quantify carbon stores in plants and ANPP can help to understand potential future carbon storage. Thus, the prediction of AGB and ANPP of plants will help to evaluate terrestrial carbon sequestration, which is important for mitigation of global climate change. Allometric models to be used for these purposes are developed for individual tree and shrub species, oftentimes for different habitats. She et al. (2015) examined allometric relationships for the xeric shrub Artemisia ordosica, a species endemic to the Mu Us Desert in China. In one part of their analysis they used crown area (CA; m2) and habitat type to explain variability in AGB (kg) of individual Artemisia shrubs. Three habitats were considered  semi-fixed dunes (SF), fixed dunes (FD), and fixed dunes with soil crusts (FC). All individual Artemisia plants were sampled from three plots that were 2-4 km separated. In their model fitting they assumed that the relationship between AGB and CA followed a power function, as is typical for many allometric relationships. The first hypothesis to be tested (i.e, parallel lines test) is \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{the relationship between AGB an CA does not differ by habitat&#39;&#39;} \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{the relationship between AGB an CA does differ by habitat&#39;&#39;} \\\\ \\end{split} \\] If this H0 is not rejected (i.e., the lines are parallel) then the following two sets of hypotheses will be tested (i.e., coincident lines and relationship tests), \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{the mean AGB at the mean CA does not differ among habitats&#39;&#39;} \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{the mean AGB at the mean CA does differ among habitats&#39;&#39;} \\\\ \\end{split} \\] and \\[ \\begin{split} \\text{H}_{\\text{0}}&amp;: ``\\text{there is not a relationship between ABG and CA&#39;&#39;} \\\\ \\text{H}_{\\text{A}}&amp;: ``\\text{there is a relationship between AGB and CA&#39;&#39;} \\\\ \\end{split} \\] The sample size is unbalanced, with essentially 50% more Artemisia sampled in semi-fixed (SF) dunes than the other two habitats (Table 24.6). The sample sizes are not large but are likely adequate in all habitats. Table 24.6: Sample size of individual plants by habitat. Habitat Freq FC 22 FD 23 SF 31 Independence of individual plants is questionable both within- and among- groups. Though the three plots were spatially separated, it appears that multiple plants were sampled in each plot. Thus, there could be an effect of one plant on another plant in the same plot. That being said, it is hard to imagine that one plant could affect the relationship between crown area and above-ground biomass of another plant in the same plot. Thus, I will tentatively continue assuming independence. Allometric relationships often follow a power function, thus the assumptions are likely not met on the original untransformed scale. Indeed, the residual plot (Figure 24.3-Right) shows a clear curvature and heteroscedasticity. A power function relationship suggests that both the response and covariate should be log-transformed. With both variables log-transformed the residual plot (Figure 24.4-Right) exhibits no curvature or funnel-shape, which indicates that the linearity and homoscedasticity assumptions are met on this scale. The residuals are approximately normal (Anderson-Darling p=0.6638; Figure 24.4-Left) and no outliers are present (outlier test p=0.2764). The analysis will continue on the log-log scale as all assumptions appear to be met on this scale. Figure 24.3: Histogram of residuals (Left) and residual plot (Right) for the IVR of above-ground biomass on crown area for three dune habitats. Figure 24.4: Histogram of residuals (Left) and residual plot (Right) for the IVR of log-transformed above-ground biomass on log-transformed crown area for three dune habitats. The relationship between log above-ground biomass and log crown area does not differ among Artemisia sampled from the different habitats (p=0.1115; Table 24.7). There does appear to be a significant relationship between log above-ground biomass and log crown area for Artemisia (p&lt;0.00005; Table 24.7). Finally, it appears that the mean log above-ground biomass at all log crown areas differs between some of the habitats (p&lt;0.00005; Table 24.7). Table 24.7: ANOVA table for the IVR of log-transformed above-ground biomass on log-transformed crown area for three dune habitats. Df Sum Sq Mean Sq F value Pr(&gt;F) logCA 1 120.72 120.72 826.34 0.0000 Habitat 2 13.65 6.83 46.73 0.0000 logCA:Habitat 2 0.66 0.33 2.26 0.1115 Residuals 70 10.23 0.15 The back-transformed mean above-ground biomass at the back-transformed mean crown area differs among all habitats (p0.0001; Table 24.8). The back-transformed mean above-ground biomass at the back-transformed mean crown area is between 5.5 and 16.4% greater in the soil crust (FC) than fixed dune (FD) habitats, between 15.8 and 27.7% greater in the soil crust (FC) than semi-fixed dune (FD) habitats, and between 4.3 and 15.4% greater in the fixed dune (FD) than semi-fixed dune habitats (Table 24.8). Table 24.8: Tukeys multiple comparisons for the RATIO mean above-ground biomass at the mean log crown areas for each pair of habitats contrast ratio lower.CL upper.CL p.value FC / FD 1.108 1.055 1.164 0.000013 FC / SF 1.216 1.158 1.277 0.000000 FD / SF 1.097 1.043 1.154 0.000103 A positive relationship was found between log above-ground biomass and log crown area that did not differ between habitat types (Figure 24.5). The mean above-ground biomass for plants with the same crown area was greater for Artemisia in the surface crust habitats than in the fixed dunes habitats which were greater than in the semi-fixed dunes habitats (Figure 24.6). In other words, it appears that the above-ground biomass is greater in the surface crust habitats than fixed-dunes than semi-fixed dunes for plants with the same crown area. Figure 24.5: Fitted lines for the regression of log above-ground biomass on log crown area separated by habitats. Note that these lines are statistically parallel, have statistically different intercepts, and exhibit a statistically positive relationship. Figure 24.6: Back-transformed mean above-ground biomass of Artemisia (and 95% confidence interval) at the back-transformed mean crown area for each habitat (FC=surface crust, FC=fixed-dune, and SF=semi-fixed dune). R Code and Results shrub &lt;- read.csv(&quot;http://derekogle.com/Book207/data/Artemisia.csv&quot;) xtabs(~Habitat,data=shrub) ivr1.shrub &lt;- lm(AGB~CA+Habitat+CA:Habitat,data=shrub) assumptionCheck(ivr1.shrub) assumptionCheck(ivr1.shrub,lambday=0,lambdax=0) shrub$logAGB &lt;- log(shrub$AGB) shrub$logCA &lt;- log(shrub$CA) ivr1t.shrub &lt;- lm(logAGB~logCA+Habitat+logCA:Habitat,data=shrub) anova(ivr1t.shrub) ivr2t.shrub &lt;- lm(logAGB~logCA+Habitat,data=shrub) mc2t.shrub &lt;- emmeans(ivr2t.shrub,specs=pairwise~Habitat,trans=&quot;log&quot;) ( mc2tsum.shrub &lt;- summary(mc2t.shrub,infer=TRUE,type=&quot;response&quot;) ) ggplot(data=shrub,mapping=aes(x=logCA,y=logAGB,color=Habitat)) + geom_point() + labs(x=&quot;log Crown Area&quot;,y=&quot;log Above-Ground Biomass&quot;) + theme_NCStats() + geom_smooth(method=&quot;lm&quot;,se=FALSE) ggplot(data=mc2tsum.shrub$emmeans, mapping=aes(x=Habitat,y=response,ymin=lower.CL,ymax=upper.CL)) + geom_errorbar(size=2,width=0) + geom_point(pch=21,fill=&quot;white&quot;) + labs(y=&quot;Mean Above-Ground Biomass (kg)&quot;,x=&quot;Habitat&quot;) + theme_NCStats() Percent dry weight is the dry weight divided by the wet weight of the fish times 100. "],["LogRegFoundations.html", "Module 25 Foundational Principles 25.1 Need for a Transformation 25.2 Odds 25.3 Log Odds and the Logit Transformation 25.4 Back-Transformation Introduction", " Module 25 Foundational Principles Logistic regression models are used when a researcher is investigating the relationship between a binary categorical response variable and a quantitative explanatory variable.94 Typically, logistic regression is used to predict the probability of membership in one level of the response variable given a particular value of the explanatory variable. Binary95 logistic regression would be used in each of the following situations: Predict the probability that a bat is of a certain subspecies based on the size of the canine tooth. Predict the probability that a household will accept an offer to install state-subsidized solar panels given the households income. Predict the probability that a beetle will die when exposed to a certain concentration of a chemical pollutant. Predict the probability of mortality for a patient given a certain score on a medical exam. Binary Logistic Regression: A linear model where a binary response variable (i.e., two possible outcomes) is examined with a quantitative explanatory variable. 25.1 Need for a Transformation The response variable in a logistic regression is categorical. How do you make a plot with categorical data on the y-axis? How do you construct a regression model when the y-axis variable is categorical? In this course, we will only consider binary response variables; i.e., there are only two categories. The two categories will generically be labeled as success and failure, where success and failure is defined by the researcher. For example, a researcher may be interested in the probability of a heart attack and, thus, would define a success as having a heart attack. The binary response variable in a logistic regression will be treated as an indicator variable, where a success is coded as a 1 and a failure is coded as a 0.96 Treating this variable as quantitative will allow us to use techniques from previous modules. However, fitting a linear regression to this response variable plotted against the quantitative explanatory variable immediately exposes two problems (Figure 25.1). First, the linearity (and homoscedasticity) assumptions of linear regression are not met. Second, predicted probabilities from this model can be less than 0 and greater than 1, even within the observed domain of the explanatory variable. Clearly, a linear regression cannot be used to model this type of data. Figure 25.1: Plot of the binary response variable, as an indicator variable, versus a quantitative explanatory variable with the best-fit linear regression line super-imposed. Note that darker points have more individuals over-plotted at that coordinate. Recall that all previous linear models dealt with the mean of the response variable. Logistic regression is no different in that it attempts to model the mean of \\(Y\\) at each value of \\(X\\). As a simple example consider the five observations of success and failure below at one particular value of \\(X\\), wher \\(Z\\) is the indicator variable that corresponds to \\(Y\\). X Y Z 20 Success 1 20 Failure 0 20 Failure 0 20 Success 1 20 Success 1 In this example the mean of \\(Z\\) is \\(\\frac{1+0+0+1+1}{5}\\)=\\(\\frac{3}{5}\\)=0.6. Lets also calculate the proportion of successes in \\(Y\\) as \\(\\frac{\\text{Number of Successes}}{\\text{Total Number of Observations}}\\)=\\(\\frac{3}{5}\\)=0.6. Thus, because \\(0\\)s and \\(1\\)s are used in the indicator variable, the mean of the indicator variable is the same as the probability of success for the corresponding factor variable. In logistic regression we will model the probability of success, while realizing that this is the same as modeling the mean of \\(Y\\) at given values of \\(X\\). In many situations it is hard to visualize the probability of success versus the explanatory variable because few values of \\(X\\) have multiple observations of \\(Y\\). Thus, a visual is constructed by computing the probability of success (\\(p_{i}\\)) within \\(i\\) windows of \\(X\\) values. For example, Figure 25.2 shows the probability of success calculated within windows of \\(X\\) that were 2.5 units wide. Figure 25.2: Plot of the binary response variable, as an indicator variable, versus a quantitative explanatory variable with the vertical lines representing windows in which the probability of success (red circles) were calculated. These are the same data as in the previous figure. From Figure 25.2, it is obvious that a model for the probability of success is non-linear. As is usual, when the assumptions of a model are not met then we need to consider a transformation. The transformation required for a logistic regression is a bit involved and will be introduced in the next two sections. 25.2 Odds The first step in transforming probabilities of success is to calculate the odds of success. The odds of success is the probability of success divided by the probability of failure; i.e., \\[ odds_{i} = \\frac{p_{i}}{1-p_{i}} \\] Thinking in terms of odds takes some practice. For example, an odds of 5 means that the probability of success is five times more likely than the probability of failure. In contrast, an odds of 0.2 means that the probability of failure is five times (i.e., \\(\\frac{1}{0.2}\\)=5) more likely than the probability of success. Odds: The ratio of the probability of success to the probability of failure. Odds have two important characteristics. First, an odds of 1 means that the probability of success is the same as the probability of failure. Second, odds are bounded below by 0 (i.e., negative odds are impossible) but are not bounded above (i.e., odds can increase to positive infinity; Figure 25.3). Figure 25.3: Plot of the odds of success for the same probabilities of success in the previous figure. From 25.3 it is clear that plotting odds versus the explanatory variable is still not linear. Thus, the odds still need to be transformed before a linear model can be fit. 25.3 Log Odds and the Logit Transformation While the plot of the odds of success versus the quantitative explanatory variable is not linear, it does have the characteristic shape of an exponential function (Figure 25.3). Exponential functions are linearized by log transforming the response variable (see Section 18.1.2). The log of the odds is called the logit transformation of the probability of success. Thus, \\[ logit(p_{i}) = log(odds_{i}) = log\\left(\\frac{p_{i}}{1-p_{i}}\\right) \\] The plot of \\(logit(p_{i})\\) versus the explanatory variable is generally linear (Figure 25.4). Figure 25.4: Plot of the log odds of success (i.e., the logit transformed probability of success) for the same odds of success in the previous figure. Therefore, the logit transformation is a common transformation for linearizing the relationship between the probability of success and the quantitative explanatory variable. The logit transformation is the basis for a logistic regression, such that the logistic regression model is \\[ log\\left(\\frac{p_{i}}{1-p_{i}}\\right) = \\alpha + \\beta x_{i} \\] where \\(\\alpha\\) is the intercept parameter and \\(\\beta\\) is the slope parameter. This model is discussed in more detail in the next module. 25.4 Back-Transformation Introduction While it will be discussed more in the next modules, it is evident from the logistic regression model above that that model is used to predict log odds. However, log odds are largely uninterpretable and should be back-transformed to the odds by exponentiating (i.e., \\(\\text{odds}=e^{\\text{log(odds)}}\\). An equation for predicting odds can also be obtained with algebra, starting with the logistic regression equation. \\[ \\begin{split} log\\left(\\frac{p}{1-p}\\right) &amp;= \\alpha+\\beta X \\\\ \\frac{p}{1-p} &amp;= e^{\\alpha+\\beta X} \\\\ p &amp;= (1-p)e^{\\alpha+\\beta X} \\\\ p &amp;= e^{\\alpha+\\beta X}-pe^{\\alpha+\\beta X} \\\\ p + pe^{\\alpha+\\beta X} &amp;= e^{\\alpha+\\beta X} \\\\ p\\left(1+e^{\\alpha+\\beta X}\\right) &amp;= e^{\\alpha+\\beta X} \\\\ p &amp;= \\frac{e^{\\alpha+\\beta X}}{1+e^{\\alpha+\\beta X}} = \\frac{e^{log(odds)}}{1+e^{log(odds)}} = \\frac{\\text{odds}}{1+\\text{odds}} \\end{split} \\] Thus, a probability can be calculated from the odds with \\(p=\\frac{\\text{odds}}{1+\\text{odds}}\\). These relationships will be expanded upon in the next module. Strictly, a logistic regression can be used with a categorical explanatory variable or multiple explanatory variables of mixed types. We will focus on the simplest situation where there is only one quantitative explanatory variable. This qualifying statement is needed as not all logistic regressions have a response variable with only two levels. See Section 20.1 for more discussion about indicator variables. "],["LogRegModels.html", "Module 26 Models and Predictions 26.1 Slope &amp; Back-Transformed Slope 26.2 Back-Transformed Slope 26.3 Predictions 26.4 Reverse Predictions 26.5 Variability Estimates 26.6 Another Example", " Module 26 Models and Predictions The logistic regression model, using the logit transformation, was briefly introduced at the end of Module 25 as \\[ log\\left(\\frac{p_{i}}{1-p_{i}}\\right) = \\alpha + \\beta x_{i} \\] where \\(\\alpha\\) is the intercept parameter and \\(\\beta\\) is the slope parameter. As noted there, this represents a linear model of log odds plotted against values of the explanatory variable. In this module, interpretations of the slope, back-transformed slope, predictions, and reverse predictions are described. Example Data Data that was collected by a student a few years ago will be used throughout this and the next module. The student putted a golf ball 10 times from every 1 foot between 1 and 25 feet from the hole. For each putt she recorded whether she made the putt or not. She wanted to model the probability of making the putt as a function of distance to the hole. 26.1 Slope &amp; Back-Transformed Slope The slope for any linear regression represents the average additive change in the response variable for a unit change in the explanatory variable. In logistic regression, this corresponds to the average additive change in the log odds of a success for a unit change in the explanatory variable. The estimated slope for the golf putt data is -0.354 with a 95% confidence interval from -0.491 to -0.272 (Table 26.1). Thus, as the length of the putt increases by one foot, the log odds that the student made the putt decreases by -0.354 (95% CI: 0.272, 0.491; Figure 26.1). Table 26.1: Parameter estimates from the logistic regression with the golf putting data. Ests 2.5 % 97.5 % (Intercept) 2.797 2.069 3.946 distance -0.354 -0.491 -0.272 Figure 26.1: Log odds of making a putt versus the distance of the putt with best-fit line superimposed. The right panel is zoomed in on distances of 5 to 15 so that the slope could be better seen. Look closely at Figure 26.1-Right to understand the meaning of the slope. When the distance of the putt increased from 6 to 7 feet the predicted log odds decreased from 0.675 to 0.321, a difference of 0.321-0.675= -0.354, which is the same as the estimated slope (Table 26.1). The same difference in log odds is observed when the distance of the putt increased from 10 to 11 feet (i.e., -1.094- -0.740= -0.354) and will be the same for every other increase of 1 foot for the distance of the putt. The slope for a logistic regression is the additive change in the log odds for a unit change in the explanatory variable. 26.2 Back-Transformed Slope Log odds are nearly impossible to interpret. The change in log odds are even hard to interpret. Fortunately, a useful interpretation emerges when the slope is back-transformed by exponentiation. Mathematically, the slope of the logistic regression looks like this: \\[ \\beta = \\text{log}(\\text{ODDS}(Y|X+1)) - \\text{log}(\\text{ODDS}(Y|X)) \\] where \\(ODDS(Y|X)\\) generically represents the odds of \\(Y\\) being a success at a given value of \\(X\\). However, back-transforming the slope (i.e., exponentiating the slope) looks like \\[ \\begin{split} e^{\\beta} &amp;= \\text{log}(\\text{ODDS}(Y|X+1)) - \\text{log}(\\text{ODDS}(Y|X)) \\\\ &amp;= \\text{log}\\left(\\frac{\\text{ODDS}(Y|X+1)}{\\text{ODDS}(Y|X)}\\right) \\\\ &amp;= \\frac{\\text{ODDS}(Y|X+1)}{\\text{ODDS}(Y|X)} \\\\ \\end{split} \\] Thus, the exponentiated slope is the multiplicative change in the odds of a success for a unit change in \\(X\\). The exponentiated slope is called an odds ratio because it is a ratio of odds at two values of \\(X\\) (that differ by one unit). For example, \\(\\hat{\\beta}\\)=0.2 means that the log odds of a success increases by 0.2, on average, for a one unit increase in \\(X\\). The corresponding exponentiated slope, \\(e^{0.2}\\)=1.22, indicates that the odds of a success are 1.22 times greater for a one unit increase in \\(X\\). The exponentiated slope does not indicate what the odds are, only that the odds are 1.22 times greater with an increase of one unit in the explanatory variable. The exponentiated estimated slope for the golf putt data is 0.702 with a 95% confidence interval from 0.612 to 0.761 (Table 26.2). Thus, as the length of the putt increases by one foot, the odds that the student made the putt is 0.702 (95% CI: 0.612, 0.761) times lower (Figure 26.2). In other words, as the length of the putt increases by one foot, the odds that the student made the putt decreases by 29.8% (95% CI: 23.9, 38.8). Table 26.2: Exponentiated parameter estimates from the logistic regression with the golf putting data. Note that the intercepts values are not useful. Ests 2.5 % 97.5 % (Intercept) 16.392 7.915 51.722 distance 0.702 0.612 0.761 Figure 26.2: Odds of making a putt versus the distance of the putt with best-fit line superimposed. The right panel is zoomed in on distances of 5 to 15 so that the exponentiated slope could be better seen. Again, look closely at Figure 26.2-Right to understand the meaning of the exponentiated slope. When the distance of the putt increased from 6 to 7 feet the predicted odds declined from 1.964 to 1.379, a difference of 1.379-1.964= -0.585 but a ratio of \\(\\frac{1.379}{1.964}\\)=0.702. When the distance of the putt was increased from 10 to 11 feet the difference in odds was 0.335-0.477= -0.142 but the ratio was \\(\\frac{0.335}{0.477}\\), which was again 0.702. Thus, the difference in odds changes depending on the values of the explanatory variable but the ratio of odds stays constant at the value of the exponentiated slope (Table 26.2). The exponentiated slope for a logistic regression is the multiplicative change in the odds for a unit change in the explanatory variable. 26.3 Predictions The fitted logistic regression model can be used to make predictions. However, you must be very careful what is being predicted (i.e., the log odds) and how to back-transform (exponentiation gives the odds, not the probability). Plugging a value of \\(X\\) into the fitted logistic regression equation will predict a value for the log odds. For example, the predicted log odds for making a 6 foot putt is 2.797-0.354Ã—6 = 0.675 (values of  and  from Table 26.1 and log odds prediction shown in Figure 26.1). Of course, predicting the log odds is not that useful. However, exponentiating this value results in the odds. Thus, the odds of making a 6 foot putt is e0.675=1.964 (Figure 26.2). Thus, the probability of making the 6 foot putt is nearly twice as likely as not making the 6 foot putt. Finally, one most often wants to predict the probability of success. As shown in Module 25, a probability can be computed from the odds with \\(p = \\frac{\\text{odds}}{\\text{1+odds}}\\). Thus, for example, the probability of making the 6 foot putt is \\(\\frac{1.964}{1+1.964}\\)=0.663 (Figure 26.3). Therefore, the students makes a 6 foot put about 66% of the time on average (so, about 2 out of every 3). Figure 26.3: Probability of making a putt versus the distance of the putt with best-fit line superimposed and the prediction of the probability of making a 6 foot is shown. 26.4 Reverse Predictions In logistic regression it is fairly common to ask a specific version of the generic question What is the value of \\(X\\) for a given probability? For example, one may be interested to determine the length of the putt where there is a 50% probability of making the putt. In other words, what is the distance when the probability of making the putt is no longer greater than the probability of not making the putt. Of course, one can consider other probabilities as well. Solving the logistic regression equation for \\(X\\) provides an equation to answer these types of questions. The algebra to solve for \\(X\\) is shown below, beginning with the logistic regression equation. \\[ \\begin{split} log\\left(\\frac{p}{1-p}\\right) &amp;= \\alpha+\\beta X \\\\ log\\left(\\frac{p}{1-p}\\right)-\\alpha &amp;= \\beta X \\\\ \\beta X &amp;= log\\left(\\frac{p}{1-p}\\right)-\\alpha \\\\ X &amp;= \\frac{log\\left(\\frac{p}{1-p}\\right)-\\alpha}{\\beta} \\\\ \\end{split} \\] For example, the distance for which the probability of making the putt is 0.1 is \\[ \\frac{log\\left(\\frac{0.1}{1-0.1}\\right)-2.797}{-0.354} = 14.12. \\] where values of  and  are from Table 26.1. This prediction is shown in Figure 26.4. Figure 26.4: Probability of making a putt versus the distance of the putt with best-fit line superimposed and the prediction of the distances where the probabililty of making the putt is 0.10 and 0.50. Because \\(log(\\left(\\frac{0.5}{1-0.5}\\right)\\)=\\(log(1)\\)=0, this equation reduces to \\(X=\\frac{-\\alpha}{\\beta}\\) for a probability of 0.5. Thus, the distance for which the probability of making the putt is 0.5 is 7.91 ft (Figure 26.4). 26.5 Variability Estimates Standard errors or confidence intervals for the parameters of the logistic regression model can be computed with normal distribution theory. However, this theory does not hold for all logistic regression models. In addition, methods for computing confidence intervals for predicted probabilities or for predicted values of \\(X\\) for a particular probability are not well formed. Bootstrapping is one method for producing confidence intervals for these parameters. Bootstrap confidence intervals are computer intensive, but provide an interval that does not depend on the shape of the underlying sampling distribution. Bootstrapping confidence intervals generally follows these steps: Generate a bootstrap sample, which is a random sample of individuals from the original sample;97 Fit the model to the bootstrap sample; Compute the statistics of interest (i.e., the slope, intercept, predicted probability, predicted value of \\(X\\)); Repeat steps 1-3 500-10000 times;98 Order the results from smallest to largest; and Approximate 95% confidence interval with the values of the statistics that have 2.5% and 97.5% of the statistics smaller (i.e., find the middle 95% of the bootstrapped statistics).99 A histogram of slopes estimated from 999 bootstrap samples is shown in Figure 26.5. It is apparent from this example that the sampling distribution of the slopes is not normal and, thus, a confidence interval generated from normal theory would not be appropriate. The 95% bootstrap confidence interval shown in Figure 26.5 matches that in Table 26.1. Figure 26.5: Histogram of logistic regression slopes from the golf putt example estimated from 999 bootstrap samples. The two values denoted mark the values with 2.5% and 97.5% of the slopes smaller and thus represents a 95% bootstrap confidence interval for the slope. Bootstrapping is particularly useful for derived statistics like predicting the \\(X\\) for a given probability. A histogram of predicted distances where the probability of making the putt is 0.50 estimated from 999 bootstrap samples is shown in Figure 26.6. Thus, one is 95% confident that the distance of the putt where the probability of making the putt is 0.50 is between 6.86 and 8.95 feet. Figure 26.6: Histogram of the predicted distance where the probability making the putt is 0.50 estimated from 999 bootstrap samples. The two values denoted mark the values with 2.5% and 97.5% of the distances smaller and thus represents a 95% bootstrap confidence interval for the distance. Actual construction of the bootstrap confidence intervals is illustrated in the next module. The bootstrap method will be used to constructed confidence intervals for parameters in a logistic regression as typical normal theory is not always reliable with logistic regressions. 26.6 Another Example As another example data about the presence or absence of a common shrub (Berberis repens) in the Bryce Canyon National Park Utah will be used. Here the researchers recorded whether the shrub was present or not in many 10mÃ—10m plots throughout the park. They also recorded the elevation (among other things) of the plot. They wanted to model the effect of elevation on the presence of the shrub. The estimated slope for the shrub data indicates that as the elevation increases by one meter, the log odds that the shrub is present increases by 0.0090 (95% CI: 0.0063, 0.0146; Table 26.3). The interpretation of the slope is made difficult by the fact that a 1 m change is a very small movement along the x-axis in this case where the elevations range from near 2000 to near 2800. However, if a 1 unit change in \\(X\\) results in an additive change in \\(Y\\) of the slope, then, for example, a 100 unit change in \\(X\\) results in an additive change in \\(Y\\) of 100 slopes. Thus, for example, if the elevation increases by 100 m then the log odds of the presence of the shrub will increase by 100Ã—0.0090=0.898 (Figure 26.7). Table 26.3: Parameter estimates from the logistic regression with the shrub presence data. Ests 2.5 % 97.5 % (Intercept) -21.6044 -34.7819 -15.3525 elev 0.0090 0.0063 0.0146 Figure 26.7: Log odds of shrub presence versus elevation with best-fit line superimposed. The right panel is zoomed in on elevations of 2250 to 2600 m so that the slope could be better seen. If a 1 unit change in \\(X\\) is very small relative to the range of \\(X\\) then multiplying the slope by an amount \\(b\\) will describe the additive change in the log odds for a \\(b\\) unit change in the explanatory variable. The exponentiated estimated slope for the shrub data would have the same issue with scale described above for the estimated slope. The same remedy may be used but, as usual, you must be very careful with the interpretation. Exponentiating 100 times the slope suggests that as the elevation increases by 100 m, the odds that the shrub is present increases 2.455 (95% CI: 1.882, 4.289) times (Figure 26.8). Figure 26.8: Odds of shrub presence versus elevation with best-fit line superimposed. The right panel is zoomed in on elevations of 2250 to 2600 m so that the exponentiated slope could be better seen. The exponentiated \\(b\\)Ã—slope for a logistic regression is the multiplicative change in the odds for a \\(b\\) unit change in the explanatory variable. The predicted log odds for the presence of the shrub at an elevation of 2350 m is -21.6040.0090Ã—2350 = -0.499 (values of  and  from Table 26.3 and log odds prediction shown in Figure 26.7). The odds of the shrubs presence at an elevation of 2350 m is e-0.499=0.607 (Figure 26.8). Thus, the probability of the shrub being present at 2350 m is 60.7 of the probability that it is not present. Alternatively, the probability that the shrub is not present at 2350 m is 1.647 times the probability that it is present at that elevation (i.e., \\(\\frac{1}{0.607}\\)). The probability that the shrub is present at 2350 m is 0.378 (=\\(\\frac{0.607}{1+0.607}\\); Figure 26.9). Therefore, a little more than 1 out of every 3 plots at 2350 m will have the shrub. Figure 26.9: Probability of the shrubs presence versus elevation with best-fit line superimposed and the prediction of the probability at 2350 m. Finally, the elevation for which the probability of the shrubs presence is 0.75 is \\[ \\frac{log\\left(\\frac{0.95}{1-0.95}\\right)--21.604}{0.0090} = 2733.4. \\] where values of  and  are from Table 26.3. Similarly, the elevation where there is an equal probability of the shrub being present or not is 2405.6 (=\\(\\frac{-(-21.604)}{0.0090}\\)). These predictions are shown in Figure 26.10. Figure 26.10: Probability of the shrubs presence versus elevation with best-fit line superimposed and the prediction of elevations where the probabililty of the shrubs presence is 0.50 and 0.75. Thus, the individuals must be selected with replacement so that each bootstrap sample is different and different from the original sample. The number of bootstrap samples depends on a number of things, including the purpose of the study and how involved the calculations are. In this course, 500-1000 bootstrap samples will be adequate. This step tends to produce slightly biased results. There are a number of possible corrections for this bias. However, we will use this method in this course to keep the method simple so that we can stay focused on the concept. "],["LogRegAnalysis.html", "Module 27 Analysis 27.1 Data Preparation 27.2 Fitting the Model 27.3 Relationship Test 27.4 Parameter Estimates 27.5 Predictions 27.6 Plotting Best-Fit Line", " Module 27 Analysis Modules 25 and 26 described the basics of fitting a logistic regression and understanding the meanings of the parameter estimates, predicted probabilities, and predicted values of the explanatory variable for a given probability. This module will demonstrate how to perform those analyses using R. 27.1 Data Preparation Bliss (1935), in a classic study, examined the mortality response of beetles to various concentrations of gaseous carbon disulphide (mg/liter). The concentration and whether or not the beetle survived the exposure to that concentration was recorded for each beetle in Bliss.csv (data, meta). These data are loaded and briefly examined below. bliss &lt;- read.csv(&quot;https://raw.githubusercontent.com/droglenc/NCData/master/Bliss.csv&quot;) str(bliss) #R&gt; &#39;data.frame&#39;: 481 obs. of 2 variables: #R&gt; $ outcome: chr &quot;dead&quot; &quot;dead&quot; &quot;dead&quot; &quot;dead&quot; ... #R&gt; $ conc : num 49.1 49.1 49.1 49.1 49.1 49.1 49.1 49.1 49.1 49.1 ... In this case, we want to model the probability of mortality (i.e., the beetle died) as a function of the concentration of gaseous carbon disulphide. With this objective, a success is a dead beetle. Thus, dead should be coded as 1 and not dead (i.e., alive) as a 0. You will recognize this as an indicator variable from Module 20. In contrast to when we used indicator variables for factors, we need to explicitly create the indicator variable here when it is used as a response variable. An indicator variable can be created with ifelse(), which takes a condition as its first argument, what should be returned if the condition is yes as the second argument, and what should be returned if the condition is no as the third argument. The code below creates a new outcome01 variable in the bliss data frame that will be 1 if outcome is dead and 0 if outcome is not dead.100 bliss$outcome01 &lt;- ifelse(bliss$outcome==&quot;dead&quot;,1,0) You should examine the new variable to make sure that it represents what you intended. head(bliss,n=8) #R&gt; outcome conc outcome01 #R&gt; 1 dead 49.1 1 #R&gt; 2 dead 49.1 1 #R&gt; 3 dead 49.1 1 #R&gt; 4 dead 49.1 1 #R&gt; 5 dead 49.1 1 #R&gt; 6 dead 49.1 1 #R&gt; 7 alive 49.1 0 #R&gt; 8 alive 49.1 0 The binary response variable must be explicitly converted to an indicator variable with ifelse() for constructing a logistic regression and plotting the results in R. 27.2 Fitting the Model The logistic regression model is fit with glm(), which is the generalized linear model function in R. The first argument to glm() is a formula of the form var01~qvar where var01 is the indicator response variable created above and qvar is the quantitative explanatory variable, the data frame that contains these variables is in data=, and family=binomial. The family=binomial argument is critical because that is what tells glm() that the response variable should be treated as an indicator rather than quantitative variable. This signals glm() to fit a logistic regression model. The results of glm() should be saved to an object. glm.bliss &lt;- glm(outcome01~conc,data=bliss,family=binomial) Logistic regressions are fit in R with glm() rather than lm() because logistic regression is a generalized rather than a general linear model. 27.3 Relationship Test Generalized linear models, like logistic regression, are fit with a method called maximum likelihood (ML) rather than least-squares (i.e,. minimizing the residual sums-of-squares) estimation. In a very loose sense, the best model with ML estimation is the model that is most likely (i.e., maximum) to fit the data, in contrast to the model that minimizes the lack-of-fit (i.e., sum-of-squares). Because ML estimation is different than least-squares, the usual model comparison procedure is different for the logistic regression model. A likelihood ratio test (LRT) is used to determine if the increased likelihood of a full model is worth the increased complexity of the full model. A LRT can be performed in R with anova(), the glm() object with the logistic regression fit, and test=\"LRT\". For example, anova(glm.bliss,test=&quot;LRT&quot;) #R&gt; Analysis of Deviance Table #R&gt; #R&gt; Model: binomial, link: logit #R&gt; #R&gt; Response: outcome01 #R&gt; #R&gt; Terms added sequentially (first to last) #R&gt; #R&gt; #R&gt; Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi) #R&gt; NULL 480 645.44 #R&gt; conc 1 276.82 479 368.62 &lt; 2.2e-16 The p-value (under Pr(&gt;Chi)) is very small in this case which indicates that the full model that has a slope parameter is a much better fit to the data than the simple model with no slope parameter. In other words, there is a significant relationship between the log odds of mortality and concentration of the calcium disulphide. By extension this means that there is a significant relationship between the probability of mortality and the concentration of calcium disulphide. 27.4 Parameter Estimates The estimated intercept and slope are extracted from the glm() object with coef(). Confidence intervals constructed from bootstrap samples require bootstrap samples to be constructed first. There are many ways to construct bootstrap samples in R. We will use Boot() from the car package. This function will be called with car::Boot() so as to not have to load the whole car package. Boot() requires only the saved glm() object as its argument.101 The results of car::Boot() should be saved to an object.102 boot.bliss &lt;- car::Boot(glm.bliss) The bootstrap confidence intervals for the intercept and slope are extracted from the Boot() object with confint(). Include type=\"perc\" to perform the last step of the bootstrap steps shown in Section 26.5. As before, I like to combine the parameter estimates and confidence intervals into one presentation. cbind(Ests=coef(glm.bliss),confint(boot.bliss,type=&quot;perc&quot;)) #R&gt; Ests 2.5 % 97.5 % #R&gt; (Intercept) -14.8229985 -17.6159611 -12.5704693 #R&gt; conc 0.2494156 0.2126906 0.2967598 27.5 Predictions 27.5.1 Functions for Bootstrapping The bootstrap method was introduced in Section 26.5 as a way to estimate reliable confidence intervals for predicted probabilities and values of the explanatory variable for a given probability. Applying the bootstrap method for derived metrics like these requires specific functions to calculate the predicted probability for a given value of \\(X\\) and the value of \\(X\\) for a given probability. The predProb() below is the R version of \\[ p = \\frac{e^{\\alpha+\\beta X}}{1+e^{\\alpha+\\beta X}} \\] from Module 25 and predX() below is the R version of \\[ X = \\frac{log\\left(\\frac{p}{1-p}\\right)-\\alpha}{\\beta} \\] from Module 26. predProb &lt;- function(x,alpha,beta) exp(alpha+beta*x)/(1+exp(alpha+beta*x)) predX &lt;- function(p,alpha,beta) (log(p/(1-p))-alpha)/beta Copy the code for predProb() and predX() as shown above directly into the beginning of your logistic regression script. 27.5.2 Predictions The predicted log odds of mortality given a value of the concentration of calcium disulphide is found with predict(), similar to what was shown in previous modules. For example, the code below finds the log odds of mortality for a concentration of 70 mg/liter. nd &lt;- data.frame(conc=70) predict(glm.bliss,newdata=nd) #R&gt; 1 #R&gt; 2.636094 The probability, rather than log odds, can be found by including type=response in predict(). predict(glm.bliss,newdata=nd,type=&quot;response&quot;) #R&gt; 1 #R&gt; 0.9331487 Unfortunately, confidence intervals for this prediction can not be constructed with predict(). Bootstrap confidence intervals, however, can be constructed using predProb() and the data frame of bootstrapped intercepts and slopes saved earlier. This is a bit of work so, lets work through this step-by-step. First, the boostrapped data is in the t object of the Boot object saved above. head(boot.bliss$t) #R&gt; (Intercept) conc #R&gt; [1,] -14.49102 0.2451659 #R&gt; [2,] -15.52964 0.2605145 #R&gt; [3,] -16.45376 0.2746857 #R&gt; [4,] -14.58048 0.2469224 #R&gt; [5,] -15.27241 0.2567067 #R&gt; [6,] -15.56794 0.2617828 The intercepts are in the first column and the slopes are in the second. For example, you could see just the vector of slopes with boot.bliss$t[,2] (rounded below to save space) round(boot.bliss$t[,2],2) #R&gt; [1] 0.25 0.26 0.27 0.25 0.26 0.26 0.27 0.24 0.25 0.24 0.28 0.23 0.26 0.24 0.23 #R&gt; [16] 0.26 0.26 0.25 0.24 0.26 0.26 0.24 0.23 0.24 0.25 0.25 0.21 0.25 0.26 0.29 #R&gt; [31] 0.27 0.25 0.22 0.22 0.24 0.29 0.28 0.24 0.21 0.28 0.26 0.24 0.28 0.26 0.25 #R&gt; [46] 0.24 0.28 0.23 0.27 0.22 0.26 0.26 0.27 0.22 0.23 0.23 0.23 0.26 0.25 0.26 #R&gt; [61] 0.24 0.24 0.26 0.25 0.21 0.25 0.28 0.22 0.23 0.27 0.25 0.23 0.26 0.26 0.25 #R&gt; [76] 0.23 0.27 0.24 0.25 0.24 0.24 0.26 0.26 0.26 0.27 0.24 0.28 0.26 0.25 0.25 #R&gt; [91] 0.23 0.24 0.21 0.24 0.25 0.24 0.25 0.26 0.23 0.23 0.27 0.26 0.25 0.24 0.26 #R&gt; [106] 0.23 0.26 0.24 0.27 0.26 0.27 0.25 0.26 0.25 0.26 0.26 0.23 0.23 0.30 0.27 #R&gt; [121] 0.24 0.23 0.23 0.24 0.28 0.26 0.24 0.25 0.24 0.25 0.25 0.26 0.26 0.22 0.25 #R&gt; [136] 0.24 0.25 0.23 0.22 0.26 0.24 0.24 0.27 0.25 0.24 0.26 0.24 0.27 0.28 0.25 #R&gt; [151] 0.30 0.25 0.26 0.22 0.27 0.21 0.30 0.29 0.23 0.25 0.25 0.26 0.23 0.26 0.22 #R&gt; [166] 0.26 0.28 0.24 0.25 0.27 0.25 0.30 0.25 0.25 0.24 0.26 0.28 0.30 0.27 0.23 #R&gt; [181] 0.29 0.26 0.24 0.24 0.24 0.23 0.22 0.26 0.21 0.25 0.26 0.28 0.27 0.23 0.27 #R&gt; [196] 0.23 0.24 0.22 0.30 0.24 0.29 0.25 0.25 0.27 0.22 0.25 0.25 0.24 0.26 0.28 #R&gt; [211] 0.26 0.34 0.26 0.27 0.25 0.22 0.23 0.27 0.23 0.24 0.26 0.24 0.23 0.22 0.18 #R&gt; [226] 0.28 0.27 0.25 0.27 0.26 0.26 0.24 0.27 0.26 0.25 0.21 0.26 0.24 0.23 0.20 #R&gt; [241] 0.27 0.25 0.21 0.21 0.25 0.24 0.22 0.25 0.23 0.26 0.19 0.23 0.25 0.25 0.27 #R&gt; [256] 0.26 0.27 0.24 0.29 0.26 0.23 0.27 0.26 0.26 0.24 0.24 0.23 0.33 0.25 0.27 #R&gt; [271] 0.22 0.21 0.27 0.20 0.23 0.25 0.30 0.27 0.30 0.24 0.22 0.23 0.22 0.29 0.25 #R&gt; [286] 0.24 0.28 0.24 0.25 0.26 0.25 0.26 0.26 0.27 0.25 0.23 0.23 0.24 0.29 0.25 #R&gt; [301] 0.28 0.27 0.23 0.22 0.25 0.27 0.26 0.25 0.26 0.26 0.23 0.28 0.25 0.25 0.26 #R&gt; [316] 0.26 0.25 0.26 0.27 0.23 0.28 0.29 0.26 0.27 0.24 0.25 0.28 0.30 0.24 0.30 #R&gt; [331] 0.28 0.23 0.27 0.26 0.25 0.27 0.27 0.26 0.23 0.28 0.25 0.24 0.24 0.26 0.25 #R&gt; [346] 0.22 0.25 0.23 0.24 0.24 0.25 0.28 0.25 0.28 0.21 0.23 0.24 0.25 0.24 0.26 #R&gt; [361] 0.27 0.26 0.25 0.24 0.24 0.32 0.23 0.26 0.24 0.26 0.23 0.25 0.23 0.30 0.24 #R&gt; [376] 0.24 0.22 0.23 0.29 0.30 0.25 0.29 0.24 0.24 0.25 0.23 0.30 0.26 0.24 0.24 #R&gt; [391] 0.22 0.24 0.24 0.24 0.23 0.26 0.25 0.25 0.24 0.23 0.27 0.27 0.29 0.29 0.25 #R&gt; [406] 0.26 0.27 0.24 0.22 0.25 0.24 0.24 0.26 0.23 0.26 0.27 0.27 0.24 0.25 0.29 #R&gt; [421] 0.24 0.24 0.26 0.22 0.26 0.26 0.28 0.22 0.27 0.23 0.22 0.25 0.23 0.29 0.25 #R&gt; [436] 0.24 0.26 0.27 0.23 0.27 0.23 0.30 0.23 0.23 0.28 0.24 0.28 0.21 0.24 0.20 #R&gt; [451] 0.24 0.22 0.24 0.27 0.27 0.26 0.26 0.27 0.25 0.28 0.24 0.26 0.26 0.27 0.25 #R&gt; [466] 0.25 0.23 0.20 0.23 0.25 0.24 0.24 0.25 0.28 0.25 0.27 0.26 0.26 0.28 0.24 #R&gt; [481] 0.26 0.25 0.26 0.24 0.27 0.24 0.28 0.24 0.24 0.27 0.22 0.27 0.25 0.25 0.23 #R&gt; [496] 0.26 0.24 0.22 0.27 0.28 0.21 0.23 0.27 0.28 0.24 0.23 0.26 0.23 0.22 0.24 #R&gt; [511] 0.24 0.23 0.29 0.24 0.26 0.26 0.27 0.25 0.25 0.24 0.25 0.26 0.29 0.23 0.28 #R&gt; [526] 0.25 0.24 0.24 0.24 0.23 0.22 0.25 0.22 0.25 0.22 0.25 0.25 0.25 0.27 0.22 #R&gt; [541] 0.28 0.26 0.28 0.25 0.24 0.28 0.25 0.25 0.24 0.25 0.26 0.27 0.23 0.23 0.24 #R&gt; [556] 0.26 0.23 0.23 0.28 0.28 0.25 0.24 0.24 0.25 0.28 0.23 0.26 0.27 0.22 0.23 #R&gt; [571] 0.26 0.23 0.22 0.23 0.25 0.23 0.25 0.26 0.30 0.24 0.22 0.26 0.25 0.25 0.24 #R&gt; [586] 0.26 0.26 0.27 0.27 0.24 0.28 0.22 0.27 0.28 0.25 0.23 0.26 0.25 0.26 0.26 #R&gt; [601] 0.26 0.26 0.25 0.26 0.23 0.25 0.26 0.27 0.28 0.23 0.27 0.24 0.25 0.25 0.29 #R&gt; [616] 0.25 0.23 0.24 0.23 0.24 0.24 0.26 0.25 0.25 0.31 0.23 0.20 0.30 0.24 0.27 #R&gt; [631] 0.24 0.26 0.23 0.29 0.26 0.25 0.25 0.26 0.22 0.24 0.26 0.24 0.23 0.26 0.27 #R&gt; [646] 0.27 0.25 0.24 0.23 0.21 0.24 0.23 0.24 0.23 0.27 0.27 0.26 0.26 0.25 0.25 #R&gt; [661] 0.27 0.23 0.26 0.22 0.25 0.24 0.24 0.26 0.26 0.28 0.21 0.26 0.25 0.24 0.29 #R&gt; [676] 0.25 0.21 0.24 0.23 0.26 0.25 0.26 0.22 0.28 0.25 0.26 0.28 0.25 0.24 0.25 #R&gt; [691] 0.30 0.29 0.27 0.22 0.27 0.26 0.25 0.22 0.28 0.24 0.22 0.24 0.22 0.27 0.29 #R&gt; [706] 0.26 0.22 0.23 0.25 0.28 0.26 0.27 0.27 0.24 0.23 0.26 0.25 0.24 0.29 0.25 #R&gt; [721] 0.22 0.28 0.28 0.27 0.26 0.24 0.25 0.27 0.27 0.23 0.26 0.25 0.21 0.26 0.24 #R&gt; [736] 0.24 0.27 0.23 0.24 0.25 0.23 0.24 0.25 0.28 0.26 0.22 0.23 0.25 0.29 0.24 #R&gt; [751] 0.26 0.26 0.25 0.22 0.22 0.25 0.21 0.28 0.25 0.23 0.24 0.26 0.26 0.25 0.26 #R&gt; [766] 0.28 0.27 0.21 0.22 0.21 0.24 0.22 0.25 0.26 0.27 0.25 0.24 0.22 0.24 0.28 #R&gt; [781] 0.26 0.25 0.29 0.27 0.26 0.23 0.26 0.28 0.24 0.24 0.22 0.24 0.25 0.25 0.24 #R&gt; [796] 0.27 0.22 0.22 0.21 0.24 0.28 0.24 0.26 0.28 0.26 0.24 0.28 0.24 0.27 0.21 #R&gt; [811] 0.26 0.28 0.26 0.28 0.25 0.25 0.27 0.28 0.24 0.22 0.25 0.25 0.23 0.25 0.24 #R&gt; [826] 0.25 0.25 0.22 0.26 0.26 0.22 0.24 0.25 0.26 0.21 0.25 0.25 0.26 0.21 0.25 #R&gt; [841] 0.23 0.22 0.24 0.21 0.24 0.27 0.29 0.27 0.22 0.26 0.24 0.25 0.22 0.27 0.23 #R&gt; [856] 0.25 0.28 0.27 0.25 0.27 0.24 0.25 0.27 0.24 0.25 0.26 0.23 0.35 0.23 0.25 #R&gt; [871] 0.24 0.22 0.26 0.26 0.27 0.24 0.24 0.24 0.23 0.25 0.26 0.24 0.27 0.22 0.27 #R&gt; [886] 0.24 0.24 0.25 0.24 0.25 0.24 0.25 0.24 0.31 0.22 0.28 0.24 0.28 0.24 0.26 #R&gt; [901] 0.23 0.30 0.24 0.25 0.27 0.24 0.24 0.25 0.29 0.21 0.27 0.27 0.20 0.27 0.27 #R&gt; [916] 0.28 0.30 0.24 0.24 0.21 0.25 0.25 0.22 0.25 0.33 0.22 0.26 0.26 0.25 0.26 #R&gt; [931] 0.26 0.21 0.28 0.27 0.22 0.22 0.24 0.30 0.26 0.23 0.26 0.30 0.28 0.24 0.23 #R&gt; [946] 0.26 0.24 0.23 0.23 0.25 0.26 0.29 0.21 0.21 0.26 0.27 0.25 0.26 0.30 0.26 #R&gt; [961] 0.24 0.27 0.23 0.23 0.26 0.24 0.24 0.27 0.23 0.27 0.25 0.24 0.26 0.26 0.26 #R&gt; [976] 0.24 0.23 0.24 0.26 0.26 0.26 0.24 0.29 0.26 0.26 0.24 0.31 0.27 0.27 0.22 #R&gt; [991] 0.27 0.24 0.23 0.22 0.27 0.27 0.26 0.26 0.25 Second, note that predProb() takes a value of \\(X\\) at which to make the prediction as its first argument, an intercept as the second argument, and the slope as the third argument. If this function is given all of the bootstrapped intercepts and slopes then it will make a prediction at the supplied value of x for each bootstrapped sample. For example, the code below computes the predicted probability of mortality at a concentration of 70 mg/L for each bootstrapped sample and then examines the first six of those values. p70 &lt;- predProb(70,boot.bliss$t[,1],boot.bliss$t[,2]) head(p70) #R&gt; [1] 0.9352690 0.9374018 0.9412677 0.9372674 0.9368530 0.9402995 The 95% bootstrapped confidence interval is between the two values in p70 that have 2.5% and 97.5% of the values lower. These values are found with quantile() given the vector of values as the first argument, the percentages to cut off at as proportions in probs=, and type=1 so that the quantiles computed here are the same as those in confint() above. For example, the 95% confidence interval for the predicted probability for a concentration of 70 mg/L is computed with ( ci70 &lt;- quantile(p70,c(0.025,0.975)) ) #R&gt; 2.5% 97.5% #R&gt; 0.9032931 0.9581815 Thus, one is 95% confident that the predicted probability of mortality for beetles exposed to 70 mg/l calcium disulphide is between 0.903 and 0.958. A similar process is used to predict the concentration where 50%, for example, of the beetles will have died, except that predX() from above is used and it requires the probability of interest as a proportion as the first argument. x50 &lt;- predX(0.5,boot.bliss$t[,1],boot.bliss$t[,2]) ( ci50 &lt;- quantile(x50,c(0.025,0.975)) ) #R&gt; 2.5% 97.5% #R&gt; 58.31069 60.44455 Thus, one is 95% confident that the predicted concentration where 50% of the beetles would be dead is between 58.3 and 60.4. 27.6 Plotting Best-Fit Line The code below is used to construct a fitted-line plot for the logistic regression. The alpha= argument in geom_point() is used to make the points semi-transparent. This is important here because many points will be plotted on top of each other. With semi-transparency the visible point will become darker as more points are plotted on top of each other. You may need to try different values for alpha= (smaller values are more transparent). Also note that geom_smooth uses method=\"glm\" instead of lm. The method.args= can be copied directly, but note that this just supplies the family= argument to glm() within geom_smooth(). ggplot(data=bliss,mapping=aes(x=conc,y=outcome01)) + geom_point(alpha=0.01) + geom_smooth(method=&quot;glm&quot;,method.args=list(family=binomial)) + labs(x=&quot;Concentration of Disulphide&quot;,y=&quot;Probability of Mortality&quot;) + theme_NCStats() Note that R uses == when asking if two things are equal. So the condition in this ifelse() is asking where the oucome variable in bliss is equal to dead. The number of bootstrap samples defaults to 999, which is adequate for our purposes. This number of bootstrap samples can be modified with R=. Boot() may take many seconds to run, depending on the size of the original data frame and the number of bootstrapped samples taken. "],["references.html", "References", " References "]]
