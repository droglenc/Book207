<!DOCTYPE html>
<html lang="en" xml:lang="en">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Module 4 Model Comparison | Readings for MTH207</title>
  <meta name="description" content="This book contains the readings for MTH207 at Northland College." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Module 4 Model Comparison | Readings for MTH207" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://derekogle.com/Book207/" />
  
  <meta property="og:description" content="This book contains the readings for MTH207 at Northland College." />
  <meta name="github-repo" content="droglenc/Book207" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Module 4 Model Comparison | Readings for MTH207" />
  
  <meta name="twitter:description" content="This book contains the readings for MTH207 at Northland College." />
  

<meta name="author" content="Derek H. Ogle" />


<meta name="date" content="2020-12-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ModelConcepts.html"/>
<link rel="next" href="ANOVA1Foundations.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Readings for MTH207</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>FOUNDATIONS</b></span></li>
<li class="chapter" data-level="1" data-path="ModelTypes.html"><a href="ModelTypes.html"><i class="fa fa-check"></i><b>1</b> Model Types &amp; Methods</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ModelTypes.html"><a href="ModelTypes.html#distinguishing-methods"><i class="fa fa-check"></i><b>1.1</b> Distinguishing Methods</a></li>
<li class="chapter" data-level="1.2" data-path="ModelTypes.html"><a href="ModelTypes.html#method-purposes"><i class="fa fa-check"></i><b>1.2</b> Method Purposes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="T2Review.html"><a href="T2Review.html"><i class="fa fa-check"></i><b>2</b> 2-Sample t Review</a>
<ul>
<li class="chapter" data-level="2.1" data-path="T2Review.html"><a href="T2Review.html#review"><i class="fa fa-check"></i><b>2.1</b> Review</a></li>
<li class="chapter" data-level="2.2" data-path="T2Review.html"><a href="T2Review.html#T2analysis"><i class="fa fa-check"></i><b>2.2</b> Analysis in R</a></li>
<li class="chapter" data-level="2.3" data-path="T2Review.html"><a href="T2Review.html#signal-to-noise"><i class="fa fa-check"></i><b>2.3</b> Signal-to-Noise</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ModelConcepts.html"><a href="ModelConcepts.html"><i class="fa fa-check"></i><b>3</b> Model Concepts</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ModelConcepts.html"><a href="ModelConcepts.html#what-is-a-model"><i class="fa fa-check"></i><b>3.1</b> What is a Model</a></li>
<li class="chapter" data-level="3.2" data-path="ModelConcepts.html"><a href="ModelConcepts.html#assessing-fit-ss"><i class="fa fa-check"></i><b>3.2</b> Assessing Fit (SS)</a></li>
<li class="chapter" data-level="3.3" data-path="ModelConcepts.html"><a href="ModelConcepts.html#residual-degrees-of-freedom"><i class="fa fa-check"></i><b>3.3</b> Residual Degrees-of-Freedom</a></li>
<li class="chapter" data-level="3.4" data-path="ModelConcepts.html"><a href="ModelConcepts.html#mean-squares"><i class="fa fa-check"></i><b>3.4</b> Mean-Squares</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ModelComparison.html"><a href="ModelComparison.html"><i class="fa fa-check"></i><b>4</b> Model Comparison</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ModelComparison.html"><a href="ModelComparison.html#competing-models"><i class="fa fa-check"></i><b>4.1</b> Competing Models</a></li>
<li class="chapter" data-level="4.2" data-path="ModelComparison.html"><a href="ModelComparison.html#measuring-increase-in-fit"><i class="fa fa-check"></i><b>4.2</b> Measuring Increase in Fit</a></li>
<li class="chapter" data-level="4.3" data-path="ModelComparison.html"><a href="ModelComparison.html#measuring-increase-in-complexity"><i class="fa fa-check"></i><b>4.3</b> Measuring Increase in Complexity</a></li>
<li class="chapter" data-level="4.4" data-path="ModelComparison.html"><a href="ModelComparison.html#noise-variances"><i class="fa fa-check"></i><b>4.4</b> “Noise” Variances</a></li>
<li class="chapter" data-level="4.5" data-path="ModelComparison.html"><a href="ModelComparison.html#signal-variance-benefit-to-cost"><i class="fa fa-check"></i><b>4.5</b> “Signal” Variance (Benefit-to-Cost)</a></li>
<li class="chapter" data-level="4.6" data-path="ModelComparison.html"><a href="ModelComparison.html#ratio-of-variances-signal-to-noise"><i class="fa fa-check"></i><b>4.6</b> Ratio of Variances (Signal-to-Noise)</a></li>
<li class="chapter" data-level="4.7" data-path="ModelComparison.html"><a href="ModelComparison.html#anova-table"><i class="fa fa-check"></i><b>4.7</b> ANOVA Table</a></li>
<li class="chapter" data-level="4.8" data-path="ModelComparison.html"><a href="ModelComparison.html#two-sample-t-test-revisited-using-linear-models"><i class="fa fa-check"></i><b>4.8</b> Two-Sample t-Test Revisited: Using Linear Models</a></li>
<li class="chapter" data-level="4.9" data-path="ModelComparison.html"><a href="ModelComparison.html#one-more-look-at-ms-and-f-test"><i class="fa fa-check"></i><b>4.9</b> One More Look at MS and F-test</a></li>
</ul></li>
<li class="part"><span><b>ONE-WAY ANOVA</b></span></li>
<li class="chapter" data-level="5" data-path="ANOVA1Foundations.html"><a href="ANOVA1Foundations.html"><i class="fa fa-check"></i><b>5</b> One-Way ANOVA Foundations</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ANOVA1Foundations.html"><a href="ANOVA1Foundations.html#analytical-foundation"><i class="fa fa-check"></i><b>5.1</b> Analytical Foundation</a></li>
<li class="chapter" data-level="5.2" data-path="ANOVA1Foundations.html"><a href="ANOVA1Foundations.html#one-way-anova-in-r"><i class="fa fa-check"></i><b>5.2</b> One-Way ANOVA in R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ANOVA1MultipleComparisons.html"><a href="ANOVA1MultipleComparisons.html"><i class="fa fa-check"></i><b>6</b> Multiple Comparisons</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ANOVA1MultipleComparisons.html"><a href="ANOVA1MultipleComparisons.html#multiple-comparison-problem"><i class="fa fa-check"></i><b>6.1</b> Multiple Comparison Problem</a></li>
<li class="chapter" data-level="6.2" data-path="ANOVA1MultipleComparisons.html"><a href="ANOVA1MultipleComparisons.html#correction-methods"><i class="fa fa-check"></i><b>6.2</b> Correction Methods</a></li>
<li class="chapter" data-level="6.3" data-path="ANOVA1MultipleComparisons.html"><a href="ANOVA1MultipleComparisons.html#multiple-comparisons-in-r"><i class="fa fa-check"></i><b>6.3</b> Multiple Comparisons in R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a></li>
<li><a href="https://bookdown.org" target="_blank">Built with Bookdown + RStudio</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Readings for MTH207</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ModelComparison" class="section level1" number="4">
<h1><span class="header-section-number">Module 4</span> Model Comparison</h1>
<div id="competing-models" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Competing Models</h2>
<div id="general" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> General</h3>
<p>Many hypothesis tests can be cast in a framework of competing models. In this module we will cast the familiar 2-sample t-test in this framework which will then serve as a conceptual foundation for all other linear models in this course.</p>
<p>The two competing models are generically called the <em>simple</em> and <em>full</em> models (Table <a href="ModelComparison.html#tab:ModelDifferences">4.1</a>). The simple model is simpler than the full model in the sense that it has fewer parameters. However, the simple model fits the data “worse” than a full model. Thus, determining which model to use becomes a question of balancing “fit” (full model fits better than the simple model) with complexity (simple model is less complex than the full model). Because the simple model corresponds to H<sub>0</sub> and the full model corresponds to H<sub>A</sub>, deciding which model to use is the same as deciding which hypothesis is supported by the data.</p>
<table class=" lightable-classic" style="font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ModelDifferences">Table 4.1: </span>Differences between the two generic model types.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
Parameters
</th>
<th style="text-align:left;">
Residual df
</th>
<th style="text-align:left;">
Relative Fit
</th>
<th style="text-align:left;">
Residual SS
</th>
<th style="text-align:left;">
Hypothesis
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Simple
</td>
<td style="text-align:left;">
Fewer
</td>
<td style="text-align:left;">
More
</td>
<td style="text-align:left;">
Worse
</td>
<td style="text-align:left;">
Larger
</td>
<td style="text-align:left;">
Null
</td>
</tr>
<tr>
<td style="text-align:left;">
Full
</td>
<td style="text-align:left;">
More
</td>
<td style="text-align:left;">
Less
</td>
<td style="text-align:left;">
Better
</td>
<td style="text-align:left;">
Smaller
</td>
<td style="text-align:left;">
Alternative
</td>
</tr>
</tbody>
</table>
<p> </p>
</div>
<div id="sample-t-test" class="section level3" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> 2-Sample t-Test</h3>
<p>Recall that H<sub>0</sub> in a two-sample t-test is that the two population means do not differ (i.e., they are equal). In this hypothesis, if the two means do not differ than a single mean would adequately represent both groups. The general model from Section <a href="ModelConcepts.html#what-is-a-model">3.1</a><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> could be specified for this situation as</p>
<p><span class="math display">\[ Y_{ij} = \mu + \epsilon_{ij} \]</span></p>
<p>where <span class="math inline">\(Y_{ij}\)</span> is the <span class="math inline">\(j\)</span>th observation of the response variable in the <span class="math inline">\(i\)</span>th group, <span class="math inline">\(\mu\)</span> is the population grand mean, and <span class="math inline">\(\epsilon_{ij}\)</span> is the “error” for the <span class="math inline">\(j\)</span>th observation in the <span class="math inline">\(i\)</span>th group. This model means that μ is the predicted response value for each observation and the model looks like the red line in Figure <a href="ModelComparison.html#fig:Models1">4.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:Models1"></span>
<img src="Book207_files/figure-html/Models1-1.png" alt="Biological oxygen demand versus sample location with group means shown as blue horizontal segments and the grand mean shown as a red horizontal segment." width="336" />
<p class="caption">
Figure 4.1: Biological oxygen demand versus sample location with group means shown as blue horizontal segments and the grand mean shown as a red horizontal segment.
</p>
</div>
<p>In contrast, H<sub>A</sub> in the 2-sample t-test is that the two population means differ (i.e., they are not equal). This hypothesis suggests that two separate means are needed to predict observations in the separate groups. The model for this situation is</p>
<p><span class="math display">\[ Y_{ij} = \mu_{i} + \epsilon_{ij} \]</span></p>
<p>where <span class="math inline">\(\mu_{i}\)</span> is the population mean for the <span class="math inline">\(i\)</span>th group. This model means that <span class="math inline">\(\mu_{1}\)</span> is the predicted response value for observations in the first group and <span class="math inline">\(\mu_{2}\)</span> is the predicted response value for observations in the second group. This model looks like the two blue lines in the figure above.</p>
<p>Thus, for a 2-sample t-test, the <strong>simple model</strong> corresponds to H<sub>0</sub>: <span class="math inline">\(\mu_{1}=\mu_{2}\)</span> (=<span class="math inline">\(\mu\)</span>), has fewer parameters (i.e., requires only one mean; the red line in the plots above), and fits “worse.”<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> In contrast, the <strong>full model</strong> corresponds to H<sub>A</sub>: <span class="math inline">\(\mu_{1}\ne\mu_{2}\)</span>, has more parameters (i.e., requires two means; the blue lines in the plots above), and fits “better.”</p>
<p>In the ensuing sections we will develop a method to determine if the increase in “fit” is worth the increase in “complexity.”</p>
<p> </p>
</div>
</div>
<div id="measuring-increase-in-fit" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Measuring Increase in Fit</h2>
<div id="sstotal-and-sswithin" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> SS<sub>Total</sub> and SS<sub>Within</sub></h3>
<p>In Section <a href="ModelConcepts.html#residual-sum-of-squares">3.2.2</a> the idea of using the residual sum-of-squares (RSS) to measure the lack-of-fit of a model was introduced. Here we apply that concept to measure the lack-of-fit of the simple and full models, which we will then use to see how much “better” the full model fits than the simple model.</p>
<div class="tip">
<p>Remember that the full model will always fit better than the simple model, even if by just a small amount.</p>
</div>
<p>The RSS for the simple model using just the grand mean is called SS<sub>Total</sub> and is computed with</p>
<p><span class="math display">\[ \text{SS}_{\text{Total}} = \sum_{i=1}^{I}\sum_{j=1}^{n_{i}}\left(Y_{ij}-\bar{Y}_{\cdot\cdot}\right)^{2} \]</span></p>
<p>where <span class="math inline">\(I\)</span> is the number of groups (=2 in a 2-sample t-test), <span class="math inline">\(n_{i}\)</span> is the sample size in the <span class="math inline">\(i\)</span>th group, and <span class="math inline">\(\bar{Y}_{\cdot\cdot}\)</span> is the sample grand mean as computed with</p>
<p><span class="math display">\[ \bar{Y}_{\cdot\cdot}= \frac{\sum_{i=1}^{I}\sum_{j=1}^{n_{i}}Y_{ij}}{n} \]</span></p>
<p>where <span class="math inline">\(n\)</span> is the sample size across all groups. The <span class="math inline">\(\bar{Y}_{\cdot\cdot}\)</span> is used here because it is an estimate of the population grand mean, <span class="math inline">\(\mu\)</span>, which is used to make predictions in this simple model.</p>
<p>The formula for SS<sub>Total</sub> may look daunting but it is just the sum of the squared residuals computed from each observation relative to the grand mean (Figure <a href="ModelComparison.html#fig:FullModelResids1">4.2</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:FullModelResids1"></span>
<img src="Book207_files/figure-html/FullModelResids1-1.png" alt="Biological oxygen demand versus sample location with the grand mean shown as a red horizontal segment. Residuals from the grand mean are shown by red vertical dashed lines. The sum of these residuals is SS&lt;sub&gt;Total&lt;/sub&gt;." width="336" />
<p class="caption">
Figure 4.2: Biological oxygen demand versus sample location with the grand mean shown as a red horizontal segment. Residuals from the grand mean are shown by red vertical dashed lines. The sum of these residuals is SS<sub>Total</sub>.
</p>
</div>
<p> </p>
<p>The RSS for the full model using separate group means is called SS<sub>Within</sub> and is computed with</p>
<p><span class="math display">\[ \text{SS}_{\text{Within}} = \sum_{i=1}^{I}\sum_{j=1}^{n_{i}}\left(Y_{ij}-\bar{Y}_{i\cdot}\right)^{2} \]</span></p>
<p>where <span class="math inline">\(\bar{Y}_{i\cdot}\)</span> are the sample group means as computed with</p>
<p><span class="math display">\[ \bar{Y}_{\cdot\cdot} = \frac{\sum_{j=1}^{n_{i}}Y_{ij}}{n_{i}} \]</span></p>
<p>The <span class="math inline">\(\bar{Y}_{i\cdot}\)</span> are used here because they are an estimate of the population group means, <span class="math inline">\(\mu_{i}\)</span>, which are used to make predictions in this full model. Again, the formula for SS<sub>Within</sub> may look imposing but it is just the sum of the squared residuals computed from each observation to the observation’s group mean (Figure <a href="ModelComparison.html#fig:SimpleModelResids1">4.3</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:SimpleModelResids1"></span>
<img src="Book207_files/figure-html/SimpleModelResids1-1.png" alt="Biological oxygen demand versus sample location with the group means shown as blue horizontal segments. Residuals from the group means are shown by blue vertical dashed lines. The sum of these residuals is SS&lt;sub&gt;Within&lt;/sub&gt;." width="336" />
<p class="caption">
Figure 4.3: Biological oxygen demand versus sample location with the group means shown as blue horizontal segments. Residuals from the group means are shown by blue vertical dashed lines. The sum of these residuals is SS<sub>Within</sub>.
</p>
</div>
<p> </p>
<p>Thus, SS<sub>Total</sub> measures the lack-of-fit of the grand mean to the data or the lack-of-fit of the simple model. SS<sub>Within</sub>, in contrast, measures the lack-of-fit of the group means to the data or the lack-of-fit of the full model.</p>
<p>In this example, SS<sub>Total</sub>=25.28 and SS<sub>Within</sub>=4.60. Because SS<sub>Within</sub> is less than SS<sub>Total</sub> that means that the full model that uses μ<sub>i</sub> fits the data better than the simple model that uses just <span class="math inline">\(\mu\)</span>.</p>
<p>However, we knew that this was going to happen as the full model always fits better. What we need now is a measure of how much better the full model fits or, equivalently, a measure of how much the lack-of-fit was reduced by using the full model rather than the simple model.</p>
</div>
<div id="ssamong" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> SS<sub>Among</sub></h3>
<p>An useful property of SS<sub>Total</sub> is that it “partitions” into two parts according to the following simple formula</p>
<p><span class="math display">\[ \text{SS}_{\text{Total}} = \text{SS}_{\text{Within}} + \text{SS}_{\text{Among}} \]</span></p>
<p>This introduces a new quantity, SS<sub>Among</sub>. A quick re-arrangement of the partitioning of SS<sub>Total</sub> shows that</p>
<p><span class="math display">\[ \text{SS}_{\text{Among}} = \text{SS}_{\text{Total}} - \text{SS}_{\text{Within}} \]</span></p>
<p>Thus, SS<sub>Among</sub> records how much the lack-of-fit was reduced by using the full model rather than the simple model. In other words, SS<sub>Among</sub> records how much “better” the full model fits the data than the simple model.</p>
<p>In our example, SS<sub>Among</sub>=25.28-4.60=20.68. Thus, the residual SS from the simple model was reduced by 20.68 when the full model was used.</p>
<div class="tip">
<p>SS<sub>Among</sub> is the <strong>benefit</strong> (i.e., reduction in lack-of-fit) of using the full rather than simple model</p>
</div>
<p>SS<sub>Among</sub> can also be thought of in a different way. It can be algebraically shown that</p>
<p><span class="math display">\[ \text{SS}_{\text{Among}} = \sum_{i=1}^{I}n_{i}\left(\bar{Y}_{i\cdot}-\bar{Y}_{\cdot\cdot}\right)^{2} \]</span></p>
<p>Again, this looks complicated, but the main part to focus on is <span class="math inline">\(\bar{Y}_{i\cdot}-\bar{Y}_{\cdot\cdot}\)</span>, which shows that SS<sub>Among</sub> is primarily concerned with measuring the distance between the group means (i.e., <span class="math inline">\(\bar{Y}_{i\cdot}\)</span>) and the grand mean (i.e., <span class="math inline">\(\bar{Y}_{\cdot\cdot}\)</span>; Figure <a href="ModelComparison.html#fig:BothModelResids">4.4</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:BothModelResids"></span>
<img src="Book207_files/figure-html/BothModelResids-1.png" alt="Mean biological oxygen demand versus sample location with the grand mean shown as a red horizontal segment and the group means shown as blue horizontal segments. Residuals between the group means and the grand mean are shown by black vertical dashed lines. The sum of these residuals scaled by the group sample sizes is SS&lt;sub&gt;Among&lt;/sub&gt;." width="336" />
<p class="caption">
Figure 4.4: Mean biological oxygen demand versus sample location with the grand mean shown as a red horizontal segment and the group means shown as blue horizontal segments. Residuals between the group means and the grand mean are shown by black vertical dashed lines. The sum of these residuals scaled by the group sample sizes is SS<sub>Among</sub>.
</p>
</div>
<p>From the figure above, it is seen that SS<sub>Among</sub> will increase as the group means become more different. In other words, SS<sub>Among</sub> measures the <strong>signal</strong> in the data.</p>
<div class="tip">
<p>SS<sub>Among</sub> is the <strong>signal</strong> (i.e., relative difference in group means) in the data</p>
</div>
<p>This can be seen in the interactive graphic below. You can adjust the amount of “signal” in the data by increasing or decreasing the difference between the group means and the grand mean. As you do this note how SS<sub>Among</sub> (and SS<sub>Total</sub>) change.</p>
<iframe src="https://derek-ogle.shinyapps.io/App_SSTotal_Partitioning/?showcase=0" width="95%" height="800px">
</iframe>
<p> </p>
<p>So, SS<sub>Among</sub> is immensely useful – it is a measure of “benefit” that will be used in a “benefit-to-cost” ratio and it is the “signal” that will be used in a “signal-to-noise” ratio. These ratios are discussed further below. Next we discuss how to measure the “cost” of using the more complex full model.</p>
</div>
</div>
<div id="measuring-increase-in-complexity" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Measuring Increase in Complexity</h2>
<p>In this example, df<sub>Total</sub>=20-1 because there is one parameter (the grand mean) in the simple model, and df<sub>Within</sub>=20-2 because there are two parameters (the group means) in the full model. The full model uses more parameters and, thus, the residual degrees-of-freedom is reduced – there is a “cost” to using the full model over the simple model. We need a measure of this “cost.”<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p>Interestingly df<sub>Total</sub> partitions in the same way as SS<sub>Total</sub>; i.e.,</p>
<p><span class="math display">\[ \text{df}_{\text{Total}} = \text{df}_{\text{Within}} + \text{df}_{\text{Among}} \]</span></p>
<p>This introduces another new quantity, df<sub>Among</sub>. A quick re-arrangement of the partitioning of df<sub>Total</sub> shows that</p>
<p><span class="math display">\[ \text{df}_{\text{Among}} = \text{df}_{\text{Total}} - \text{df}_{\text{Within}} \]</span></p>
<p>In this case, df<sub>Among</sub>=19-18=1.</p>
<p>Thus, df<sub>Among</sub> is the degrees-of-freedom that were “lost” or “used” when the more complicated full model was used compared to the simpler simple model. The df<sub>Among</sub> is also the <strong>difference in number of parameters</strong> between the full and simple models. In other words, df<sub>Among</sub> is how much more complex (in terms of number of parameters) the full model is compared to the simple model. Thus, df<sub>Among</sub> measures the <strong>cost</strong> of using the full model rather than the simple model.</p>
<div class="tip">
<p>df<sub>Among</sub> is the extra <strong>cost</strong> (i.e., loss of df) from using the full rather than simple model</p>
</div>
<p> </p>
</div>
<div id="noise-variances" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> “Noise” Variances</h2>
<p>MS<sub>Total</sub> and MS<sub>Within</sub> are measures of the variance<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> of <strong>individuals</strong> around the grand mean and group means, respectively. Thus, MS<sub>Total</sub> measures the variance or “noise” around the full model, whereas MS<sub>Within</sub> measures the variance or “noise” around the simple model.</p>
<div class="tip">
<p>MS<sub>Total</sub> and MS<sub>Within</sub> measure “noise” – i.e., variability of observations around a model</p>
</div>
<p>Before moving on to discuss MS<sub>Among</sub>, it is worth noting that MS<sub>Total</sub> is</p>
<p><span class="math display">\[ \text{MS}_{\text{Total}} = \frac{\text{SS}_{\text{Total}}}{\text{df}_{\text{Total}}} = \frac{\sum_{i=1}^{I}\sum_{j=1}^{n_{i}}\left(Y_{ij}-\bar{Y}_{\cdot\cdot}\right)^{2}}{n-1} \]</span></p>
<p>Realizing that the double summation simply means to “sum across all individuals” it is seen that this is the variance (<span class="math inline">\(s^{2}\)</span>) from your introductory statistics course. In other words it is just the variability of the individuals around a mean that ignores that there are groups.</p>
<div class="tip">
<p>MS<sub>Total</sub>=<span class="math inline">\(s^{2}\)</span></p>
</div>
<p>Similarly, MS<sub>Within</sub> is</p>
<p><span class="math display">\[ \text{MS}_{\text{Within}} = \frac{\text{SS}_{\text{Within}}}{\text{df}_{\text{Within}}} = \frac{\sum_{i=1}^{I}\sum_{j=1}^{n_{i}}\left(Y_{ij}-\bar{Y}_{i\cdot}\right)^{2}}{\sum_{i=1}^{I}n_{i}-I} \]</span></p>
<p>It is not hard to show algebraically (and for just two groups) that the numerator is <span class="math inline">\(n_{1}s_{1}^{2}+n_{2}s_{2}^{2}\)</span> and that the denominator is <span class="math inline">\(n_{1}+n_{2}-2\)</span>. This numerator and denominator are then simply the pooled sample variance (<span class="math inline">\(s_{p}^{2}\)</span>) from the 2-sample t-test. Thus, MS<sub>Within</sub> with two groups is the same as <span class="math inline">\(s_{p}^{2}\)</span> from the 2-sample t-test.</p>
<div class="tip">
<p>MS<sub>Within</sub>=<span class="math inline">\(s_{p}^{2}\)</span></p>
</div>
<p> </p>
</div>
<div id="signal-variance-benefit-to-cost" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> “Signal” Variance (Benefit-to-Cost)</h2>
<p>Of course SS<sub>Among</sub> divided by df<sub>Among</sub> will be MS<sub>Among</sub>. However, while MS<sub>Among</sub> is still a variance, it has a very different interpretation.</p>
<p>MS<sub>Among</sub> is NOT a variance of <em>individuals</em>, rather it is a variance of <em>sample means</em>. Sample means can vary (i.e., not be equal) for two reasons – purely due to random sampling variability (i.e., the population means are not different) or the population means really do differ such that the sample means differ. In other words, MS<sub>Among</sub> – the variance among means – is a combination of “noise” and “signal.” Our goal (next) is to disentangle these two reasons for why the sample means differ to determine if there is a real “signal” or not.</p>
<p>Additionally, MS<sub>Among</sub> is a ratio of the “benefit” (i.e., SS<sub>Among</sub>) to the “cost” (i.e., df<sub>Among</sub>) of using the full model over the simple model. So MS<sub>Among</sub> scales the benefit to the cost of using the full model.</p>
<p> </p>
</div>
<div id="ratio-of-variances-signal-to-noise" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Ratio of Variances (Signal-to-Noise)</h2>
<p>From the above discussion we have a measure of potential “signal” in MS<sub>Among</sub> and actual “noise” around the full model (the model representing the “signal”) in MS<sub>Within</sub>. The ratio of this “signal” to “noise” is called an F test statistic; i.e.,</p>
<p><span class="math display">\[ \text{F}=\frac{\text{MS}_{\text{Among}}}{\text{MS}_{\text{Within}}} = \frac{\text{Signal}}{\text{Noise}} = \frac{\text{Variance Explained by Full Model}}{\text{Variance Unexplained by Full Model}} \]</span></p>
<p>If the F-ratio is “large,” then a great deal more variability was explained (i.e., more “signal”) than was unexplained by the full model (i.e., “less noise”) and one would conclude that the full model fits the data significantly better than the simple model, even considering the increased complexity of the full model.</p>
<p>The question now becomes “when is the F-ratio considered large enough to reject the simple model and conclude that the full model is significantly better?” This question can by comparing the F-ratio test statistic to an F-distribution.</p>
<p>An F-distribution<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> is right-skewed, with the exact shape of the distribution dictated by two separate degrees-of-freedom – called the numerator and denominator degrees-of-freedom, respectively. The numerator df is equal to the df used in MS<sub>Among</sub>, whereas the denominator df is equal to the df used in MS<sub>Within</sub>. The p-value is always computed as the area under the F-distribution curve to the right of the observed F-ratio test statistic.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
<div class="tip">
<p>The p-value is always computed to the <strong>right</strong> on an F-distribution.</p>
</div>
<p><img src="Book207_files/figure-html/Fpvalue-1.png" width="336" style="display: block; margin: auto;" /></p>
<p> </p>
<p>From this it can be seen that a small p-value comes from a large F-ratio, which comes from a large MS<sub>Among</sub> relative to MS<sub>Within</sub>, which means both that the full model explains more variability than is left unexplained and the “signal” is much greater than the “noise,” which means that the full model does fit significantly better than the simple model (even given the increased complexity), and, thus, the means are indeed different, which is what we would conclude from a small p-value. This cascade of measures can be explored with the dynamic graphic below.</p>
<iframe src="https://derek-ogle.shinyapps.io/App_F_Meaning/?showcase=0" width="95%" height="800px">
</iframe>
<p> </p>
</div>
<div id="anova-table" class="section level2" number="4.7">
<h2><span class="header-section-number">4.7</span> ANOVA Table</h2>
<p>The degrees-of-freedom (df), sum-of-squares (SS), mean-squares (MS), F-ratio test statistic (F), and corresponding p-value are summarized in what is called an <strong>analysis of variance (ANOVA) table</strong>.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> The ANOVA table contains rows that correspond to the different measures discussed above: among,<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> within,<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> and total. The df and SS are shown for each source, but the MS is shown only for the within and among sources because MS<sub>Among</sub>+MS<sub>Within</sub>≠MS<sub>Total</sub>.</p>
<div class="tip">
<p>SS and df partition, but MS do not! Do not add MS<sub>Among</sub> and MS<sub>Within</sub> to get MS<sub>Total</sub>, instead divide SS<sub>Total</sub> by df<sub>Total</sub>.</p>
</div>
<p>An ANOVA table for the BOD measurements at the inlet and outlet sources to the aquaculture facility is in Table <a href="ModelComparison.html#tab:ANOVA1">4.2</a>. Note that R does not show the total row that most softwares do.</p>
<table class=" lightable-classic" style="font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ANOVA1">Table 4.2: </span>An ANOVA table for biological oxygen demand measurements at two locations of the aquaculture facility. Note that the “Total” row is not shown.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Df
</th>
<th style="text-align:right;">
Sum Sq
</th>
<th style="text-align:right;">
Mean Sq
</th>
<th style="text-align:right;">
F value
</th>
<th style="text-align:right;">
Pr(&gt;F)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
src
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
20.6756
</td>
<td style="text-align:right;">
20.6756
</td>
<td style="text-align:right;">
80.8912
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Residuals
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
4.6008
</td>
<td style="text-align:right;">
0.2556
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
</tbody>
</table>
<p>These results indicate that H<sub>0</sub> should be rejected (i.e., F-test p-value &lt;0.00005). Thus, the full model fits the data significantly better than the simple model even given the difference in complexity between the two models and sampling variability. Therefore, there is a significant difference in mean BOD between the two locations.</p>
<p>In addition to the primary objective of comparing the full and simple models, several items of interest can be identified from an ANOVA table. Using the table above as an example, note the following items:</p>
<ul>
<li>The variance within groups is equal to MS<sub>Within</sub> (e.g., MS<sub>Residuals</sub>=0.2556 in this case). This is <span class="math inline">\(s_{p}^{2}\)</span> from the two-sample t-test (because there are only two groups here).</li>
<li>The common variance about the mean (<span class="math inline">\(s^{2}\)</span>) is given by MS<sub>Total</sub> (e.g., <span class="math inline">\(=\frac{20.6756+4.6008}{1+18}\)</span>=1.3303).</li>
</ul>
<p> </p>
</div>
<div id="two-sample-t-test-revisited-using-linear-models" class="section level2" number="4.8">
<h2><span class="header-section-number">4.8</span> Two-Sample t-Test Revisited: Using Linear Models</h2>
<p>The models for a two-sample t-test can be fit and assessed with <code>lm()</code>. This function requires the same type of formula for its first argument – <code>response~factor</code> – and a data.frame in the <code>data=</code> argument as described for <code>t.test()</code> in Section <a href="T2Review.html#T2analysis">2.2</a>. The results of <code>lm()</code> should be assigned to an object so that specific results can be selectively extracted from it. For example, the ANOVA table results are extracted from the <code>lm()</code> object with <code>anova()</code>. In addition, coefficient results<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a> can be extracted with <code>coef()</code>, <code>confint()</code>, and <code>summary()</code>. Note that I like to “column-bind” the coefficients and confidence intervals together for a more succinct representation.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="ModelComparison.html#cb10-1" aria-hidden="true" tabindex="-1"></a>aqua.lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(BOD<span class="sc">~</span>src,<span class="at">data=</span>aqua)</span>
<span id="cb10-2"><a href="ModelComparison.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(aqua.lm)</span></code></pre></div>
<pre><code>#R&gt;   Analysis of Variance Table
#R&gt;   
#R&gt;   Response: BOD
#R&gt;             Df  Sum Sq Mean Sq F value    Pr(&gt;F)
#R&gt;   src        1 20.6756 20.6756  80.891 4.449e-08
#R&gt;   Residuals 18  4.6008  0.2556</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="ModelComparison.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="at">ests=</span><span class="fu">coef</span>(aqua.lm),<span class="fu">confint</span>(aqua.lm))</span></code></pre></div>
<pre><code>#R&gt;                 ests    2.5 %   97.5 %
#R&gt;   (Intercept) 6.6538 6.317917 6.989683
#R&gt;   srcoutlet   2.0335 1.558489 2.508511</code></pre>
<p>From these results, note:</p>
<ul>
<li>The p-value in the ANOVA table is the same as that computed from <code>t.test()</code>.</li>
<li>The coefficient for <code>srcoutlet</code> is the same as the difference in the group means computed with <code>t.test()</code>.</li>
<li>The F test statistics in the ANOVA table equals the square of the t test statistic from <code>t.test()</code>. This is because an F with 1 numerator and v denominator df exactly equals the square of a t with v df.</li>
</ul>
<p>Thus, the exact same results for a two-sample t-test are obtained whether the analysis is completed in the “traditional” manner (i.e., with <code>t.test()</code>) or with competing models (i.e., using <code>lm()</code>). This concept will be extended in subsequent modules.</p>
<p> </p>
</div>
<div id="one-more-look-at-ms-and-f-test" class="section level2" number="4.9">
<h2><span class="header-section-number">4.9</span> One More Look at MS and F-test</h2>
<p>Recall from your introductory statistics course that a sampling distribution is the distribution of a statistic from all possible samples. For example, the Central Limit Theorem states that the distribution of sample means is approximately normal, centered on μ, with a standard error of <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span> as long as assumptions about the sample size are met. Further recall that the sampling distribution of the sample means is centered on μ because the sample mean is an unbiased estimator of μ. Similarly, it is also known that the center of the sampling distribution of <span class="math inline">\(s^{2}\)</span> is equal to <span class="math inline">\(\sigma^{2}\)</span> because <span class="math inline">\(s^{2}\)</span> is an unbiased estimate of <span class="math inline">\(\sigma^{2}\)</span>.</p>
<p>MS<sub>Within</sub> and MS<sub>Among</sub> are statistics just as <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(s^{2}\)</span> are statistics. Thus, MS<sub>Within</sub> and MS<sub>Among</sub> are subject to sampling variability and have sampling distributions. It can be shown<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a> that the center of the sampling distribution of MS<sub>Within</sub> is <span class="math inline">\(\sigma^{2}\)</span> and the center of the sampling distribution of MS<sub>Among</sub> is</p>
<p><span class="math display">\[ \sigma^{2} + \frac{1}{I-1}\sum_{i=1}^{I}n_{i}\left(\mu_{i}-\mu\right)^{2} \]</span></p>
<p>Thus, MS<sub>Among</sub> consists of two “sources” of variability. The first source (<span class="math inline">\(\sigma^{2}\)</span>) is the natural variability that exists among individuals. The second source <span class="math inline">\(\left(\frac{1}{I-1}\sum_{i=1}^{I}n_{i}\left(\mu_{i}-\mu\right)^{2}\right)\)</span> is related to differences among the group means. Therefore, if the group means are all equal – i.e., <span class="math inline">\(\mu_{1}\)</span>=<span class="math inline">\(\mu_{2}\)</span>= <span class="math inline">\(\cdots\)</span> = <span class="math inline">\(\mu_{I}\)</span> = <span class="math inline">\(\mu\)</span> – then the second source of variability is equal to zero and MS<sub>Among</sub> will equal MS<sub>Within</sub>. As soon as the groups begin to differ, the second source of variability will be greater than 0 and MS<sub>Among</sub> will be greater than MS<sub>Within</sub>.</p>
<p>From this, it follows that if the null hypothesis of equal population means is true (i.e., one mean fits all groups), then the center of the sampling distribution of both MS<sub>Within</sub> and MS<sub>Among</sub> is <span class="math inline">\(\sigma^{2}\)</span>. Therefore, if the null hypothesis is true, then the F test-statistic is expected to be equal to 1, on average, which will always result in a large p-value and a DNR H<sub>0</sub> conclusion. However, if the null hypothesis is false (i.e., separate means are needed for all groups), then the center of the sampling distribution of MS<sub>Within</sub> is <span class="math inline">\(\sigma^{2}\)</span> but the center of the sampling distribution of MS<sub>Among</sub> is <span class="math inline">\(\sigma^{2}\)</span> + “something,” where the “something” is greater than 0 and gets larger as the means become “more different.” Thus, if the null hypothesis is false then the F test-statistic is expected to be greater than 1 and will get larger as the null hypothesis gets “more false.” This analysis of sampling distribution theory illustrates once again that (1) MS<sub>Among</sub> consists of multiple sources of variability and (2) “large” values of the F test-statistic indicate that the null hypothesis is incorrect.</p>

</div>
</div>



<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>Generally, Observation = Model Prediction + Error<a href="ModelComparison.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>We will be more objective in the following sections, but an examination of the plot above clearly shows that the red line does not represent the observations well.<a href="ModelComparison.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>The “cost” is obviously 1 in this simple case.<a href="ModelComparison.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>As discussed in Section <a href="ModelConcepts.html#mean-squares">3.4</a>, SS are not true variances until they are divided by their df and become mean-squares (MS).<a href="ModelComparison.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>An F-distribution occurs whenever the ratio of two variances is calculated.<a href="ModelComparison.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>If the F-ratio is computed by hand, then <code>distrib()</code> with <code>distrib="f"</code>, <code>df1=</code>, <code>df2=</code>, and <code>lower.tail=FALSE</code> may be used to calculate the corresponding p-value.<a href="ModelComparison.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>An ANOVA table does not necessarily mean that an “analysis of variance” method was used. It turns out that all general linear models are summarized with an ANOVA table, regardless of whether a one- or two-way ANOVA method was used.<a href="ModelComparison.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>Labeled as the factor variable in most statistical software packages including R – that variable was called <code>src</code> in this example.<a href="ModelComparison.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>Labeled as residuals in R and error in other statistical software packages.<a href="ModelComparison.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>The coefficient results will be discussed in more detail in Module <a href="ANOVA1Foundations.html#ANOVA1Foundations">5</a>.<a href="ModelComparison.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>This derivation is beyond the scope of this course.<a href="ModelComparison.html#fnref16" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ModelConcepts.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ANOVA1Foundations.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Book207.pdf", "Book207.epub"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
