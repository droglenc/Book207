# 2-Sample t Review {#T2Review}

```{r 2TReview-setup, include=FALSE}
aqua <- read.csv("https://raw.githubusercontent.com/droglenc/NCData/master/BOD.csv")
p.lev.aqua <- levenesTest(BOD~src,data=aqua)$"Pr(>F)"[1]
aqua2t <- t.test(BOD~src,data=aqua,var.equal=TRUE,alt="two.side",conf.level=0.95)
```

A two-sample t-test is a statistical method for comparing the means of a quantitative variable between two populations represented by two independent samples. The [specific details of a two-sample t-test were covered in your introductory statistics course](http://derekogle.com/NCMTH107/modules/2Samplet.html) and will only be cursorily reviewed here. 

## Review
The null hypothesis for a 2-sample t-test is H<sub>0</sub>: $\mu_{1}=\mu_{2}$, where $\mu$ is the population mean and the subscripts represent the two populations. The alternative hypothesis of a 2-sample t-test may be "less than", "greater than", or "not equals". We will use H<sub>A</sub>: $\mu_{1}\ne\mu_{2}$ for most examples in this course.

The 2-sample t-test assumes that (i) individuals in the populations are independent; (ii) the sample size ($n_{1}+n_{2}$) is great than 40, greater than 15 and the histograms are not strongly skewed, or the histograms are normally distributed; and (iii) the population variances are equal. The assumption of equal variances for the 2-sample t-test is tested with Levene's test, which uses H<sub>0</sub>: $\sigma_{1}^{2}=\sigma_{2}^{2}$ and H<sub>A</sub>: $\sigma_{1}^{2}\ne\sigma_{2}^{2}$, where $\sigma^{2}$ is the population variance. If H<sub>0</sub> is rejected for Levene's test then the variances for both populations are assumed to be equal, such that only one combined sample variance needs to be estimated. That combined sample variance is called the *the pooled sample variance* and is computed as a weighted mean of the two sample variances,

$$ s_{p}^{2}=\frac{(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2} $$

If the three assumptions are met then the statistic for the 2-sample t-test is $\bar{x}_{1}-\bar{x}_{2}$ which is standardized to a t test statistic with

$$ t=\frac{\bar{x}_{1}-\bar{x}_{2}}{\sqrt{s_{p}^{2}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}} \right)}} $$

The t test statistic is converted to a p-value using a t-distribution with $n_{1}+n_{2}-2$ df. Of course, a p-value < &alpha; means that H<sub>0</sub> is rejected and the two population means appear to be different. A confidence interval would then be used to fully describe which population mean was greater (or smaller) and by how much.

&nbsp;

## Analysis in R {#T2analysis}
### Data Format
Data for a 2-sample t-test must be in stacked format, where measurements are in one column and a label for the populations is in another column. Each row corresponds to the measurement and population of a single individual.

The data in BOD.csv ([data](https://raw.githubusercontent.com/droglenc/NCData/master/BOD.csv), [meta](https://github.com/droglenc/NCData/blob/master/BOD_meta.txt)) are the [biological oxygen demands (BOD)](https://www.usgs.gov/special-topic/water-science-school/science/biological-oxygen-demand-bod-and-water?qt-science_center_objects=0#qt-science_center_objects) at the inlet and outlet to an aquaculture facility. These data illustrate stacked data because each row is one water sample with two variables recorded -- BOD and where the sample came from.

```{r eval=FALSE}
aqua <- read.csv("BOD.csv")   # Loads the data
```
```{r}
headtail(aqua)  # First and last three rows of the data
```

::: {.defn data-latex=""}
**Stacked Data**: Data where the quantitative measurements of two or more groups are "stacked" on top of each other and a second variable is used to record to which group (or population) the measurement belongs.
:::

::: {.tip data-latex=""}
Stacked data are required for the methods used in this course.
:::

Specific [details for performing a 2-sample t-test in R](http://derekogle.com/NCMTH107/modules/2Samplet.html) were provided in your introductory statistics course, but will be cursorily reviewed below.

### Assumption Checking
The [meta](https://github.com/droglenc/NCData/blob/master/BOD_meta.txt))data suggests that measurements at the intake and outtake were taken at different times. Thus, there is no reasonable reason to think that BOD measurements are dependent across the two locations. Thus, the independence assumption is met.

The sample size is less than 40 but greater than 15. The histograms shown below are not particularly informative because of the small sample size. The histogram for the inlet samples appears to be not strongly skewed, but that for the outlet appears to be strongly right-skewed. I am going to continue with this analysis, but I will be cautious with my final interpretations.

```{r fig.width=7}
ggplot(data=aqua,mapping=aes(x=BOD)) +
  geom_histogram(binwidth=0.5,boundary=0,color="black",fill="lightgray") +
  labs(y="Frequency of Water Samples",x="Biological Oxygen Demand") +
  scale_y_continuous(expand=expansion(mult=c(0,0.05))) +
  theme_NCStats() +
  facet_wrap(vars(src))
```

::: {.tip data-latex=""}
The `ggplot2` package is required to make plots with `ggplot()`.
:::

Levene's test is computed with `levenesTest()` using a formula of `response~groups` as the first argument, where `response` represents the name of the quantitative response variable and `groups` represents the name of the categorical variable that identifies the two populations. The data.frame with the variables must be in `data=`. From the results below, it is concluded that the population variances appear to be equal because the Levene's test p-value (`r kPvalue(p.lev.aqua,include.p=FALSE,latex=FALSE)`) is greater than &alpha;=0.05.

```{r warning=FALSE}
levenesTest(BOD~src,data=aqua)
```

::: {.tip data-latex=""}
Levene's test requires the `NCStats` package to be loaded.
:::

### Analysis
A 2-sample t-test is constructed in R with `t.test()` using the exact same `response~groups` formula and `data=` used in `levenesTest()`. Additionally, `var.equal=TRUE` is used when the two population variances should be considered equal. By default `t.test()` uses a "not equals" H<sub>A</sub> and a 95% confidence interval. In the results below the two sample means are `r formatC(aqua2t$estimate[1],format="f",digits=4)` for the inlet group and `r formatC(aqua2t$estimate[2],format="f",digits=4)` for the outlet group such that the statistic is `r formatC(aqua2t$estimate[1],format="f",digits=4)`-`r formatC(aqua2t$estimate[2],format="f",digits=4)`=`r formatC(aqua2t$estimate[1]-aqua2t$estimate[2],format="f",digits=4)`; the t test statistic is `r formatC(aqua2t$statistic[1],format="f",digits=3)` with `r aqua2t$parameter` df; and the p-value is `r kPvalue(aqua2t$p.value,include.p=FALSE,latex=FALSE)` (or, more specifically, `r formatC(aqua2t$p.value,digits=4)`).^[I usually round my p-values to four decimal places. In this case that would mean 0.0000 which is awkward. Thus, I will say p<0.00005 as the fifth position must have been less than 5 to round to 0.0000.] Because the p-value<&alpha; the H<sub>0</sub> is rejected and we conclude that the mean BOD at the inlet is lower than the mean BOD at the outlet. More specifically, the mean BOD at the inlet is between `r formatC(-1*aqua2t$conf.int[2],format="f",digits=3)` and `r formatC(-1*aqua2t$conf.int[1],format="f",digits=3)` units lower than the mean BOD at the outlet. Thus, it appears that the mean BOD in the water is increased from when it enters to when it leaves the aquaculture facility.

```{r}
t.test(BOD~src,data=aqua,var.equal=TRUE)
```

A graphic that illustrates the mean BOD with 95% confidence intervals for each sampling location is constructed below. In the code below you only need to change `data=` to the name of your data and `x=` and `y=` to the names of the explanatory and response variables in the first line and provide appropriate labels for the x- and y-axes in `labs()`.

```{r}
ggplot(data=aqua,mapping=aes(x=src,y=BOD)) +
  geom_jitter(alpha=0.5,width=0.05) +
  stat_summary(fun.data=mean_cl_normal,geom="errorbar",size=2,width=0) +
  stat_summary(fun=mean,geom="point",pch=21,fill="white",size=2) +
  labs(x="Water Sample Location",y="Biological Oxygen Demand") +
  theme_NCStats()
```

&nbsp;

## Signal-to-Noise
```{r echo=FALSE}
set.seed(53236)
ybar <- c(2,3,2,3,2,3)*10+25
sp <- c(2,2,8,8,20,20)
n <- 20
y <- NULL
for (i in seq_along(ybar)) y <- c(y,ybar[i]+sp[i]*scale(rnorm(n=n)))
d <- data.frame(y=y,
                grp=rep(rep(c("A","B"),each=n),times=3),
                sim=factor(rep(c("Small SE","Medium SE","Large SE"),each=n*2),
                           levels=c("Small SE","Medium SE","Large SE")))
d1 <- filter(d,sim=="Small SE")
```

The ratio of signal to noise can be a useful metaphor for understanding hypothesis testing, as we have done here, and model comparisons, as we will do in future modules. In this metaphor, think of "signal" as how different two things are and "noise" as anything that gets in the way of you receiving the signal. For example, the lights on a care are a "signal", but fog on the road is "noise" (Figure \@ref(fig:Signal2NoiseMetaphor)). As another example, it may be easy to see an orange kayak (the "signal") on Lake Superior on a calm day but harder to see it on a wavy day (i.e., more "noise"; Figure \@ref(fig:Signal2NoiseMetaphor)).

```{r Signal2NoiseMetaphor, echo=FALSE, out.width="75%", fig.cap="Signal-to-noise metahpors - seeing car lights through fog (Left) and seeing a kayak in the waves (Right)."}
knitr::include_graphics("zimgs/Signal2NoiseMetaphor.jpg")
```

&nbsp;

In a 2-sample t-test, the "signal" is the difference in the two group means (Figure \@ref(fig:SignalNoise1)), which is measured by $\bar{x}_{1}-\bar{x}_{2}$, the numerator of the t-test statistic. The bigger the difference in sample means the stronger the "signal" that the population means are different.

```{r SignalNoise1, echo=FALSE, fig.cap='Response variable by group for each individual (points) with group means shown as horizontal segments. The difference in sample means is highlighted as the "signal" in these data.'}
tmp <- ggplot(data=d1,mapping=aes(y=y,x=grp,color=grp)) +
  geom_point(alpha=0.5) +
  stat_summary(geom="point",fun="mean",shape="-",size=15) +
  labs(y="Response Variable",x="Group") +
  scale_color_manual(values=clrs2) +
  theme_NCStats() +
  theme(legend.position="none")
tmp +
  geom_segment(mapping=aes(x=1.5,xend=1,y=45,yend=45),
               color=lbl_clr,linetype="dashed") +
  geom_segment(mapping=aes(x=1.5,xend=2,y=55,yend=55),
               color=lbl_clr,linetype="dashed") +
  geom_segment(mapping=aes(x=1.5,xend=1.5,y=45,yend=55),color=lbl_clr,
               arrow=arrow(ends="both",length=unit(0.2,"cm"),type="closed")) +
  geom_text(mapping=aes(x=1.5,y=50,label="Signal"),size=4,color=lbl_clr,
            angle=90,vjust=-0.5)
```

::: {.tip data-latex=""}
The "signal" is the difference in sample means
:::

"Noise" is sampling variability, the fact that statistics (e.g., $\bar{x}_{1}$ and $\bar{x}_{2}$) vary from sample to sample. Sampling variability in a 2-sample t-test is measured by $SE_{\bar{x}_{1}-\bar{x}_{2}}$, which is the denominator of the t test statistic, or $\sqrt{s_{p}^{2}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)}$. This SE increases with increasing $s_{p}^{2}$ and decreases with increasing n<sub>1</sub> and n<sub>2</sub>. So the "noise" increases as the (natural) variability of individuals increases (i.e., $s_{p}^{2}$; Figure \@ref(fig:SignalNoise2)), but decreases as the sample size increases.

```{r SignalNoise2, echo=FALSE, results='hide', fig.cap='Response variable by group for each individual (points) with group means shown as horizontal segments. The variability of individuals around the group means is highlighted as a part of the "noise" in these data.'}
d1 %>%
  group_by(grp) %>%
  summarize(miny=min(y),
            maxy=max(y))

tmp + 
  geom_segment(mapping=aes(x=1,xend=1.2,y=41.3,yend=41.3),
               color=lbl_clr,linetype="dashed") +
  geom_segment(mapping=aes(x=1,xend=1.2,y=49.0,yend=49.0),
               color=lbl_clr,linetype="dashed") +
  geom_segment(mapping=aes(x=1.2,xend=1.2,y=41.3,yend=49.0),color=lbl_clr,
               arrow=arrow(ends="both",length=unit(0.2,"cm"),type="closed")) +
  geom_segment(mapping=aes(x=2,xend=1.8,y=50.1,yend=50.1),
               color=lbl_clr,linetype="dashed") +
  geom_segment(mapping=aes(x=2,xend=1.8,y=58.5,yend=58.5),
               color=lbl_clr,linetype="dashed") +
  geom_segment(mapping=aes(x=1.8,xend=1.8,y=50.1,yend=58.5),color=lbl_clr,
               arrow=arrow(ends="both",length=unit(0.2,"cm"),type="closed")) +
  geom_segment(mapping=aes(x=1.2,xend=1.5,y=45,yend=45),color=lbl_clr) +
  geom_segment(mapping=aes(x=1.8,xend=1.5,y=55,yend=55),color=lbl_clr) +
  geom_segment(mapping=aes(x=1.5,xend=1.5,y=45,yend=55),color=lbl_clr) +
  geom_text(mapping=aes(x=1.5,y=50,label="Part of the Noise"),
            size=4,color=lbl_clr,angle=90,vjust=-0.5)
```

::: {.tip data-latex=""}
The "noise" is sampling variability
:::

The ratio of signal to noise is related to whether we will be able to detect the difference between two things or not. If the signal is large relative to the noise then the signal will be detected. In other words, we will be able to see the car lights if the road is not foggy or we will more likely see the kayak if the lake is calm.

For example, each panel in Figure \@ref(fig:SignalNoise3) has the same signal (difference in means) but the noise (i.e., SE) increases from left to right. In the left-most panel it is very clear that the sample means are different (high signal-to-noise ratio), but in the right-most panel it is less clear that the sample means are different (low signal-to-noise ratio).

```{r SignalNoise3, echo=FALSE, fig.width=7.5, fig.height=3, fig.cap='Response variable by group for each indiviual (points) with group means shown as horizontal segments for three different standard errors (SE; i.e., "noise"). Note that the group means are the same in all three panels.'}
ggplot(data=d,mapping=aes(y=y,x=grp,color=grp)) +
  geom_point(alpha=0.5) +
  stat_summary(geom="point",fun="mean",shape="-",size=15) +
  labs(y="Response Variable",x="Group") +
  scale_color_manual(values=clrs2) +
  facet_wrap(vars(sim),scales="free_y") +
  theme_NCStats() +
  theme(legend.position="none",
        strip.text=element_text(face="bold"))
```

&nbsp;

The t test statistic is a measure of signal (i.e., difference in sample means) to noise (i.e., sampling variability as measured by the SE)

$$ t=\frac{\bar{x}_{1}-\bar{x}_{2}}{\sqrt{s_{p}^{2}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}} \right)}} = \frac{\text{Signal}}{\text{Noise}} $$

Thus, larger values of the t test statistic indicate a larger signal-to-noise ratio. Larger t test statistics are further into the tail of the t distribution and result in smaller p-values. Therefore, small p-values represent larger signal-to-noise ratios and are more likely to lead to concluding that the population means differ. In other words, you were able to detect the "signal" through the "noise."

::: {.tip data-latex=""}
More signal-to-noise means smaller p-values
:::

We will return to the signal-to-noise metaphor throughout this course.
